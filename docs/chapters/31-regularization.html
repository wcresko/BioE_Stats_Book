<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.30">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>32&nbsp; Regularization Methods – Statistics for the Biosciences and Bioengineering</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/32-smoothing.html" rel="next">
<link href="../chapters/30-model-validation.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-de070a7b0ab54f8780927367ac907214.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-485d01fc63b59abcd3ee1bf1e8e2748d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/29-intro-statistical-learning.html">Statistical Learning</a></li><li class="breadcrumb-item"><a href="../chapters/31-regularization.html"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Regularization Methods</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Statistics for the Biosciences and Bioengineering</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Why This Book?</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Core Data Science Tools</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/01-introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/02-installing-tools.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Installing Core Tools</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/03-unix-command-line.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Unix and the Command Line</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/04-r-rstudio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">R and RStudio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/05-markdown-latex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Markdown and LaTeX</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Data Exploration</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/06-tidy-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Tidy Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/07-data-wrangling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Data Wrangling with dplyr</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/08-exploratory-data-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Exploratory Data Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/09-data-visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Data Visualization</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Probability and Distributions</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/10-probability-foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Foundations of Probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/11-discrete-distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Discrete Probability Distributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/12-continuous-distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Continuous Probability Distributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/13-sampling-estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Sampling and Parameter Estimation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Statistical Inference</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/14-experimental-design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Experimental Design Principles</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/15-hypothesis-testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/16-t-tests.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">T-Tests</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/17-nonparametric-tests.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Nonparametric Tests</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/18-bootstrapping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Resampling Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/19-presenting-results.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Presenting Statistical Results</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Linear Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/20-what-are-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">What are Models?</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/21-correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Correlation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/22-simple-linear-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Simple Linear Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/23-residual-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Residual Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/24-statistical-power.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Statistical Power</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/25-multiple-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Multiple Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/26-single-factor-anova.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Single Factor ANOVA</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/27-multifactor-anova.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Multi-Factor ANOVA</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/28-glm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Generalized Linear Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Statistical Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/29-intro-statistical-learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Introduction to Statistical Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/30-model-validation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Model Validation and the Bias-Variance Tradeoff</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/31-regularization.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Regularization Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/32-smoothing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Smoothing and Non-Parametric Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/33-classification-methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Classification and Performance Metrics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/34-trees-forests.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Decision Trees and Random Forests</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/35-svm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Support Vector Machines</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/36-clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Clustering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/37-dimensionality-reduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Dimensionality Reduction and Multivariate Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/38-tsne-umap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Non-Linear Dimensionality Reduction: t-SNE and UMAP</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/39-bayesian-statistics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Bayesian Statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/40-deep-learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Introduction to Deep Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A1-eugenics-history.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">The Eugenics History of Statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A2-keyboard-shortcuts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Keyboard Shortcuts Reference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A3-unix-reference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Unix Command Reference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A4-r-reference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">R Command Reference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A5-quarto-reference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Quarto Markdown Reference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A6-latex-reference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">LaTeX Command Reference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A7-greek-letters.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Greek Letters in Mathematics and Statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A8-probability-distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Common Probability Distributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A9-sampling-distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Sampling Distributions in Hypothesis Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A10-matrix-algebra.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Matrix Algebra Fundamentals</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A11-high-performance-computing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">High Performance Computing</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#the-need-for-regularization" id="toc-the-need-for-regularization" class="nav-link active" data-scroll-target="#the-need-for-regularization"><span class="header-section-number">32.1</span> The Need for Regularization</a></li>
  <li><a href="#the-regularization-idea" id="toc-the-regularization-idea" class="nav-link" data-scroll-target="#the-regularization-idea"><span class="header-section-number">32.2</span> The Regularization Idea</a></li>
  <li><a href="#ridge-regression-l2-penalty" id="toc-ridge-regression-l2-penalty" class="nav-link" data-scroll-target="#ridge-regression-l2-penalty"><span class="header-section-number">32.3</span> Ridge Regression (L2 Penalty)</a>
  <ul class="collapse">
  <li><a href="#properties-of-ridge-regression" id="toc-properties-of-ridge-regression" class="nav-link" data-scroll-target="#properties-of-ridge-regression">Properties of Ridge Regression</a></li>
  <li><a href="#geometric-interpretation" id="toc-geometric-interpretation" class="nav-link" data-scroll-target="#geometric-interpretation">Geometric Interpretation</a></li>
  </ul></li>
  <li><a href="#lasso-regression-l1-penalty" id="toc-lasso-regression-l1-penalty" class="nav-link" data-scroll-target="#lasso-regression-l1-penalty"><span class="header-section-number">32.4</span> Lasso Regression (L1 Penalty)</a>
  <ul class="collapse">
  <li><a href="#properties-of-lasso-regression" id="toc-properties-of-lasso-regression" class="nav-link" data-scroll-target="#properties-of-lasso-regression">Properties of Lasso Regression</a></li>
  <li><a href="#geometric-interpretation-1" id="toc-geometric-interpretation-1" class="nav-link" data-scroll-target="#geometric-interpretation-1">Geometric Interpretation</a></li>
  </ul></li>
  <li><a href="#elastic-net-combining-ridge-and-lasso" id="toc-elastic-net-combining-ridge-and-lasso" class="nav-link" data-scroll-target="#elastic-net-combining-ridge-and-lasso"><span class="header-section-number">32.5</span> Elastic Net: Combining Ridge and Lasso</a></li>
  <li><a href="#choosing-lambda-with-cross-validation" id="toc-choosing-lambda-with-cross-validation" class="nav-link" data-scroll-target="#choosing-lambda-with-cross-validation"><span class="header-section-number">32.6</span> Choosing Lambda with Cross-Validation</a>
  <ul class="collapse">
  <li><a href="#extracting-coefficients" id="toc-extracting-coefficients" class="nav-link" data-scroll-target="#extracting-coefficients">Extracting Coefficients</a></li>
  </ul></li>
  <li><a href="#comparing-regularization-methods" id="toc-comparing-regularization-methods" class="nav-link" data-scroll-target="#comparing-regularization-methods"><span class="header-section-number">32.7</span> Comparing Regularization Methods</a></li>
  <li><a href="#visualizing-the-comparison" id="toc-visualizing-the-comparison" class="nav-link" data-scroll-target="#visualizing-the-comparison"><span class="header-section-number">32.8</span> Visualizing the Comparison</a></li>
  <li><a href="#prediction-performance" id="toc-prediction-performance" class="nav-link" data-scroll-target="#prediction-performance"><span class="header-section-number">32.9</span> Prediction Performance</a></li>
  <li><a href="#when-to-use-each-method" id="toc-when-to-use-each-method" class="nav-link" data-scroll-target="#when-to-use-each-method"><span class="header-section-number">32.10</span> When to Use Each Method</a></li>
  <li><a href="#regularization-in-practice" id="toc-regularization-in-practice" class="nav-link" data-scroll-target="#regularization-in-practice"><span class="header-section-number">32.11</span> Regularization in Practice</a>
  <ul class="collapse">
  <li><a href="#high-dimensional-data-example" id="toc-high-dimensional-data-example" class="nav-link" data-scroll-target="#high-dimensional-data-example">High-Dimensional Data Example</a></li>
  <li><a href="#regularized-logistic-regression" id="toc-regularized-logistic-regression" class="nav-link" data-scroll-target="#regularized-logistic-regression">Regularized Logistic Regression</a></li>
  </ul></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">32.12</span> Exercises</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">32.13</span> Summary</a></li>
  <li><a href="#additional-resources" id="toc-additional-resources" class="nav-link" data-scroll-target="#additional-resources"><span class="header-section-number">32.14</span> Additional Resources</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/29-intro-statistical-learning.html">Statistical Learning</a></li><li class="breadcrumb-item"><a href="../chapters/31-regularization.html"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Regularization Methods</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-regularization" class="quarto-section-identifier"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Regularization Methods</span></span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="the-need-for-regularization" class="level2" data-number="32.1">
<h2 data-number="32.1" class="anchored" data-anchor-id="the-need-for-regularization"><span class="header-section-number">32.1</span> The Need for Regularization</h2>
<p>Standard linear regression estimates coefficients by minimizing the residual sum of squares (RSS):</p>
<p><span class="math display">\[\text{RSS} = \sum_{i=1}^n \left(y_i - \beta_0 - \sum_{j=1}^p \beta_j x_{ij}\right)^2\]</span></p>
<p>This works well when you have many more observations than predictors (<span class="math inline">\(n \gg p\)</span>) and the predictors are not highly correlated. But problems arise in several common situations.</p>
<p>When you have <strong>many predictors</strong> relative to the number of observations, coefficient estimates become unstable and their variance is high. The model has too many degrees of freedom to estimate reliably from the available data. When predictors are <strong>highly correlated</strong> (multicollinearity), the problem is compounded: small changes in the data can cause dramatic swings in the estimated coefficients, even though predictions remain stable. In either case, the result is often <strong>overfitting</strong>—the model fits the training data well but predicts poorly on new observations.</p>
<p><strong>Regularization</strong> addresses these issues by adding a penalty term that shrinks coefficients toward zero. This intentionally introduces a small amount of bias in exchange for a substantial reduction in variance. The net effect is usually better predictions on new data, especially when the number of predictors is large relative to the sample size.</p>
</section>
<section id="the-regularization-idea" class="level2" data-number="32.2">
<h2 data-number="32.2" class="anchored" data-anchor-id="the-regularization-idea"><span class="header-section-number">32.2</span> The Regularization Idea</h2>
<p>Regularized regression minimizes a modified objective:</p>
<p><span class="math display">\[\text{Minimize: } \text{RSS} + \lambda \cdot P(\beta)\]</span></p>
<p>In this formulation, <span class="math inline">\(P(\beta)\)</span> is a <strong>penalty function</strong> that penalizes large coefficients, and <span class="math inline">\(\lambda \geq 0\)</span> is the <strong>regularization parameter</strong> that controls the strength of the penalty.</p>
<p>The effect of the penalty is to shrink coefficients toward zero, with <span class="math inline">\(\lambda\)</span> controlling how aggressively. When <span class="math inline">\(\lambda = 0\)</span>, there is no penalty and we recover ordinary least squares. As <span class="math inline">\(\lambda\)</span> increases, the penalty becomes stronger and coefficients shrink more. In the limit as <span class="math inline">\(\lambda \to \infty\)</span>, all coefficients are forced to zero.</p>
<p>Different choices of the penalty function <span class="math inline">\(P(\beta)\)</span> lead to different regularization methods, each with distinct properties and use cases.</p>
</section>
<section id="ridge-regression-l2-penalty" class="level2" data-number="32.3">
<h2 data-number="32.3" class="anchored" data-anchor-id="ridge-regression-l2-penalty"><span class="header-section-number">32.3</span> Ridge Regression (L2 Penalty)</h2>
<p><strong>Ridge regression</strong> <span class="citation" data-cites="hoerl1970ridge">(<a href="../references.html#ref-hoerl1970ridge" role="doc-biblioref">Hoerl and Kennard 1970</a>)</span> uses the sum of squared coefficients as the penalty:</p>
<p><span class="math display">\[P(\beta) = \sum_{j=1}^p \beta_j^2\]</span></p>
<p>The full optimization problem is:</p>
<p><span class="math display">\[\hat{\beta}^{\text{ridge}} = \arg\min_\beta \left\{ \sum_{i=1}^n \left(y_i - \beta_0 - \sum_{j=1}^p \beta_j x_{ij}\right)^2 + \lambda \sum_{j=1}^p \beta_j^2 \right\}\]</span></p>
<section id="properties-of-ridge-regression" class="level3">
<h3 class="anchored" data-anchor-id="properties-of-ridge-regression">Properties of Ridge Regression</h3>
<p>Ridge regression shrinks all coefficients toward zero but <strong>never exactly to zero</strong>. This means all predictors remain in the model regardless of how large <span class="math inline">\(\lambda\)</span> becomes—coefficients get very small but never vanish entirely. This property makes ridge regression particularly useful when you believe all predictors are relevant to some degree. It is also especially effective when predictors are highly correlated (multicollinearity), as the penalty stabilizes the coefficient estimates that would otherwise be wildly unstable in ordinary least squares.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate sample data with correlated predictors</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n <span class="sc">*</span> p), n, p)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create correlated predictors</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>X[, <span class="dv">2</span>] <span class="ot">&lt;-</span> X[, <span class="dv">1</span>] <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> <span class="fl">0.5</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>X[, <span class="dv">3</span>] <span class="ot">&lt;-</span> X[, <span class="dv">1</span>] <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> <span class="fl">0.5</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>true_beta <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="fl">1.5</span>, <span class="fu">rep</span>(<span class="dv">0</span>, p <span class="sc">-</span> <span class="dv">3</span>))</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> X <span class="sc">%*%</span> true_beta <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit ridge regression across lambda values</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>ridge_fit <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, y, <span class="at">alpha =</span> <span class="dv">0</span>)  <span class="co"># alpha = 0 for ridge</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot coefficient paths</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ridge_fit, <span class="at">xvar =</span> <span class="st">"lambda"</span>, <span class="at">main =</span> <span class="st">"Ridge Regression Coefficients"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-ridge-path" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ridge-path-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="31-regularization_files/figure-html/fig-ridge-path-1.png" class="img-fluid figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ridge-path-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;32.1: Ridge regression coefficient paths: as lambda increases, coefficients shrink toward zero but never reach exactly zero
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="geometric-interpretation" class="level3">
<h3 class="anchored" data-anchor-id="geometric-interpretation">Geometric Interpretation</h3>
<p>Ridge regression constrains coefficients to lie within a sphere (in 2D, a circle) centered at the origin:</p>
<p><span class="math display">\[\sum_{j=1}^p \beta_j^2 \leq t\]</span></p>
<p>where <span class="math inline">\(t\)</span> is inversely related to <span class="math inline">\(\lambda\)</span>. The OLS solution may lie outside this constraint region, so ridge finds the point where the RSS contours first touch the constraint boundary.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Geometric illustration</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">2</span><span class="sc">*</span>pi, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">cos</span>(theta), <span class="fu">sin</span>(theta), <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"blue"</span>,</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">asp =</span> <span class="dv">1</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>),</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>]), <span class="at">ylab =</span> <span class="fu">expression</span>(beta[<span class="dv">2</span>]),</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Ridge Constraint Region"</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Add contours representing RSS</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (r <span class="cf">in</span> <span class="fu">seq</span>(<span class="fl">0.3</span>, <span class="fl">1.5</span>, <span class="fl">0.3</span>)) {</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(r <span class="sc">*</span> <span class="fu">cos</span>(theta) <span class="sc">+</span> <span class="fl">0.8</span>, r <span class="sc">*</span> <span class="fu">sin</span>(theta) <span class="sc">+</span> <span class="fl">0.6</span>,</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        <span class="at">col =</span> <span class="st">"gray"</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co"># OLS estimate</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fl">0.8</span>, <span class="fl">0.6</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.8</span>, <span class="fl">0.75</span>, <span class="st">"OLS"</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Ridge estimate (on boundary)</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fl">0.5</span>, <span class="fl">0.37</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="st">"Ridge"</span>, <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"bottomleft"</span>, <span class="fu">c</span>(<span class="st">"Constraint region"</span>, <span class="st">"RSS contours"</span>),</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"gray"</span>), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">lwd =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-ridge-geometry" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ridge-geometry-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="31-regularization_files/figure-html/fig-ridge-geometry-1.png" class="img-fluid figure-img" width="576">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ridge-geometry-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;32.2: Geometric interpretation of ridge regression: the constraint region is circular, so the solution rarely lies exactly on an axis (coefficient rarely zero)
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="lasso-regression-l1-penalty" class="level2" data-number="32.4">
<h2 data-number="32.4" class="anchored" data-anchor-id="lasso-regression-l1-penalty"><span class="header-section-number">32.4</span> Lasso Regression (L1 Penalty)</h2>
<p><strong>Lasso</strong> (Least Absolute Shrinkage and Selection Operator) <span class="citation" data-cites="tibshirani1996regression">(<a href="../references.html#ref-tibshirani1996regression" role="doc-biblioref">Tibshirani 1996</a>)</span> uses the sum of absolute values as the penalty:</p>
<p><span class="math display">\[P(\beta) = \sum_{j=1}^p |\beta_j|\]</span></p>
<p>The optimization problem is:</p>
<p><span class="math display">\[\hat{\beta}^{\text{lasso}} = \arg\min_\beta \left\{ \sum_{i=1}^n \left(y_i - \beta_0 - \sum_{j=1}^p \beta_j x_{ij}\right)^2 + \lambda \sum_{j=1}^p |\beta_j| \right\}\]</span></p>
<section id="properties-of-lasso-regression" class="level3">
<h3 class="anchored" data-anchor-id="properties-of-lasso-regression">Properties of Lasso Regression</h3>
<p>Unlike ridge, lasso can shrink coefficients <strong>exactly to zero</strong>, effectively performing <strong>variable selection</strong>. This produces <strong>sparse models</strong> with fewer predictors, making the resulting models easier to interpret since they explicitly identify which variables are “important.” However, lasso may struggle when predictors are highly correlated—in such cases, it tends to select one predictor from a correlated group arbitrarily while setting the others to zero, rather than distributing the effect among them as ridge would.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit lasso regression</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>lasso_fit <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, y, <span class="at">alpha =</span> <span class="dv">1</span>)  <span class="co"># alpha = 1 for lasso</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lasso_fit, <span class="at">xvar =</span> <span class="st">"lambda"</span>, <span class="at">main =</span> <span class="st">"Lasso Regression Coefficients"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-lasso-path" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-lasso-path-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="31-regularization_files/figure-html/fig-lasso-path-1.png" class="img-fluid figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-lasso-path-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;32.3: Lasso regression coefficient paths: as lambda increases, coefficients shrink and some become exactly zero (variable selection)
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="geometric-interpretation-1" class="level3">
<h3 class="anchored" data-anchor-id="geometric-interpretation-1">Geometric Interpretation</h3>
<p>Lasso constrains coefficients to lie within a diamond (in 2D, an L1 ball):</p>
<p><span class="math display">\[\sum_{j=1}^p |\beta_j| \leq t\]</span></p>
<p>The diamond has corners on the axes, so the RSS contours often touch the constraint at a corner, forcing some coefficients to exactly zero.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Diamond constraint</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>diamond_x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>diamond_y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(diamond_x, diamond_y, <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"blue"</span>,</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">asp =</span> <span class="dv">1</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>),</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>]), <span class="at">ylab =</span> <span class="fu">expression</span>(beta[<span class="dv">2</span>]),</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Lasso Constraint Region"</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Add contours</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (r <span class="cf">in</span> <span class="fu">seq</span>(<span class="fl">0.3</span>, <span class="fl">1.5</span>, <span class="fl">0.3</span>)) {</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(r <span class="sc">*</span> <span class="fu">cos</span>(theta) <span class="sc">+</span> <span class="fl">0.8</span>, r <span class="sc">*</span> <span class="fu">sin</span>(theta) <span class="sc">+</span> <span class="fl">0.6</span>,</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        <span class="at">col =</span> <span class="st">"gray"</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co"># OLS estimate</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fl">0.8</span>, <span class="fl">0.6</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.8</span>, <span class="fl">0.75</span>, <span class="st">"OLS"</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Lasso estimate (at corner)</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fl">0.7</span>, <span class="dv">0</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.7</span>, <span class="fl">0.15</span>, <span class="st">"Lasso"</span>, <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"bottomleft"</span>, <span class="fu">c</span>(<span class="st">"Constraint region"</span>, <span class="st">"RSS contours"</span>),</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"gray"</span>), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">lwd =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-lasso-geometry" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-lasso-geometry-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="31-regularization_files/figure-html/fig-lasso-geometry-1.png" class="img-fluid figure-img" width="576">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-lasso-geometry-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;32.4: Geometric interpretation of lasso: the constraint region has corners on the axes, so the solution often lies at a corner where one or more coefficients are exactly zero
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="elastic-net-combining-ridge-and-lasso" class="level2" data-number="32.5">
<h2 data-number="32.5" class="anchored" data-anchor-id="elastic-net-combining-ridge-and-lasso"><span class="header-section-number">32.5</span> Elastic Net: Combining Ridge and Lasso</h2>
<p><strong>Elastic net</strong> combines both penalties:</p>
<p><span class="math display">\[P(\beta) = \alpha \sum_{j=1}^p |\beta_j| + (1-\alpha) \sum_{j=1}^p \beta_j^2\]</span></p>
<p>The mixing parameter <span class="math inline">\(\alpha\)</span> controls the balance between the two penalties. When <span class="math inline">\(\alpha = 0\)</span>, elastic net reduces to pure ridge regression. When <span class="math inline">\(\alpha = 1\)</span>, it becomes pure lasso. Values between 0 and 1 give a combination of both penalties, often with <span class="math inline">\(\alpha = 0.5\)</span> as a natural starting point.</p>
<p>Elastic net is often preferred when predictors are correlated. Unlike lasso, which arbitrarily selects one variable from a correlated group, elastic net tends to select groups of correlated variables together. This behavior often produces more stable and interpretable models when the underlying science suggests that correlated predictors genuinely contribute to the outcome.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit elastic net</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>enet_fit <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, y, <span class="at">alpha =</span> <span class="fl">0.5</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(enet_fit, <span class="at">xvar =</span> <span class="st">"lambda"</span>, <span class="at">main =</span> <span class="st">"Elastic Net Coefficients (α = 0.5)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-elastic-net" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-elastic-net-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="31-regularization_files/figure-html/fig-elastic-net-1.png" class="img-fluid figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-elastic-net-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;32.5: Elastic net coefficient paths with alpha = 0.5 (equal mix of L1 and L2 penalties)
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Ridge</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">cos</span>(theta), <span class="fu">sin</span>(theta), <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"blue"</span>,</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">asp =</span> <span class="dv">1</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.2</span>, <span class="fl">1.2</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.2</span>, <span class="fl">1.2</span>),</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>]), <span class="at">ylab =</span> <span class="fu">expression</span>(beta[<span class="dv">2</span>]),</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Ridge (α = 0)"</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Elastic net</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>alpha_en <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>en_x <span class="ot">&lt;-</span> en_y <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="dv">100</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>) {</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Approximate elastic net constraint boundary</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>  ang <span class="ot">&lt;-</span> theta[i]</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>  r <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> (alpha_en <span class="sc">*</span> (<span class="fu">abs</span>(<span class="fu">cos</span>(ang)) <span class="sc">+</span> <span class="fu">abs</span>(<span class="fu">sin</span>(ang))) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">-</span> alpha_en))</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>  en_x[i] <span class="ot">&lt;-</span> r <span class="sc">*</span> <span class="fu">cos</span>(ang)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>  en_y[i] <span class="ot">&lt;-</span> r <span class="sc">*</span> <span class="fu">sin</span>(ang)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(en_x, en_y, <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"purple"</span>,</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>     <span class="at">asp =</span> <span class="dv">1</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.2</span>, <span class="fl">1.2</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.2</span>, <span class="fl">1.2</span>),</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>]), <span class="at">ylab =</span> <span class="fu">expression</span>(beta[<span class="dv">2</span>]),</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Elastic Net (α = 0.5)"</span>)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Lasso</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(diamond_x, diamond_y, <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"red"</span>,</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>     <span class="at">asp =</span> <span class="dv">1</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.2</span>, <span class="fl">1.2</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.2</span>, <span class="fl">1.2</span>),</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>]), <span class="at">ylab =</span> <span class="fu">expression</span>(beta[<span class="dv">2</span>]),</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Lasso (α = 1)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-enet-geometry" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-enet-geometry-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="31-regularization_files/figure-html/fig-enet-geometry-1.png" class="img-fluid figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-enet-geometry-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;32.6: Elastic net constraint region: intermediate between ridge (circle) and lasso (diamond)
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="choosing-lambda-with-cross-validation" class="level2" data-number="32.6">
<h2 data-number="32.6" class="anchored" data-anchor-id="choosing-lambda-with-cross-validation"><span class="header-section-number">32.6</span> Choosing Lambda with Cross-Validation</h2>
<p>The regularization parameter <span class="math inline">\(\lambda\)</span> is typically chosen by cross-validation:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cross-validation for lasso</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>cv_lasso <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X, y, <span class="at">alpha =</span> <span class="dv">1</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot cross-validation results</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv_lasso)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimal lambda values</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Lambda with minimum CV error:"</span>, <span class="fu">round</span>(cv_lasso<span class="sc">$</span>lambda.min, <span class="dv">4</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Lambda with minimum CV error: 0.0378 </code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Lambda within 1 SE of minimum:"</span>, <span class="fu">round</span>(cv_lasso<span class="sc">$</span>lambda<span class="fl">.1</span>se, <span class="dv">4</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Lambda within 1 SE of minimum: 0.0957 </code></pre>
</div>
<div class="cell-output-display">
<div id="fig-cv-lambda" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cv-lambda-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="31-regularization_files/figure-html/fig-cv-lambda-1.png" class="img-fluid figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cv-lambda-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;32.7: Cross-validation to select optimal lambda: the left dashed line marks the minimum error, the right marks the most regularized model within one standard error
</figcaption>
</figure>
</div>
</div>
</div>
<p>The <code>lambda.1se</code> (one standard error rule) often provides a more parsimonious model with nearly as good performance as the minimum.</p>
<section id="extracting-coefficients" class="level3">
<h3 class="anchored" data-anchor-id="extracting-coefficients">Extracting Coefficients</h3>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Coefficients at different lambda values</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Coefficients at lambda.min:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Coefficients at lambda.min:</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(cv_lasso, <span class="at">s =</span> <span class="st">"lambda.min"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>11 x 1 sparse Matrix of class "dgCMatrix"
              lambda.min
(Intercept)  0.095754403
V1           2.767360455
V2          -1.859381388
V3           1.597508497
V4          -0.099434052
V5           .          
V6           0.029276120
V7           .          
V8           .          
V9           0.005843271
V10         -0.082824940</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Coefficients at lambda.1se:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Coefficients at lambda.1se:</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(cv_lasso, <span class="at">s =</span> <span class="st">"lambda.1se"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>11 x 1 sparse Matrix of class "dgCMatrix"
             lambda.1se
(Intercept)  0.12555152
V1           2.16091712
V2          -1.35004269
V3           1.62087619
V4          -0.04486516
V5           .         
V6           .         
V7           .         
V8           .         
V9           .         
V10         -0.03937774</code></pre>
</div>
</div>
</section>
</section>
<section id="comparing-regularization-methods" class="level2" data-number="32.7">
<h2 data-number="32.7" class="anchored" data-anchor-id="comparing-regularization-methods"><span class="header-section-number">32.7</span> Comparing Regularization Methods</h2>
<p>Let’s compare OLS, ridge, and lasso on the same data:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit models with optimal lambda</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>ridge_cv <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X, y, <span class="at">alpha =</span> <span class="dv">0</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>lasso_cv <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X, y, <span class="at">alpha =</span> <span class="dv">1</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract coefficients</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>coef_ols <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(y <span class="sc">~</span> X))</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>coef_ridge <span class="ot">&lt;-</span> <span class="fu">coef</span>(ridge_cv, <span class="at">s =</span> <span class="st">"lambda.1se"</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>coef_lasso <span class="ot">&lt;-</span> <span class="fu">coef</span>(lasso_cv, <span class="at">s =</span> <span class="st">"lambda.1se"</span>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare (excluding intercept)</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>comparison <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">True =</span> <span class="fu">c</span>(<span class="cn">NA</span>, true_beta),</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">OLS =</span> <span class="fu">as.vector</span>(coef_ols),</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">Ridge =</span> <span class="fu">as.vector</span>(coef_ridge),</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">Lasso =</span> <span class="fu">as.vector</span>(coef_lasso)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(comparison) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Intercept"</span>, <span class="fu">paste0</span>(<span class="st">"X"</span>, <span class="dv">1</span><span class="sc">:</span>p))</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(comparison, <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>          True    OLS  Ridge  Lasso
Intercept   NA  0.069  0.175  0.121
X1         3.0  3.214  1.587  2.248
X2        -2.0 -2.217 -0.764 -1.423
X3         1.5  1.559  1.499  1.618
X4         0.0 -0.126 -0.157 -0.053
X5         0.0 -0.061 -0.009  0.000
X6         0.0  0.103 -0.009  0.000
X7         0.0 -0.023 -0.008  0.000
X8         0.0  0.036  0.009  0.000
X9         0.0  0.051  0.081  0.000
X10        0.0 -0.113 -0.127 -0.046</code></pre>
</div>
</div>
<p>The comparison reveals the distinct behavior of each method. <strong>OLS</strong> estimates show high variance, especially for the variables whose true coefficients are zero—these spuriously appear nonzero due to fitting noise. <strong>Ridge</strong> shrinks all coefficients toward zero, reducing variance, but it doesn’t eliminate any predictors from the model. <strong>Lasso</strong> strikes a different balance: it correctly identifies many of the zero coefficients and sets them exactly to zero, producing a sparse model that more closely matches the true data-generating process.</p>
</section>
<section id="visualizing-the-comparison" class="level2" data-number="32.8">
<h2 data-number="32.8" class="anchored" data-anchor-id="visualizing-the-comparison"><span class="header-section-number">32.8</span> Visualizing the Comparison</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot comparison</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>var_names <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"X"</span>, <span class="dv">1</span><span class="sc">:</span>p)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>coef_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">Variable =</span> <span class="fu">rep</span>(var_names, <span class="dv">4</span>),</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">Method =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"True"</span>, <span class="st">"OLS"</span>, <span class="st">"Ridge"</span>, <span class="st">"Lasso"</span>), <span class="at">each =</span> p),</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">Coefficient =</span> <span class="fu">c</span>(true_beta,</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">as.vector</span>(coef_ols)[<span class="sc">-</span><span class="dv">1</span>],</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">as.vector</span>(coef_ridge)[<span class="sc">-</span><span class="dv">1</span>],</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">as.vector</span>(coef_lasso)[<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(coef_df, <span class="fu">aes</span>(<span class="at">x =</span> Variable, <span class="at">y =</span> Coefficient, <span class="at">fill =</span> Method)) <span class="sc">+</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="at">position =</span> <span class="st">"dodge"</span>) <span class="sc">+</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"True"</span> <span class="ot">=</span> <span class="st">"black"</span>, <span class="st">"OLS"</span> <span class="ot">=</span> <span class="st">"gray"</span>,</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>                               <span class="st">"Ridge"</span> <span class="ot">=</span> <span class="st">"steelblue"</span>, <span class="st">"Lasso"</span> <span class="ot">=</span> <span class="st">"coral"</span>)) <span class="sc">+</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">45</span>, <span class="at">hjust =</span> <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Coefficient Estimates by Method"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-method-comparison" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-method-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="31-regularization_files/figure-html/fig-method-comparison-1.png" class="img-fluid figure-img" width="864">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-method-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;32.8: Comparison of coefficient estimates: true values, OLS, ridge, and lasso. Lasso successfully identifies zero coefficients while ridge shrinks but retains all.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="prediction-performance" class="level2" data-number="32.9">
<h2 data-number="32.9" class="anchored" data-anchor-id="prediction-performance"><span class="header-section-number">32.9</span> Prediction Performance</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate test data</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">999</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>X_test <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">50</span> <span class="sc">*</span> p), <span class="dv">50</span>, p)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>X_test[, <span class="dv">2</span>] <span class="ot">&lt;-</span> X_test[, <span class="dv">1</span>] <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">50</span>, <span class="at">sd =</span> <span class="fl">0.5</span>)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>X_test[, <span class="dv">3</span>] <span class="ot">&lt;-</span> X_test[, <span class="dv">1</span>] <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">50</span>, <span class="at">sd =</span> <span class="fl">0.5</span>)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>y_test <span class="ot">&lt;-</span> X_test <span class="sc">%*%</span> true_beta <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">50</span>)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>pred_ols <span class="ot">&lt;-</span> <span class="fu">predict</span>(<span class="fu">lm</span>(y <span class="sc">~</span> X), <span class="at">newdata =</span> <span class="fu">data.frame</span>(X_test))</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>pred_ridge <span class="ot">&lt;-</span> <span class="fu">predict</span>(ridge_cv, <span class="at">newx =</span> X_test, <span class="at">s =</span> <span class="st">"lambda.1se"</span>)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>pred_lasso <span class="ot">&lt;-</span> <span class="fu">predict</span>(lasso_cv, <span class="at">newx =</span> X_test, <span class="at">s =</span> <span class="st">"lambda.1se"</span>)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Test MSE</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>mse_ols <span class="ot">&lt;-</span> <span class="fu">mean</span>((y_test <span class="sc">-</span> pred_ols)<span class="sc">^</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in `h()`:
! error in evaluating the argument 'x' in selecting a method for function 'mean': dims [product 50] do not match the length of object [100]</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>mse_ridge <span class="ot">&lt;-</span> <span class="fu">mean</span>((y_test <span class="sc">-</span> pred_ridge)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>mse_lasso <span class="ot">&lt;-</span> <span class="fu">mean</span>((y_test <span class="sc">-</span> pred_lasso)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Test MSE:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Test MSE:</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"  OLS:"</span>, <span class="fu">round</span>(mse_ols, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error:
! object 'mse_ols' not found</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"  Ridge:"</span>, <span class="fu">round</span>(mse_ridge, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>  Ridge: 1.642 </code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"  Lasso:"</span>, <span class="fu">round</span>(mse_lasso, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>  Lasso: 1.148 </code></pre>
</div>
</div>
</section>
<section id="when-to-use-each-method" class="level2" data-number="32.10">
<h2 data-number="32.10" class="anchored" data-anchor-id="when-to-use-each-method"><span class="header-section-number">32.10</span> When to Use Each Method</h2>
<p>Choosing among regularization methods depends on your goals and the structure of your data.</p>
<p><strong>Ridge regression</strong> is the natural choice when you believe all predictors are genuinely relevant to the outcome, even if their individual effects are small. It is particularly effective when predictors are highly correlated, as the L2 penalty stabilizes coefficient estimates. Ridge tends to produce the most stable predictions, though the resulting model includes all variables, which may complicate interpretation.</p>
<p><strong>Lasso</strong> is preferred when you want automatic variable selection and believe only a subset of predictors are truly relevant. The resulting sparse models are easier to interpret and communicate, since they explicitly identify which variables matter. However, lasso can behave arbitrarily when predictors are correlated, selecting one while zeroing out others that may be equally important.</p>
<p><strong>Elastic net</strong> offers a middle ground that is often optimal in practice. Use it when predictors are correlated but you still want variable selection—elastic net tends to select groups of correlated variables together rather than making arbitrary choices. It’s also a sensible default when you’re unsure whether ridge or lasso is more appropriate, as cross-validation can select an optimal mixing parameter.</p>
<p>One practical note: always standardize predictors before applying regularization, as the penalty treats all coefficients equally and would otherwise penalize variables on larger scales more heavily. The <code>glmnet</code> function handles this automatically by default.</p>
</section>
<section id="regularization-in-practice" class="level2" data-number="32.11">
<h2 data-number="32.11" class="anchored" data-anchor-id="regularization-in-practice"><span class="header-section-number">32.11</span> Regularization in Practice</h2>
<section id="high-dimensional-data-example" class="level3">
<h3 class="anchored" data-anchor-id="high-dimensional-data-example">High-Dimensional Data Example</h3>
<p>Regularization is especially valuable when <span class="math inline">\(p\)</span> approaches or exceeds <span class="math inline">\(n\)</span>:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># High-dimensional example: p = 80, n = 100</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">80</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>X_hd <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n <span class="sc">*</span> p), n, p)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Sparse true model: only 5 predictors matter</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>true_beta_hd <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">2</span>, <span class="dv">5</span>), <span class="fu">rep</span>(<span class="dv">0</span>, p <span class="sc">-</span> <span class="dv">5</span>))</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>y_hd <span class="ot">&lt;-</span> X_hd <span class="sc">%*%</span> true_beta_hd <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="co"># OLS fails (numerically unstable or overfits severely)</span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="co"># ols_hd &lt;- lm(y_hd ~ X_hd)  # Would have issues</span></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Lasso works</span></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>cv_lasso_hd <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X_hd, y_hd, <span class="at">alpha =</span> <span class="dv">1</span>)</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a><span class="co"># How many non-zero coefficients?</span></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>lasso_coef <span class="ot">&lt;-</span> <span class="fu">coef</span>(cv_lasso_hd, <span class="at">s =</span> <span class="st">"lambda.1se"</span>)</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>n_nonzero <span class="ot">&lt;-</span> <span class="fu">sum</span>(lasso_coef[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">!=</span> <span class="dv">0</span>)</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"True non-zero coefficients:"</span>, <span class="dv">5</span>, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>True non-zero coefficients: 5 </code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Lasso selected:"</span>, n_nonzero, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Lasso selected: 5 </code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Which variables selected?</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>selected <span class="ot">&lt;-</span> <span class="fu">which</span>(lasso_coef[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">!=</span> <span class="dv">0</span>)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Selected variables:"</span>, <span class="fu">paste</span>(selected, <span class="at">collapse =</span> <span class="st">", "</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Selected variables: 1, 2, 3, 4, 5 </code></pre>
</div>
</div>
</section>
<section id="regularized-logistic-regression" class="level3">
<h3 class="anchored" data-anchor-id="regularized-logistic-regression">Regularized Logistic Regression</h3>
<p>Regularization extends naturally to classification problems:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Binary classification example</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>y_binary <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fu">plogis</span>(X <span class="sc">%*%</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="sc">-</span><span class="fl">0.5</span>, <span class="fl">0.3</span>, <span class="fu">rep</span>(<span class="dv">0</span>, p <span class="sc">-</span> <span class="dv">3</span>))))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in `X %*% c(1, -0.5, 0.3, rep(0, p - 3))`:
! non-conformable arguments</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Regularized logistic regression</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>cv_logit <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X, y_binary, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">alpha =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in `h()`:
! error in evaluating the argument 'x' in selecting a method for function 'drop': object 'y_binary' not found</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Coefficients</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Selected predictors for logistic regression:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Selected predictors for logistic regression:</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>logit_coef <span class="ot">&lt;-</span> <span class="fu">coef</span>(cv_logit, <span class="at">s =</span> <span class="st">"lambda.1se"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error:
! object 'cv_logit' not found</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">which</span>(logit_coef[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">!=</span> <span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>Error in `h()`:
! error in evaluating the argument 'x' in selecting a method for function 'which': object 'logit_coef' not found</code></pre>
</div>
</div>
</section>
</section>
<section id="exercises" class="level2" data-number="32.12">
<h2 data-number="32.12" class="anchored" data-anchor-id="exercises"><span class="header-section-number">32.12</span> Exercises</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise Reg.1: Ridge vs Lasso
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><p>Generate data with <span class="math inline">\(n = 100\)</span> observations and <span class="math inline">\(p = 20\)</span> predictors where:</p>
<ul>
<li>Predictors 1-3 have coefficients 3, -2, 1</li>
<li>Predictors 4-6 are correlated with 1-3</li>
<li>Predictors 7-20 have coefficient 0</li>
</ul></li>
<li><p>Fit OLS, ridge, and lasso. Compare the coefficient estimates to the true values.</p></li>
<li><p>Generate a test set and compare prediction performance.</p></li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise Reg.2: Choosing Alpha
</div>
</div>
<div class="callout-body-container callout-body">
<ol start="4" type="1">
<li><p>For the data above, use cross-validation to select the optimal mixing parameter <span class="math inline">\(\alpha\)</span> for elastic net. Try <span class="math inline">\(\alpha \in \{0, 0.25, 0.5, 0.75, 1\}\)</span>.</p></li>
<li><p>Does the optimal <span class="math inline">\(\alpha\)</span> match what you would expect given the correlation structure?</p></li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise Reg.3: High-Dimensional Classification
</div>
</div>
<div class="callout-body-container callout-body">
<ol start="6" type="1">
<li><p>Load a gene expression dataset with many more genes than samples. Use regularized logistic regression to build a classifier.</p></li>
<li><p>Compare the number of genes selected by lasso at <code>lambda.min</code> vs <code>lambda.1se</code>. Which would you prefer in practice?</p></li>
</ol>
</div>
</div>
</section>
<section id="summary" class="level2" data-number="32.13">
<h2 data-number="32.13" class="anchored" data-anchor-id="summary"><span class="header-section-number">32.13</span> Summary</h2>
<p>This chapter introduced <strong>regularization</strong> as a powerful technique for preventing overfitting, especially when the number of predictors is large relative to the sample size. The core idea is to add a penalty term that shrinks coefficients toward zero, trading a small increase in bias for a substantial reduction in variance.</p>
<p><strong>Ridge regression</strong> uses an L2 penalty (sum of squared coefficients) that shrinks all coefficients toward zero but never exactly to zero. This makes ridge ideal when all predictors may be relevant and particularly effective for handling multicollinearity. <strong>Lasso regression</strong> uses an L1 penalty (sum of absolute values) that can shrink coefficients exactly to zero, automatically performing variable selection. The resulting sparse models are easier to interpret, though lasso can behave arbitrarily with correlated predictors. <strong>Elastic net</strong> combines both penalties, offering the variable selection of lasso with the stability of ridge for correlated predictors.</p>
<p>The regularization parameter <span class="math inline">\(\lambda\)</span> controls the penalty strength and is typically selected by <strong>cross-validation</strong>. The <code>lambda.min</code> value minimizes cross-validation error, while the <code>lambda.1se</code> (one standard error rule) often provides a more parsimonious model with nearly equivalent performance.</p>
<p><strong>Standardization</strong> of predictors is essential before applying regularization, since the penalty treats all coefficients equally and would otherwise unfairly penalize variables measured on larger scales. Finally, regularization extends naturally beyond regression to classification problems through regularized logistic regression and other generalized linear models.</p>
</section>
<section id="additional-resources" class="level2" data-number="32.14">
<h2 data-number="32.14" class="anchored" data-anchor-id="additional-resources"><span class="header-section-number">32.14</span> Additional Resources</h2>
<ul>
<li><span class="citation" data-cites="james2023islr">James et al. (<a href="../references.html#ref-james2023islr" role="doc-biblioref">2023</a>)</span> - Detailed treatment of regularization methods</li>
<li><span class="citation" data-cites="hastie2009elements">Hastie, Tibshirani, and Friedman (<a href="../references.html#ref-hastie2009elements" role="doc-biblioref">2009</a>)</span> - Theoretical foundations</li>
<li><code>glmnet</code> package vignette - Practical implementation details</li>
<li><span class="citation" data-cites="tibshirani1996regression">Tibshirani (<a href="../references.html#ref-tibshirani1996regression" role="doc-biblioref">1996</a>)</span> - Original lasso paper</li>
</ul>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-hastie2009elements" class="csl-entry" role="listitem">
Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>. 2nd ed. New York: Springer.
</div>
<div id="ref-hoerl1970ridge" class="csl-entry" role="listitem">
Hoerl, Arthur E., and Robert W. Kennard. 1970. <span>“Ridge Regression: Biased Estimation for Nonorthogonal Problems.”</span> <em>Technometrics</em> 12 (1): 55–67.
</div>
<div id="ref-james2023islr" class="csl-entry" role="listitem">
James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2023. <em>An Introduction to Statistical Learning with Applications in r</em>. 2nd ed. Springer. <a href="https://www.statlearning.com">https://www.statlearning.com</a>.
</div>
<div id="ref-tibshirani1996regression" class="csl-entry" role="listitem">
Tibshirani, Robert. 1996. <span>“Regression Shrinkage and Selection via the Lasso.”</span> <em>Journal of the Royal Statistical Society: Series B (Methodological)</em> 58 (1): 267–88.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/30-model-validation.html" class="pagination-link" aria-label="Model Validation and the Bias-Variance Tradeoff">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Model Validation and the Bias-Variance Tradeoff</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/32-smoothing.html" class="pagination-link" aria-label="Smoothing and Non-Parametric Regression">
        <span class="nav-page-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Smoothing and Non-Parametric Regression</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb48" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Regularization Methods {#sec-regularization}</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_minimal</span>())</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Need for Regularization</span></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>Standard linear regression estimates coefficients by minimizing the residual sum of squares (RSS):</span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a>$$\text{RSS} = \sum_{i=1}^n \left(y_i - \beta_0 - \sum_{j=1}^p \beta_j x_{ij}\right)^2$$</span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a>This works well when you have many more observations than predictors ($n \gg p$) and the predictors are not highly correlated. But problems arise in several common situations.</span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-21"><a href="#cb48-21" aria-hidden="true" tabindex="-1"></a>When you have **many predictors** relative to the number of observations, coefficient estimates become unstable and their variance is high. The model has too many degrees of freedom to estimate reliably from the available data. When predictors are **highly correlated** (multicollinearity), the problem is compounded: small changes in the data can cause dramatic swings in the estimated coefficients, even though predictions remain stable. In either case, the result is often **overfitting**—the model fits the training data well but predicts poorly on new observations.</span>
<span id="cb48-22"><a href="#cb48-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-23"><a href="#cb48-23" aria-hidden="true" tabindex="-1"></a>**Regularization** addresses these issues by adding a penalty term that shrinks coefficients toward zero. This intentionally introduces a small amount of bias in exchange for a substantial reduction in variance. The net effect is usually better predictions on new data, especially when the number of predictors is large relative to the sample size.</span>
<span id="cb48-24"><a href="#cb48-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-25"><a href="#cb48-25" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Regularization Idea</span></span>
<span id="cb48-26"><a href="#cb48-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-27"><a href="#cb48-27" aria-hidden="true" tabindex="-1"></a>Regularized regression minimizes a modified objective:</span>
<span id="cb48-28"><a href="#cb48-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-29"><a href="#cb48-29" aria-hidden="true" tabindex="-1"></a>$$\text{Minimize: } \text{RSS} + \lambda \cdot P(\beta)$$</span>
<span id="cb48-30"><a href="#cb48-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-31"><a href="#cb48-31" aria-hidden="true" tabindex="-1"></a>In this formulation, $P(\beta)$ is a **penalty function** that penalizes large coefficients, and $\lambda \geq 0$ is the **regularization parameter** that controls the strength of the penalty.</span>
<span id="cb48-32"><a href="#cb48-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-33"><a href="#cb48-33" aria-hidden="true" tabindex="-1"></a>The effect of the penalty is to shrink coefficients toward zero, with $\lambda$ controlling how aggressively. When $\lambda = 0$, there is no penalty and we recover ordinary least squares. As $\lambda$ increases, the penalty becomes stronger and coefficients shrink more. In the limit as $\lambda \to \infty$, all coefficients are forced to zero.</span>
<span id="cb48-34"><a href="#cb48-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-35"><a href="#cb48-35" aria-hidden="true" tabindex="-1"></a>Different choices of the penalty function $P(\beta)$ lead to different regularization methods, each with distinct properties and use cases.</span>
<span id="cb48-36"><a href="#cb48-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-37"><a href="#cb48-37" aria-hidden="true" tabindex="-1"></a><span class="fu">## Ridge Regression (L2 Penalty)</span></span>
<span id="cb48-38"><a href="#cb48-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-39"><a href="#cb48-39" aria-hidden="true" tabindex="-1"></a>**Ridge regression** <span class="co">[</span><span class="ot">@hoerl1970ridge</span><span class="co">]</span> uses the sum of squared coefficients as the penalty:</span>
<span id="cb48-40"><a href="#cb48-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-41"><a href="#cb48-41" aria-hidden="true" tabindex="-1"></a>$$P(\beta) = \sum_{j=1}^p \beta_j^2$$</span>
<span id="cb48-42"><a href="#cb48-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-43"><a href="#cb48-43" aria-hidden="true" tabindex="-1"></a>The full optimization problem is:</span>
<span id="cb48-44"><a href="#cb48-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-45"><a href="#cb48-45" aria-hidden="true" tabindex="-1"></a>$$\hat{\beta}^{\text{ridge}} = \arg\min_\beta \left<span class="sc">\{</span> \sum_{i=1}^n \left(y_i - \beta_0 - \sum_{j=1}^p \beta_j x_{ij}\right)^2 + \lambda \sum_{j=1}^p \beta_j^2 \right<span class="sc">\}</span>$$</span>
<span id="cb48-46"><a href="#cb48-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-47"><a href="#cb48-47" aria-hidden="true" tabindex="-1"></a><span class="fu">### Properties of Ridge Regression</span></span>
<span id="cb48-48"><a href="#cb48-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-49"><a href="#cb48-49" aria-hidden="true" tabindex="-1"></a>Ridge regression shrinks all coefficients toward zero but **never exactly to zero**. This means all predictors remain in the model regardless of how large $\lambda$ becomes—coefficients get very small but never vanish entirely. This property makes ridge regression particularly useful when you believe all predictors are relevant to some degree. It is also especially effective when predictors are highly correlated (multicollinearity), as the penalty stabilizes the coefficient estimates that would otherwise be wildly unstable in ordinary least squares.</span>
<span id="cb48-50"><a href="#cb48-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-53"><a href="#cb48-53" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb48-54"><a href="#cb48-54" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-ridge-path</span></span>
<span id="cb48-55"><a href="#cb48-55" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Ridge regression coefficient paths: as lambda increases, coefficients shrink toward zero but never reach exactly zero"</span></span>
<span id="cb48-56"><a href="#cb48-56" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb48-57"><a href="#cb48-57" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb48-58"><a href="#cb48-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate sample data with correlated predictors</span></span>
<span id="cb48-59"><a href="#cb48-59" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb48-60"><a href="#cb48-60" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb48-61"><a href="#cb48-61" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb48-62"><a href="#cb48-62" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n <span class="sc">*</span> p), n, p)</span>
<span id="cb48-63"><a href="#cb48-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Create correlated predictors</span></span>
<span id="cb48-64"><a href="#cb48-64" aria-hidden="true" tabindex="-1"></a>X[, <span class="dv">2</span>] <span class="ot">&lt;-</span> X[, <span class="dv">1</span>] <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> <span class="fl">0.5</span>)</span>
<span id="cb48-65"><a href="#cb48-65" aria-hidden="true" tabindex="-1"></a>X[, <span class="dv">3</span>] <span class="ot">&lt;-</span> X[, <span class="dv">1</span>] <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> <span class="fl">0.5</span>)</span>
<span id="cb48-66"><a href="#cb48-66" aria-hidden="true" tabindex="-1"></a>true_beta <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="fl">1.5</span>, <span class="fu">rep</span>(<span class="dv">0</span>, p <span class="sc">-</span> <span class="dv">3</span>))</span>
<span id="cb48-67"><a href="#cb48-67" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> X <span class="sc">%*%</span> true_beta <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb48-68"><a href="#cb48-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-69"><a href="#cb48-69" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit ridge regression across lambda values</span></span>
<span id="cb48-70"><a href="#cb48-70" aria-hidden="true" tabindex="-1"></a>ridge_fit <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, y, <span class="at">alpha =</span> <span class="dv">0</span>)  <span class="co"># alpha = 0 for ridge</span></span>
<span id="cb48-71"><a href="#cb48-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-72"><a href="#cb48-72" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot coefficient paths</span></span>
<span id="cb48-73"><a href="#cb48-73" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ridge_fit, <span class="at">xvar =</span> <span class="st">"lambda"</span>, <span class="at">main =</span> <span class="st">"Ridge Regression Coefficients"</span>)</span>
<span id="cb48-74"><a href="#cb48-74" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb48-75"><a href="#cb48-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-76"><a href="#cb48-76" aria-hidden="true" tabindex="-1"></a><span class="fu">### Geometric Interpretation</span></span>
<span id="cb48-77"><a href="#cb48-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-78"><a href="#cb48-78" aria-hidden="true" tabindex="-1"></a>Ridge regression constrains coefficients to lie within a sphere (in 2D, a circle) centered at the origin:</span>
<span id="cb48-79"><a href="#cb48-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-80"><a href="#cb48-80" aria-hidden="true" tabindex="-1"></a>$$\sum_{j=1}^p \beta_j^2 \leq t$$</span>
<span id="cb48-81"><a href="#cb48-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-82"><a href="#cb48-82" aria-hidden="true" tabindex="-1"></a>where $t$ is inversely related to $\lambda$. The OLS solution may lie outside this constraint region, so ridge finds the point where the RSS contours first touch the constraint boundary.</span>
<span id="cb48-83"><a href="#cb48-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-86"><a href="#cb48-86" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb48-87"><a href="#cb48-87" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-ridge-geometry</span></span>
<span id="cb48-88"><a href="#cb48-88" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Geometric interpretation of ridge regression: the constraint region is circular, so the solution rarely lies exactly on an axis (coefficient rarely zero)"</span></span>
<span id="cb48-89"><a href="#cb48-89" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 6</span></span>
<span id="cb48-90"><a href="#cb48-90" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 6</span></span>
<span id="cb48-91"><a href="#cb48-91" aria-hidden="true" tabindex="-1"></a><span class="co"># Geometric illustration</span></span>
<span id="cb48-92"><a href="#cb48-92" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">2</span><span class="sc">*</span>pi, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb48-93"><a href="#cb48-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-94"><a href="#cb48-94" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">cos</span>(theta), <span class="fu">sin</span>(theta), <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"blue"</span>,</span>
<span id="cb48-95"><a href="#cb48-95" aria-hidden="true" tabindex="-1"></a>     <span class="at">asp =</span> <span class="dv">1</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>),</span>
<span id="cb48-96"><a href="#cb48-96" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>]), <span class="at">ylab =</span> <span class="fu">expression</span>(beta[<span class="dv">2</span>]),</span>
<span id="cb48-97"><a href="#cb48-97" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Ridge Constraint Region"</span>)</span>
<span id="cb48-98"><a href="#cb48-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-99"><a href="#cb48-99" aria-hidden="true" tabindex="-1"></a><span class="co"># Add contours representing RSS</span></span>
<span id="cb48-100"><a href="#cb48-100" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (r <span class="cf">in</span> <span class="fu">seq</span>(<span class="fl">0.3</span>, <span class="fl">1.5</span>, <span class="fl">0.3</span>)) {</span>
<span id="cb48-101"><a href="#cb48-101" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(r <span class="sc">*</span> <span class="fu">cos</span>(theta) <span class="sc">+</span> <span class="fl">0.8</span>, r <span class="sc">*</span> <span class="fu">sin</span>(theta) <span class="sc">+</span> <span class="fl">0.6</span>,</span>
<span id="cb48-102"><a href="#cb48-102" aria-hidden="true" tabindex="-1"></a>        <span class="at">col =</span> <span class="st">"gray"</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb48-103"><a href="#cb48-103" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb48-104"><a href="#cb48-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-105"><a href="#cb48-105" aria-hidden="true" tabindex="-1"></a><span class="co"># OLS estimate</span></span>
<span id="cb48-106"><a href="#cb48-106" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fl">0.8</span>, <span class="fl">0.6</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb48-107"><a href="#cb48-107" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.8</span>, <span class="fl">0.75</span>, <span class="st">"OLS"</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb48-108"><a href="#cb48-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-109"><a href="#cb48-109" aria-hidden="true" tabindex="-1"></a><span class="co"># Ridge estimate (on boundary)</span></span>
<span id="cb48-110"><a href="#cb48-110" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fl">0.5</span>, <span class="fl">0.37</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb48-111"><a href="#cb48-111" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="st">"Ridge"</span>, <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb48-112"><a href="#cb48-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-113"><a href="#cb48-113" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"bottomleft"</span>, <span class="fu">c</span>(<span class="st">"Constraint region"</span>, <span class="st">"RSS contours"</span>),</span>
<span id="cb48-114"><a href="#cb48-114" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"gray"</span>), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">lwd =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>))</span>
<span id="cb48-115"><a href="#cb48-115" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb48-116"><a href="#cb48-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-117"><a href="#cb48-117" aria-hidden="true" tabindex="-1"></a><span class="fu">## Lasso Regression (L1 Penalty)</span></span>
<span id="cb48-118"><a href="#cb48-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-119"><a href="#cb48-119" aria-hidden="true" tabindex="-1"></a>**Lasso** (Least Absolute Shrinkage and Selection Operator) <span class="co">[</span><span class="ot">@tibshirani1996regression</span><span class="co">]</span> uses the sum of absolute values as the penalty:</span>
<span id="cb48-120"><a href="#cb48-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-121"><a href="#cb48-121" aria-hidden="true" tabindex="-1"></a>$$P(\beta) = \sum_{j=1}^p |\beta_j|$$</span>
<span id="cb48-122"><a href="#cb48-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-123"><a href="#cb48-123" aria-hidden="true" tabindex="-1"></a>The optimization problem is:</span>
<span id="cb48-124"><a href="#cb48-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-125"><a href="#cb48-125" aria-hidden="true" tabindex="-1"></a>$$\hat{\beta}^{\text{lasso}} = \arg\min_\beta \left<span class="sc">\{</span> \sum_{i=1}^n \left(y_i - \beta_0 - \sum_{j=1}^p \beta_j x_{ij}\right)^2 + \lambda \sum_{j=1}^p |\beta_j| \right<span class="sc">\}</span>$$</span>
<span id="cb48-126"><a href="#cb48-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-127"><a href="#cb48-127" aria-hidden="true" tabindex="-1"></a><span class="fu">### Properties of Lasso Regression</span></span>
<span id="cb48-128"><a href="#cb48-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-129"><a href="#cb48-129" aria-hidden="true" tabindex="-1"></a>Unlike ridge, lasso can shrink coefficients **exactly to zero**, effectively performing **variable selection**. This produces **sparse models** with fewer predictors, making the resulting models easier to interpret since they explicitly identify which variables are "important." However, lasso may struggle when predictors are highly correlated—in such cases, it tends to select one predictor from a correlated group arbitrarily while setting the others to zero, rather than distributing the effect among them as ridge would.</span>
<span id="cb48-130"><a href="#cb48-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-133"><a href="#cb48-133" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb48-134"><a href="#cb48-134" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-lasso-path</span></span>
<span id="cb48-135"><a href="#cb48-135" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Lasso regression coefficient paths: as lambda increases, coefficients shrink and some become exactly zero (variable selection)"</span></span>
<span id="cb48-136"><a href="#cb48-136" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb48-137"><a href="#cb48-137" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb48-138"><a href="#cb48-138" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit lasso regression</span></span>
<span id="cb48-139"><a href="#cb48-139" aria-hidden="true" tabindex="-1"></a>lasso_fit <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, y, <span class="at">alpha =</span> <span class="dv">1</span>)  <span class="co"># alpha = 1 for lasso</span></span>
<span id="cb48-140"><a href="#cb48-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-141"><a href="#cb48-141" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lasso_fit, <span class="at">xvar =</span> <span class="st">"lambda"</span>, <span class="at">main =</span> <span class="st">"Lasso Regression Coefficients"</span>)</span>
<span id="cb48-142"><a href="#cb48-142" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb48-143"><a href="#cb48-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-144"><a href="#cb48-144" aria-hidden="true" tabindex="-1"></a><span class="fu">### Geometric Interpretation</span></span>
<span id="cb48-145"><a href="#cb48-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-146"><a href="#cb48-146" aria-hidden="true" tabindex="-1"></a>Lasso constrains coefficients to lie within a diamond (in 2D, an L1 ball):</span>
<span id="cb48-147"><a href="#cb48-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-148"><a href="#cb48-148" aria-hidden="true" tabindex="-1"></a>$$\sum_{j=1}^p |\beta_j| \leq t$$</span>
<span id="cb48-149"><a href="#cb48-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-150"><a href="#cb48-150" aria-hidden="true" tabindex="-1"></a>The diamond has corners on the axes, so the RSS contours often touch the constraint at a corner, forcing some coefficients to exactly zero.</span>
<span id="cb48-151"><a href="#cb48-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-154"><a href="#cb48-154" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb48-155"><a href="#cb48-155" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-lasso-geometry</span></span>
<span id="cb48-156"><a href="#cb48-156" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Geometric interpretation of lasso: the constraint region has corners on the axes, so the solution often lies at a corner where one or more coefficients are exactly zero"</span></span>
<span id="cb48-157"><a href="#cb48-157" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 6</span></span>
<span id="cb48-158"><a href="#cb48-158" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 6</span></span>
<span id="cb48-159"><a href="#cb48-159" aria-hidden="true" tabindex="-1"></a><span class="co"># Diamond constraint</span></span>
<span id="cb48-160"><a href="#cb48-160" aria-hidden="true" tabindex="-1"></a>diamond_x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb48-161"><a href="#cb48-161" aria-hidden="true" tabindex="-1"></a>diamond_y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb48-162"><a href="#cb48-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-163"><a href="#cb48-163" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(diamond_x, diamond_y, <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"blue"</span>,</span>
<span id="cb48-164"><a href="#cb48-164" aria-hidden="true" tabindex="-1"></a>     <span class="at">asp =</span> <span class="dv">1</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>),</span>
<span id="cb48-165"><a href="#cb48-165" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>]), <span class="at">ylab =</span> <span class="fu">expression</span>(beta[<span class="dv">2</span>]),</span>
<span id="cb48-166"><a href="#cb48-166" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Lasso Constraint Region"</span>)</span>
<span id="cb48-167"><a href="#cb48-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-168"><a href="#cb48-168" aria-hidden="true" tabindex="-1"></a><span class="co"># Add contours</span></span>
<span id="cb48-169"><a href="#cb48-169" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (r <span class="cf">in</span> <span class="fu">seq</span>(<span class="fl">0.3</span>, <span class="fl">1.5</span>, <span class="fl">0.3</span>)) {</span>
<span id="cb48-170"><a href="#cb48-170" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(r <span class="sc">*</span> <span class="fu">cos</span>(theta) <span class="sc">+</span> <span class="fl">0.8</span>, r <span class="sc">*</span> <span class="fu">sin</span>(theta) <span class="sc">+</span> <span class="fl">0.6</span>,</span>
<span id="cb48-171"><a href="#cb48-171" aria-hidden="true" tabindex="-1"></a>        <span class="at">col =</span> <span class="st">"gray"</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb48-172"><a href="#cb48-172" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb48-173"><a href="#cb48-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-174"><a href="#cb48-174" aria-hidden="true" tabindex="-1"></a><span class="co"># OLS estimate</span></span>
<span id="cb48-175"><a href="#cb48-175" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fl">0.8</span>, <span class="fl">0.6</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb48-176"><a href="#cb48-176" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.8</span>, <span class="fl">0.75</span>, <span class="st">"OLS"</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb48-177"><a href="#cb48-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-178"><a href="#cb48-178" aria-hidden="true" tabindex="-1"></a><span class="co"># Lasso estimate (at corner)</span></span>
<span id="cb48-179"><a href="#cb48-179" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fl">0.7</span>, <span class="dv">0</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb48-180"><a href="#cb48-180" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.7</span>, <span class="fl">0.15</span>, <span class="st">"Lasso"</span>, <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb48-181"><a href="#cb48-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-182"><a href="#cb48-182" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"bottomleft"</span>, <span class="fu">c</span>(<span class="st">"Constraint region"</span>, <span class="st">"RSS contours"</span>),</span>
<span id="cb48-183"><a href="#cb48-183" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"gray"</span>), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">lwd =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>))</span>
<span id="cb48-184"><a href="#cb48-184" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb48-185"><a href="#cb48-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-186"><a href="#cb48-186" aria-hidden="true" tabindex="-1"></a><span class="fu">## Elastic Net: Combining Ridge and Lasso</span></span>
<span id="cb48-187"><a href="#cb48-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-188"><a href="#cb48-188" aria-hidden="true" tabindex="-1"></a>**Elastic net** combines both penalties:</span>
<span id="cb48-189"><a href="#cb48-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-190"><a href="#cb48-190" aria-hidden="true" tabindex="-1"></a>$$P(\beta) = \alpha \sum_{j=1}^p |\beta_j| + (1-\alpha) \sum_{j=1}^p \beta_j^2$$</span>
<span id="cb48-191"><a href="#cb48-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-192"><a href="#cb48-192" aria-hidden="true" tabindex="-1"></a>The mixing parameter $\alpha$ controls the balance between the two penalties. When $\alpha = 0$, elastic net reduces to pure ridge regression. When $\alpha = 1$, it becomes pure lasso. Values between 0 and 1 give a combination of both penalties, often with $\alpha = 0.5$ as a natural starting point.</span>
<span id="cb48-193"><a href="#cb48-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-194"><a href="#cb48-194" aria-hidden="true" tabindex="-1"></a>Elastic net is often preferred when predictors are correlated. Unlike lasso, which arbitrarily selects one variable from a correlated group, elastic net tends to select groups of correlated variables together. This behavior often produces more stable and interpretable models when the underlying science suggests that correlated predictors genuinely contribute to the outcome.</span>
<span id="cb48-195"><a href="#cb48-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-198"><a href="#cb48-198" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb48-199"><a href="#cb48-199" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-elastic-net</span></span>
<span id="cb48-200"><a href="#cb48-200" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Elastic net coefficient paths with alpha = 0.5 (equal mix of L1 and L2 penalties)"</span></span>
<span id="cb48-201"><a href="#cb48-201" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb48-202"><a href="#cb48-202" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb48-203"><a href="#cb48-203" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit elastic net</span></span>
<span id="cb48-204"><a href="#cb48-204" aria-hidden="true" tabindex="-1"></a>enet_fit <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, y, <span class="at">alpha =</span> <span class="fl">0.5</span>)</span>
<span id="cb48-205"><a href="#cb48-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-206"><a href="#cb48-206" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(enet_fit, <span class="at">xvar =</span> <span class="st">"lambda"</span>, <span class="at">main =</span> <span class="st">"Elastic Net Coefficients (α = 0.5)"</span>)</span>
<span id="cb48-207"><a href="#cb48-207" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb48-208"><a href="#cb48-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-211"><a href="#cb48-211" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb48-212"><a href="#cb48-212" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-enet-geometry</span></span>
<span id="cb48-213"><a href="#cb48-213" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Elastic net constraint region: intermediate between ridge (circle) and lasso (diamond)"</span></span>
<span id="cb48-214"><a href="#cb48-214" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb48-215"><a href="#cb48-215" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 4</span></span>
<span id="cb48-216"><a href="#cb48-216" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb48-217"><a href="#cb48-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-218"><a href="#cb48-218" aria-hidden="true" tabindex="-1"></a><span class="co"># Ridge</span></span>
<span id="cb48-219"><a href="#cb48-219" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">cos</span>(theta), <span class="fu">sin</span>(theta), <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"blue"</span>,</span>
<span id="cb48-220"><a href="#cb48-220" aria-hidden="true" tabindex="-1"></a>     <span class="at">asp =</span> <span class="dv">1</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.2</span>, <span class="fl">1.2</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.2</span>, <span class="fl">1.2</span>),</span>
<span id="cb48-221"><a href="#cb48-221" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>]), <span class="at">ylab =</span> <span class="fu">expression</span>(beta[<span class="dv">2</span>]),</span>
<span id="cb48-222"><a href="#cb48-222" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Ridge (α = 0)"</span>)</span>
<span id="cb48-223"><a href="#cb48-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-224"><a href="#cb48-224" aria-hidden="true" tabindex="-1"></a><span class="co"># Elastic net</span></span>
<span id="cb48-225"><a href="#cb48-225" aria-hidden="true" tabindex="-1"></a>alpha_en <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb48-226"><a href="#cb48-226" aria-hidden="true" tabindex="-1"></a>en_x <span class="ot">&lt;-</span> en_y <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="dv">100</span>)</span>
<span id="cb48-227"><a href="#cb48-227" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>) {</span>
<span id="cb48-228"><a href="#cb48-228" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Approximate elastic net constraint boundary</span></span>
<span id="cb48-229"><a href="#cb48-229" aria-hidden="true" tabindex="-1"></a>  ang <span class="ot">&lt;-</span> theta[i]</span>
<span id="cb48-230"><a href="#cb48-230" aria-hidden="true" tabindex="-1"></a>  r <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> (alpha_en <span class="sc">*</span> (<span class="fu">abs</span>(<span class="fu">cos</span>(ang)) <span class="sc">+</span> <span class="fu">abs</span>(<span class="fu">sin</span>(ang))) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">-</span> alpha_en))</span>
<span id="cb48-231"><a href="#cb48-231" aria-hidden="true" tabindex="-1"></a>  en_x[i] <span class="ot">&lt;-</span> r <span class="sc">*</span> <span class="fu">cos</span>(ang)</span>
<span id="cb48-232"><a href="#cb48-232" aria-hidden="true" tabindex="-1"></a>  en_y[i] <span class="ot">&lt;-</span> r <span class="sc">*</span> <span class="fu">sin</span>(ang)</span>
<span id="cb48-233"><a href="#cb48-233" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb48-234"><a href="#cb48-234" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(en_x, en_y, <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"purple"</span>,</span>
<span id="cb48-235"><a href="#cb48-235" aria-hidden="true" tabindex="-1"></a>     <span class="at">asp =</span> <span class="dv">1</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.2</span>, <span class="fl">1.2</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.2</span>, <span class="fl">1.2</span>),</span>
<span id="cb48-236"><a href="#cb48-236" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>]), <span class="at">ylab =</span> <span class="fu">expression</span>(beta[<span class="dv">2</span>]),</span>
<span id="cb48-237"><a href="#cb48-237" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Elastic Net (α = 0.5)"</span>)</span>
<span id="cb48-238"><a href="#cb48-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-239"><a href="#cb48-239" aria-hidden="true" tabindex="-1"></a><span class="co"># Lasso</span></span>
<span id="cb48-240"><a href="#cb48-240" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(diamond_x, diamond_y, <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"red"</span>,</span>
<span id="cb48-241"><a href="#cb48-241" aria-hidden="true" tabindex="-1"></a>     <span class="at">asp =</span> <span class="dv">1</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.2</span>, <span class="fl">1.2</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.2</span>, <span class="fl">1.2</span>),</span>
<span id="cb48-242"><a href="#cb48-242" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>]), <span class="at">ylab =</span> <span class="fu">expression</span>(beta[<span class="dv">2</span>]),</span>
<span id="cb48-243"><a href="#cb48-243" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Lasso (α = 1)"</span>)</span>
<span id="cb48-244"><a href="#cb48-244" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb48-245"><a href="#cb48-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-246"><a href="#cb48-246" aria-hidden="true" tabindex="-1"></a><span class="fu">## Choosing Lambda with Cross-Validation</span></span>
<span id="cb48-247"><a href="#cb48-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-248"><a href="#cb48-248" aria-hidden="true" tabindex="-1"></a>The regularization parameter $\lambda$ is typically chosen by cross-validation:</span>
<span id="cb48-249"><a href="#cb48-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-252"><a href="#cb48-252" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb48-253"><a href="#cb48-253" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-cv-lambda</span></span>
<span id="cb48-254"><a href="#cb48-254" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Cross-validation to select optimal lambda: the left dashed line marks the minimum error, the right marks the most regularized model within one standard error"</span></span>
<span id="cb48-255"><a href="#cb48-255" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb48-256"><a href="#cb48-256" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb48-257"><a href="#cb48-257" aria-hidden="true" tabindex="-1"></a><span class="co"># Cross-validation for lasso</span></span>
<span id="cb48-258"><a href="#cb48-258" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb48-259"><a href="#cb48-259" aria-hidden="true" tabindex="-1"></a>cv_lasso <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X, y, <span class="at">alpha =</span> <span class="dv">1</span>)</span>
<span id="cb48-260"><a href="#cb48-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-261"><a href="#cb48-261" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot cross-validation results</span></span>
<span id="cb48-262"><a href="#cb48-262" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv_lasso)</span>
<span id="cb48-263"><a href="#cb48-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-264"><a href="#cb48-264" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimal lambda values</span></span>
<span id="cb48-265"><a href="#cb48-265" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Lambda with minimum CV error:"</span>, <span class="fu">round</span>(cv_lasso<span class="sc">$</span>lambda.min, <span class="dv">4</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb48-266"><a href="#cb48-266" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Lambda within 1 SE of minimum:"</span>, <span class="fu">round</span>(cv_lasso<span class="sc">$</span>lambda<span class="fl">.1</span>se, <span class="dv">4</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb48-267"><a href="#cb48-267" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb48-268"><a href="#cb48-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-269"><a href="#cb48-269" aria-hidden="true" tabindex="-1"></a>The <span class="in">`lambda.1se`</span> (one standard error rule) often provides a more parsimonious model with nearly as good performance as the minimum.</span>
<span id="cb48-270"><a href="#cb48-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-271"><a href="#cb48-271" aria-hidden="true" tabindex="-1"></a><span class="fu">### Extracting Coefficients</span></span>
<span id="cb48-272"><a href="#cb48-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-275"><a href="#cb48-275" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb48-276"><a href="#cb48-276" aria-hidden="true" tabindex="-1"></a><span class="co"># Coefficients at different lambda values</span></span>
<span id="cb48-277"><a href="#cb48-277" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Coefficients at lambda.min:</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb48-278"><a href="#cb48-278" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(cv_lasso, <span class="at">s =</span> <span class="st">"lambda.min"</span>)</span>
<span id="cb48-279"><a href="#cb48-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-280"><a href="#cb48-280" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Coefficients at lambda.1se:</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb48-281"><a href="#cb48-281" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(cv_lasso, <span class="at">s =</span> <span class="st">"lambda.1se"</span>)</span>
<span id="cb48-282"><a href="#cb48-282" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb48-283"><a href="#cb48-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-284"><a href="#cb48-284" aria-hidden="true" tabindex="-1"></a><span class="fu">## Comparing Regularization Methods</span></span>
<span id="cb48-285"><a href="#cb48-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-286"><a href="#cb48-286" aria-hidden="true" tabindex="-1"></a>Let's compare OLS, ridge, and lasso on the same data:</span>
<span id="cb48-287"><a href="#cb48-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-290"><a href="#cb48-290" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb48-291"><a href="#cb48-291" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit models with optimal lambda</span></span>
<span id="cb48-292"><a href="#cb48-292" aria-hidden="true" tabindex="-1"></a>ridge_cv <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X, y, <span class="at">alpha =</span> <span class="dv">0</span>)</span>
<span id="cb48-293"><a href="#cb48-293" aria-hidden="true" tabindex="-1"></a>lasso_cv <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X, y, <span class="at">alpha =</span> <span class="dv">1</span>)</span>
<span id="cb48-294"><a href="#cb48-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-295"><a href="#cb48-295" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract coefficients</span></span>
<span id="cb48-296"><a href="#cb48-296" aria-hidden="true" tabindex="-1"></a>coef_ols <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(y <span class="sc">~</span> X))</span>
<span id="cb48-297"><a href="#cb48-297" aria-hidden="true" tabindex="-1"></a>coef_ridge <span class="ot">&lt;-</span> <span class="fu">coef</span>(ridge_cv, <span class="at">s =</span> <span class="st">"lambda.1se"</span>)</span>
<span id="cb48-298"><a href="#cb48-298" aria-hidden="true" tabindex="-1"></a>coef_lasso <span class="ot">&lt;-</span> <span class="fu">coef</span>(lasso_cv, <span class="at">s =</span> <span class="st">"lambda.1se"</span>)</span>
<span id="cb48-299"><a href="#cb48-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-300"><a href="#cb48-300" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare (excluding intercept)</span></span>
<span id="cb48-301"><a href="#cb48-301" aria-hidden="true" tabindex="-1"></a>comparison <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb48-302"><a href="#cb48-302" aria-hidden="true" tabindex="-1"></a>  <span class="at">True =</span> <span class="fu">c</span>(<span class="cn">NA</span>, true_beta),</span>
<span id="cb48-303"><a href="#cb48-303" aria-hidden="true" tabindex="-1"></a>  <span class="at">OLS =</span> <span class="fu">as.vector</span>(coef_ols),</span>
<span id="cb48-304"><a href="#cb48-304" aria-hidden="true" tabindex="-1"></a>  <span class="at">Ridge =</span> <span class="fu">as.vector</span>(coef_ridge),</span>
<span id="cb48-305"><a href="#cb48-305" aria-hidden="true" tabindex="-1"></a>  <span class="at">Lasso =</span> <span class="fu">as.vector</span>(coef_lasso)</span>
<span id="cb48-306"><a href="#cb48-306" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb48-307"><a href="#cb48-307" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(comparison) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Intercept"</span>, <span class="fu">paste0</span>(<span class="st">"X"</span>, <span class="dv">1</span><span class="sc">:</span>p))</span>
<span id="cb48-308"><a href="#cb48-308" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(comparison, <span class="dv">3</span>)</span>
<span id="cb48-309"><a href="#cb48-309" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb48-310"><a href="#cb48-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-311"><a href="#cb48-311" aria-hidden="true" tabindex="-1"></a>The comparison reveals the distinct behavior of each method. **OLS** estimates show high variance, especially for the variables whose true coefficients are zero—these spuriously appear nonzero due to fitting noise. **Ridge** shrinks all coefficients toward zero, reducing variance, but it doesn't eliminate any predictors from the model. **Lasso** strikes a different balance: it correctly identifies many of the zero coefficients and sets them exactly to zero, producing a sparse model that more closely matches the true data-generating process.</span>
<span id="cb48-312"><a href="#cb48-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-313"><a href="#cb48-313" aria-hidden="true" tabindex="-1"></a><span class="fu">## Visualizing the Comparison</span></span>
<span id="cb48-314"><a href="#cb48-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-317"><a href="#cb48-317" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb48-318"><a href="#cb48-318" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-method-comparison</span></span>
<span id="cb48-319"><a href="#cb48-319" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Comparison of coefficient estimates: true values, OLS, ridge, and lasso. Lasso successfully identifies zero coefficients while ridge shrinks but retains all."</span></span>
<span id="cb48-320"><a href="#cb48-320" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 9</span></span>
<span id="cb48-321"><a href="#cb48-321" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb48-322"><a href="#cb48-322" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot comparison</span></span>
<span id="cb48-323"><a href="#cb48-323" aria-hidden="true" tabindex="-1"></a>var_names <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"X"</span>, <span class="dv">1</span><span class="sc">:</span>p)</span>
<span id="cb48-324"><a href="#cb48-324" aria-hidden="true" tabindex="-1"></a>coef_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb48-325"><a href="#cb48-325" aria-hidden="true" tabindex="-1"></a>  <span class="at">Variable =</span> <span class="fu">rep</span>(var_names, <span class="dv">4</span>),</span>
<span id="cb48-326"><a href="#cb48-326" aria-hidden="true" tabindex="-1"></a>  <span class="at">Method =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"True"</span>, <span class="st">"OLS"</span>, <span class="st">"Ridge"</span>, <span class="st">"Lasso"</span>), <span class="at">each =</span> p),</span>
<span id="cb48-327"><a href="#cb48-327" aria-hidden="true" tabindex="-1"></a>  <span class="at">Coefficient =</span> <span class="fu">c</span>(true_beta,</span>
<span id="cb48-328"><a href="#cb48-328" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">as.vector</span>(coef_ols)[<span class="sc">-</span><span class="dv">1</span>],</span>
<span id="cb48-329"><a href="#cb48-329" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">as.vector</span>(coef_ridge)[<span class="sc">-</span><span class="dv">1</span>],</span>
<span id="cb48-330"><a href="#cb48-330" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">as.vector</span>(coef_lasso)[<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb48-331"><a href="#cb48-331" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb48-332"><a href="#cb48-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-333"><a href="#cb48-333" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(coef_df, <span class="fu">aes</span>(<span class="at">x =</span> Variable, <span class="at">y =</span> Coefficient, <span class="at">fill =</span> Method)) <span class="sc">+</span></span>
<span id="cb48-334"><a href="#cb48-334" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="at">position =</span> <span class="st">"dodge"</span>) <span class="sc">+</span></span>
<span id="cb48-335"><a href="#cb48-335" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"True"</span> <span class="ot">=</span> <span class="st">"black"</span>, <span class="st">"OLS"</span> <span class="ot">=</span> <span class="st">"gray"</span>,</span>
<span id="cb48-336"><a href="#cb48-336" aria-hidden="true" tabindex="-1"></a>                               <span class="st">"Ridge"</span> <span class="ot">=</span> <span class="st">"steelblue"</span>, <span class="st">"Lasso"</span> <span class="ot">=</span> <span class="st">"coral"</span>)) <span class="sc">+</span></span>
<span id="cb48-337"><a href="#cb48-337" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">45</span>, <span class="at">hjust =</span> <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb48-338"><a href="#cb48-338" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Coefficient Estimates by Method"</span>)</span>
<span id="cb48-339"><a href="#cb48-339" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb48-340"><a href="#cb48-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-341"><a href="#cb48-341" aria-hidden="true" tabindex="-1"></a><span class="fu">## Prediction Performance</span></span>
<span id="cb48-342"><a href="#cb48-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-345"><a href="#cb48-345" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb48-346"><a href="#cb48-346" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate test data</span></span>
<span id="cb48-347"><a href="#cb48-347" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">999</span>)</span>
<span id="cb48-348"><a href="#cb48-348" aria-hidden="true" tabindex="-1"></a>X_test <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">50</span> <span class="sc">*</span> p), <span class="dv">50</span>, p)</span>
<span id="cb48-349"><a href="#cb48-349" aria-hidden="true" tabindex="-1"></a>X_test[, <span class="dv">2</span>] <span class="ot">&lt;-</span> X_test[, <span class="dv">1</span>] <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">50</span>, <span class="at">sd =</span> <span class="fl">0.5</span>)</span>
<span id="cb48-350"><a href="#cb48-350" aria-hidden="true" tabindex="-1"></a>X_test[, <span class="dv">3</span>] <span class="ot">&lt;-</span> X_test[, <span class="dv">1</span>] <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">50</span>, <span class="at">sd =</span> <span class="fl">0.5</span>)</span>
<span id="cb48-351"><a href="#cb48-351" aria-hidden="true" tabindex="-1"></a>y_test <span class="ot">&lt;-</span> X_test <span class="sc">%*%</span> true_beta <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">50</span>)</span>
<span id="cb48-352"><a href="#cb48-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-353"><a href="#cb48-353" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions</span></span>
<span id="cb48-354"><a href="#cb48-354" aria-hidden="true" tabindex="-1"></a>pred_ols <span class="ot">&lt;-</span> <span class="fu">predict</span>(<span class="fu">lm</span>(y <span class="sc">~</span> X), <span class="at">newdata =</span> <span class="fu">data.frame</span>(X_test))</span>
<span id="cb48-355"><a href="#cb48-355" aria-hidden="true" tabindex="-1"></a>pred_ridge <span class="ot">&lt;-</span> <span class="fu">predict</span>(ridge_cv, <span class="at">newx =</span> X_test, <span class="at">s =</span> <span class="st">"lambda.1se"</span>)</span>
<span id="cb48-356"><a href="#cb48-356" aria-hidden="true" tabindex="-1"></a>pred_lasso <span class="ot">&lt;-</span> <span class="fu">predict</span>(lasso_cv, <span class="at">newx =</span> X_test, <span class="at">s =</span> <span class="st">"lambda.1se"</span>)</span>
<span id="cb48-357"><a href="#cb48-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-358"><a href="#cb48-358" aria-hidden="true" tabindex="-1"></a><span class="co"># Test MSE</span></span>
<span id="cb48-359"><a href="#cb48-359" aria-hidden="true" tabindex="-1"></a>mse_ols <span class="ot">&lt;-</span> <span class="fu">mean</span>((y_test <span class="sc">-</span> pred_ols)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb48-360"><a href="#cb48-360" aria-hidden="true" tabindex="-1"></a>mse_ridge <span class="ot">&lt;-</span> <span class="fu">mean</span>((y_test <span class="sc">-</span> pred_ridge)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb48-361"><a href="#cb48-361" aria-hidden="true" tabindex="-1"></a>mse_lasso <span class="ot">&lt;-</span> <span class="fu">mean</span>((y_test <span class="sc">-</span> pred_lasso)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb48-362"><a href="#cb48-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-363"><a href="#cb48-363" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Test MSE:</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb48-364"><a href="#cb48-364" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"  OLS:"</span>, <span class="fu">round</span>(mse_ols, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb48-365"><a href="#cb48-365" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"  Ridge:"</span>, <span class="fu">round</span>(mse_ridge, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb48-366"><a href="#cb48-366" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"  Lasso:"</span>, <span class="fu">round</span>(mse_lasso, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb48-367"><a href="#cb48-367" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb48-368"><a href="#cb48-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-369"><a href="#cb48-369" aria-hidden="true" tabindex="-1"></a><span class="fu">## When to Use Each Method</span></span>
<span id="cb48-370"><a href="#cb48-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-371"><a href="#cb48-371" aria-hidden="true" tabindex="-1"></a>Choosing among regularization methods depends on your goals and the structure of your data.</span>
<span id="cb48-372"><a href="#cb48-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-373"><a href="#cb48-373" aria-hidden="true" tabindex="-1"></a>**Ridge regression** is the natural choice when you believe all predictors are genuinely relevant to the outcome, even if their individual effects are small. It is particularly effective when predictors are highly correlated, as the L2 penalty stabilizes coefficient estimates. Ridge tends to produce the most stable predictions, though the resulting model includes all variables, which may complicate interpretation.</span>
<span id="cb48-374"><a href="#cb48-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-375"><a href="#cb48-375" aria-hidden="true" tabindex="-1"></a>**Lasso** is preferred when you want automatic variable selection and believe only a subset of predictors are truly relevant. The resulting sparse models are easier to interpret and communicate, since they explicitly identify which variables matter. However, lasso can behave arbitrarily when predictors are correlated, selecting one while zeroing out others that may be equally important.</span>
<span id="cb48-376"><a href="#cb48-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-377"><a href="#cb48-377" aria-hidden="true" tabindex="-1"></a>**Elastic net** offers a middle ground that is often optimal in practice. Use it when predictors are correlated but you still want variable selection—elastic net tends to select groups of correlated variables together rather than making arbitrary choices. It's also a sensible default when you're unsure whether ridge or lasso is more appropriate, as cross-validation can select an optimal mixing parameter.</span>
<span id="cb48-378"><a href="#cb48-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-379"><a href="#cb48-379" aria-hidden="true" tabindex="-1"></a>One practical note: always standardize predictors before applying regularization, as the penalty treats all coefficients equally and would otherwise penalize variables on larger scales more heavily. The <span class="in">`glmnet`</span> function handles this automatically by default.</span>
<span id="cb48-380"><a href="#cb48-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-381"><a href="#cb48-381" aria-hidden="true" tabindex="-1"></a><span class="fu">## Regularization in Practice</span></span>
<span id="cb48-382"><a href="#cb48-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-383"><a href="#cb48-383" aria-hidden="true" tabindex="-1"></a><span class="fu">### High-Dimensional Data Example</span></span>
<span id="cb48-384"><a href="#cb48-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-385"><a href="#cb48-385" aria-hidden="true" tabindex="-1"></a>Regularization is especially valuable when $p$ approaches or exceeds $n$:</span>
<span id="cb48-386"><a href="#cb48-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-389"><a href="#cb48-389" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb48-390"><a href="#cb48-390" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-high-dim</span></span>
<span id="cb48-391"><a href="#cb48-391" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Regularization is essential for high-dimensional data where p ≈ n or p &gt; n"</span></span>
<span id="cb48-392"><a href="#cb48-392" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb48-393"><a href="#cb48-393" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb48-394"><a href="#cb48-394" aria-hidden="true" tabindex="-1"></a><span class="co"># High-dimensional example: p = 80, n = 100</span></span>
<span id="cb48-395"><a href="#cb48-395" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb48-396"><a href="#cb48-396" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb48-397"><a href="#cb48-397" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">80</span></span>
<span id="cb48-398"><a href="#cb48-398" aria-hidden="true" tabindex="-1"></a>X_hd <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n <span class="sc">*</span> p), n, p)</span>
<span id="cb48-399"><a href="#cb48-399" aria-hidden="true" tabindex="-1"></a><span class="co"># Sparse true model: only 5 predictors matter</span></span>
<span id="cb48-400"><a href="#cb48-400" aria-hidden="true" tabindex="-1"></a>true_beta_hd <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">2</span>, <span class="dv">5</span>), <span class="fu">rep</span>(<span class="dv">0</span>, p <span class="sc">-</span> <span class="dv">5</span>))</span>
<span id="cb48-401"><a href="#cb48-401" aria-hidden="true" tabindex="-1"></a>y_hd <span class="ot">&lt;-</span> X_hd <span class="sc">%*%</span> true_beta_hd <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb48-402"><a href="#cb48-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-403"><a href="#cb48-403" aria-hidden="true" tabindex="-1"></a><span class="co"># OLS fails (numerically unstable or overfits severely)</span></span>
<span id="cb48-404"><a href="#cb48-404" aria-hidden="true" tabindex="-1"></a><span class="co"># ols_hd &lt;- lm(y_hd ~ X_hd)  # Would have issues</span></span>
<span id="cb48-405"><a href="#cb48-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-406"><a href="#cb48-406" aria-hidden="true" tabindex="-1"></a><span class="co"># Lasso works</span></span>
<span id="cb48-407"><a href="#cb48-407" aria-hidden="true" tabindex="-1"></a>cv_lasso_hd <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X_hd, y_hd, <span class="at">alpha =</span> <span class="dv">1</span>)</span>
<span id="cb48-408"><a href="#cb48-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-409"><a href="#cb48-409" aria-hidden="true" tabindex="-1"></a><span class="co"># How many non-zero coefficients?</span></span>
<span id="cb48-410"><a href="#cb48-410" aria-hidden="true" tabindex="-1"></a>lasso_coef <span class="ot">&lt;-</span> <span class="fu">coef</span>(cv_lasso_hd, <span class="at">s =</span> <span class="st">"lambda.1se"</span>)</span>
<span id="cb48-411"><a href="#cb48-411" aria-hidden="true" tabindex="-1"></a>n_nonzero <span class="ot">&lt;-</span> <span class="fu">sum</span>(lasso_coef[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">!=</span> <span class="dv">0</span>)</span>
<span id="cb48-412"><a href="#cb48-412" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"True non-zero coefficients:"</span>, <span class="dv">5</span>, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb48-413"><a href="#cb48-413" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Lasso selected:"</span>, n_nonzero, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb48-414"><a href="#cb48-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-415"><a href="#cb48-415" aria-hidden="true" tabindex="-1"></a><span class="co"># Which variables selected?</span></span>
<span id="cb48-416"><a href="#cb48-416" aria-hidden="true" tabindex="-1"></a>selected <span class="ot">&lt;-</span> <span class="fu">which</span>(lasso_coef[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">!=</span> <span class="dv">0</span>)</span>
<span id="cb48-417"><a href="#cb48-417" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Selected variables:"</span>, <span class="fu">paste</span>(selected, <span class="at">collapse =</span> <span class="st">", "</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb48-418"><a href="#cb48-418" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb48-419"><a href="#cb48-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-420"><a href="#cb48-420" aria-hidden="true" tabindex="-1"></a><span class="fu">### Regularized Logistic Regression</span></span>
<span id="cb48-421"><a href="#cb48-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-422"><a href="#cb48-422" aria-hidden="true" tabindex="-1"></a>Regularization extends naturally to classification problems:</span>
<span id="cb48-423"><a href="#cb48-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-426"><a href="#cb48-426" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb48-427"><a href="#cb48-427" aria-hidden="true" tabindex="-1"></a><span class="co"># Binary classification example</span></span>
<span id="cb48-428"><a href="#cb48-428" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb48-429"><a href="#cb48-429" aria-hidden="true" tabindex="-1"></a>y_binary <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fu">plogis</span>(X <span class="sc">%*%</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="sc">-</span><span class="fl">0.5</span>, <span class="fl">0.3</span>, <span class="fu">rep</span>(<span class="dv">0</span>, p <span class="sc">-</span> <span class="dv">3</span>))))</span>
<span id="cb48-430"><a href="#cb48-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-431"><a href="#cb48-431" aria-hidden="true" tabindex="-1"></a><span class="co"># Regularized logistic regression</span></span>
<span id="cb48-432"><a href="#cb48-432" aria-hidden="true" tabindex="-1"></a>cv_logit <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X, y_binary, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">alpha =</span> <span class="dv">1</span>)</span>
<span id="cb48-433"><a href="#cb48-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-434"><a href="#cb48-434" aria-hidden="true" tabindex="-1"></a><span class="co"># Coefficients</span></span>
<span id="cb48-435"><a href="#cb48-435" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Selected predictors for logistic regression:</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb48-436"><a href="#cb48-436" aria-hidden="true" tabindex="-1"></a>logit_coef <span class="ot">&lt;-</span> <span class="fu">coef</span>(cv_logit, <span class="at">s =</span> <span class="st">"lambda.1se"</span>)</span>
<span id="cb48-437"><a href="#cb48-437" aria-hidden="true" tabindex="-1"></a><span class="fu">which</span>(logit_coef[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">!=</span> <span class="dv">0</span>)</span>
<span id="cb48-438"><a href="#cb48-438" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb48-439"><a href="#cb48-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-440"><a href="#cb48-440" aria-hidden="true" tabindex="-1"></a><span class="fu">## Exercises</span></span>
<span id="cb48-441"><a href="#cb48-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-442"><a href="#cb48-442" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb48-443"><a href="#cb48-443" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise Reg.1: Ridge vs Lasso</span></span>
<span id="cb48-444"><a href="#cb48-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-445"><a href="#cb48-445" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Generate data with $n = 100$ observations and $p = 20$ predictors where:</span>
<span id="cb48-446"><a href="#cb48-446" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Predictors 1-3 have coefficients 3, -2, 1</span>
<span id="cb48-447"><a href="#cb48-447" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Predictors 4-6 are correlated with 1-3</span>
<span id="cb48-448"><a href="#cb48-448" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Predictors 7-20 have coefficient 0</span>
<span id="cb48-449"><a href="#cb48-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-450"><a href="#cb48-450" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Fit OLS, ridge, and lasso. Compare the coefficient estimates to the true values.</span>
<span id="cb48-451"><a href="#cb48-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-452"><a href="#cb48-452" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Generate a test set and compare prediction performance.</span>
<span id="cb48-453"><a href="#cb48-453" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb48-454"><a href="#cb48-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-455"><a href="#cb48-455" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb48-456"><a href="#cb48-456" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise Reg.2: Choosing Alpha</span></span>
<span id="cb48-457"><a href="#cb48-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-458"><a href="#cb48-458" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>For the data above, use cross-validation to select the optimal mixing parameter $\alpha$ for elastic net. Try $\alpha \in <span class="sc">\{</span>0, 0.25, 0.5, 0.75, 1<span class="sc">\}</span>$.</span>
<span id="cb48-459"><a href="#cb48-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-460"><a href="#cb48-460" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Does the optimal $\alpha$ match what you would expect given the correlation structure?</span>
<span id="cb48-461"><a href="#cb48-461" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb48-462"><a href="#cb48-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-463"><a href="#cb48-463" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb48-464"><a href="#cb48-464" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise Reg.3: High-Dimensional Classification</span></span>
<span id="cb48-465"><a href="#cb48-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-466"><a href="#cb48-466" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>Load a gene expression dataset with many more genes than samples. Use regularized logistic regression to build a classifier.</span>
<span id="cb48-467"><a href="#cb48-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-468"><a href="#cb48-468" aria-hidden="true" tabindex="-1"></a><span class="ss">7. </span>Compare the number of genes selected by lasso at <span class="in">`lambda.min`</span> vs <span class="in">`lambda.1se`</span>. Which would you prefer in practice?</span>
<span id="cb48-469"><a href="#cb48-469" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb48-470"><a href="#cb48-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-471"><a href="#cb48-471" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summary</span></span>
<span id="cb48-472"><a href="#cb48-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-473"><a href="#cb48-473" aria-hidden="true" tabindex="-1"></a>This chapter introduced **regularization** as a powerful technique for preventing overfitting, especially when the number of predictors is large relative to the sample size. The core idea is to add a penalty term that shrinks coefficients toward zero, trading a small increase in bias for a substantial reduction in variance.</span>
<span id="cb48-474"><a href="#cb48-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-475"><a href="#cb48-475" aria-hidden="true" tabindex="-1"></a>**Ridge regression** uses an L2 penalty (sum of squared coefficients) that shrinks all coefficients toward zero but never exactly to zero. This makes ridge ideal when all predictors may be relevant and particularly effective for handling multicollinearity. **Lasso regression** uses an L1 penalty (sum of absolute values) that can shrink coefficients exactly to zero, automatically performing variable selection. The resulting sparse models are easier to interpret, though lasso can behave arbitrarily with correlated predictors. **Elastic net** combines both penalties, offering the variable selection of lasso with the stability of ridge for correlated predictors.</span>
<span id="cb48-476"><a href="#cb48-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-477"><a href="#cb48-477" aria-hidden="true" tabindex="-1"></a>The regularization parameter $\lambda$ controls the penalty strength and is typically selected by **cross-validation**. The <span class="in">`lambda.min`</span> value minimizes cross-validation error, while the <span class="in">`lambda.1se`</span> (one standard error rule) often provides a more parsimonious model with nearly equivalent performance.</span>
<span id="cb48-478"><a href="#cb48-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-479"><a href="#cb48-479" aria-hidden="true" tabindex="-1"></a>**Standardization** of predictors is essential before applying regularization, since the penalty treats all coefficients equally and would otherwise unfairly penalize variables measured on larger scales. Finally, regularization extends naturally beyond regression to classification problems through regularized logistic regression and other generalized linear models.</span>
<span id="cb48-480"><a href="#cb48-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-481"><a href="#cb48-481" aria-hidden="true" tabindex="-1"></a><span class="fu">## Additional Resources</span></span>
<span id="cb48-482"><a href="#cb48-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-483"><a href="#cb48-483" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>@james2023islr - Detailed treatment of regularization methods</span>
<span id="cb48-484"><a href="#cb48-484" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>@hastie2009elements - Theoretical foundations</span>
<span id="cb48-485"><a href="#cb48-485" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`glmnet`</span> package vignette - Practical implementation details</span>
<span id="cb48-486"><a href="#cb48-486" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>@tibshirani1996regression - Original lasso paper</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Statistics for Biosciences and Bioengineering</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>Built with <a href="https://quarto.org/">Quarto</a></p>
</div>
  </div>
</footer>




</body></html>