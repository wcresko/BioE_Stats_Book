<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.30">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>31&nbsp; Classification Methods – Statistics for the Biosciences and Bioengineering</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/33-clustering.html" rel="next">
<link href="../chapters/31-bayesian-statistics.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-de070a7b0ab54f8780927367ac907214.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-485d01fc63b59abcd3ee1bf1e8e2748d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/22-statistical-learning.html">Statistical Learning</a></li><li class="breadcrumb-item"><a href="../chapters/32-classification.html"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Classification Methods</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Statistics for the Biosciences and Bioengineering</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Why This Book?</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Core Data Science Tools</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/01-introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/02-installing-tools.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Installing Core Tools</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/02-unix-command-line.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Unix and the Command Line</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/03-r-rstudio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">R and RStudio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/04-markdown-latex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Markdown and LaTeX</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Data Exploration</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/07-tidy-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Tidy Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/08-data-wrangling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Data Wrangling with dplyr</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/09-exploratory-data-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Exploratory Data Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/06-data-visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Data Visualization</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Probability and Distributions</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/07-probability-foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Foundations of Probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/08-discrete-distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Discrete Probability Distributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/09-continuous-distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Continuous Probability Distributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/10-sampling-estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Sampling and Parameter Estimation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Statistical Inference</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/11-experimental-design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Experimental Design Principles</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/11-hypothesis-testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/12-t-tests.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">T-Tests</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/13-nonparametric-tests.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Nonparametric Tests</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/14-bootstrapping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Resampling Methods</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Linear Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/30-what-are-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">What are Models?</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/15-correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Correlation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/16-simple-linear-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Simple Linear Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/17-residual-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Residual Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/18-statistical-power.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Statistical Power</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/20-multiple-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Multiple Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/19-single-factor-anova.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Single Factor ANOVA</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/20-multifactor-anova.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Multi-Factor ANOVA</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/21-glm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Generalized Linear Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Statistical Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/22-statistical-learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Core Concepts in Statistical Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/31-bayesian-statistics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Bayesian Statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/32-classification.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Classification Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/33-clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Clustering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/23-dimensionality-reduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Dimensionality Reduction and Multivariate Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/34-tsne-umap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Non-Linear Dimensionality Reduction: t-SNE and UMAP</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/24-high-performance-computing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">High Performance Computing</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Scientific Communication</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/25-presenting-results.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Presenting Statistical Results</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Historical Context</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A1-eugenics-history.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">The Eugenics History of Statistics</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A8-keyboard-shortcuts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Keyboard Shortcuts Reference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A6-unix-reference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Unix Command Reference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A2-r-reference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">R Command Reference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A9-quarto-reference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Quarto Markdown Reference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A7-latex-reference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">LaTeX Command Reference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A4-greek-letters.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Greek Letters in Mathematics and Statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A3-probability-distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Common Probability Distributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A5-sampling-distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Sampling Distributions in Hypothesis Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/A10-matrix-algebra.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Matrix Algebra Fundamentals</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction-to-classification" id="toc-introduction-to-classification" class="nav-link active" data-scroll-target="#introduction-to-classification"><span class="header-section-number">31.1</span> Introduction to Classification</a></li>
  <li><a href="#distance-the-foundation-of-classification" id="toc-distance-the-foundation-of-classification" class="nav-link" data-scroll-target="#distance-the-foundation-of-classification"><span class="header-section-number">31.2</span> Distance: The Foundation of Classification</a>
  <ul class="collapse">
  <li><a href="#euclidean-distance" id="toc-euclidean-distance" class="nav-link" data-scroll-target="#euclidean-distance">Euclidean Distance</a></li>
  <li><a href="#distance-in-higher-dimensions" id="toc-distance-in-higher-dimensions" class="nav-link" data-scroll-target="#distance-in-higher-dimensions">Distance in Higher Dimensions</a></li>
  <li><a href="#example-distance-between-digits" id="toc-example-distance-between-digits" class="nav-link" data-scroll-target="#example-distance-between-digits">Example: Distance Between Digits</a></li>
  <li><a href="#computing-distance-matrices" id="toc-computing-distance-matrices" class="nav-link" data-scroll-target="#computing-distance-matrices">Computing Distance Matrices</a></li>
  <li><a href="#other-distance-metrics" id="toc-other-distance-metrics" class="nav-link" data-scroll-target="#other-distance-metrics">Other Distance Metrics</a></li>
  </ul></li>
  <li><a href="#k-nearest-neighbors-knn" id="toc-k-nearest-neighbors-knn" class="nav-link" data-scroll-target="#k-nearest-neighbors-knn"><span class="header-section-number">31.3</span> K-Nearest Neighbors (KNN)</a>
  <ul class="collapse">
  <li><a href="#the-knn-algorithm" id="toc-the-knn-algorithm" class="nav-link" data-scroll-target="#the-knn-algorithm">The KNN Algorithm</a></li>
  <li><a href="#knn-for-classification" id="toc-knn-for-classification" class="nav-link" data-scroll-target="#knn-for-classification">KNN for Classification</a></li>
  <li><a href="#the-effect-of-k-bias-variance-tradeoff" id="toc-the-effect-of-k-bias-variance-tradeoff" class="nav-link" data-scroll-target="#the-effect-of-k-bias-variance-tradeoff">The Effect of K: Bias-Variance Tradeoff</a></li>
  <li><a href="#selecting-k-with-cross-validation" id="toc-selecting-k-with-cross-validation" class="nav-link" data-scroll-target="#selecting-k-with-cross-validation">Selecting K with Cross-Validation</a></li>
  <li><a href="#knn-with-the-caret-package" id="toc-knn-with-the-caret-package" class="nav-link" data-scroll-target="#knn-with-the-caret-package">KNN with the caret Package</a></li>
  <li><a href="#visualizing-knn-decision-boundaries" id="toc-visualizing-knn-decision-boundaries" class="nav-link" data-scroll-target="#visualizing-knn-decision-boundaries">Visualizing KNN Decision Boundaries</a></li>
  </ul></li>
  <li><a href="#predictor-space" id="toc-predictor-space" class="nav-link" data-scroll-target="#predictor-space"><span class="header-section-number">31.4</span> Predictor Space</a></li>
  <li><a href="#knn-for-regression" id="toc-knn-for-regression" class="nav-link" data-scroll-target="#knn-for-regression"><span class="header-section-number">31.5</span> KNN for Regression</a></li>
  <li><a href="#advantages-and-limitations-of-knn" id="toc-advantages-and-limitations-of-knn" class="nav-link" data-scroll-target="#advantages-and-limitations-of-knn"><span class="header-section-number">31.6</span> Advantages and Limitations of KNN</a>
  <ul class="collapse">
  <li><a href="#advantages" id="toc-advantages" class="nav-link" data-scroll-target="#advantages">Advantages</a></li>
  <li><a href="#limitations" id="toc-limitations" class="nav-link" data-scroll-target="#limitations">Limitations</a></li>
  </ul></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">31.7</span> Exercises</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">31.8</span> Summary</a></li>
  <li><a href="#additional-resources" id="toc-additional-resources" class="nav-link" data-scroll-target="#additional-resources"><span class="header-section-number">31.9</span> Additional Resources</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/22-statistical-learning.html">Statistical Learning</a></li><li class="breadcrumb-item"><a href="../chapters/32-classification.html"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Classification Methods</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-classification" class="quarto-section-identifier"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Classification Methods</span></span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction-to-classification" class="level2" data-number="31.1">
<h2 data-number="31.1" class="anchored" data-anchor-id="introduction-to-classification"><span class="header-section-number">31.1</span> Introduction to Classification</h2>
<p>Classification is a supervised learning task where the goal is to predict categorical outcomes. Given a set of features (predictors), we want to assign observations to one of several predefined classes.</p>
<p>Classification problems are ubiquitous in biology and bioengineering:</p>
<ul>
<li>Diagnosing disease states from biomarkers</li>
<li>Classifying cell types from gene expression</li>
<li>Predicting protein function from sequence</li>
<li>Identifying species from morphological measurements</li>
</ul>
<p>In this chapter, we focus on <strong>K-Nearest Neighbors (KNN)</strong>, a fundamental classification algorithm that illustrates key concepts applicable to all classification methods. Other classification methods like decision trees, random forests, and support vector machines are covered in <a href="22-statistical-learning.html" class="quarto-xref"><span>Chapter 29</span></a>.</p>
</section>
<section id="distance-the-foundation-of-classification" class="level2" data-number="31.2">
<h2 data-number="31.2" class="anchored" data-anchor-id="distance-the-foundation-of-classification"><span class="header-section-number">31.2</span> Distance: The Foundation of Classification</h2>
<p>Many classification algorithms rely on measuring how similar or different observations are. <strong>Distance</strong> quantifies this similarity—observations that are close together are considered similar.</p>
<section id="euclidean-distance" class="level3">
<h3 class="anchored" data-anchor-id="euclidean-distance">Euclidean Distance</h3>
<p>The most common distance measure is <strong>Euclidean distance</strong>, the straight-line distance between two points:</p>
<p>For two points in two dimensions: <span class="math display">\[
d(A, B) = \sqrt{(A_x - B_x)^2 + (A_y - B_y)^2}
\]</span></p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>rafalib<span class="sc">::</span><span class="fu">mypar</span>()</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>), <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>), <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">cex =</span> <span class="dv">2</span>,</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">xaxt =</span> <span class="st">"n"</span>, <span class="at">yaxt =</span> <span class="st">"n"</span>, <span class="at">xlab =</span> <span class="st">""</span>, <span class="at">ylab =</span> <span class="st">""</span>, <span class="at">bty =</span> <span class="st">"n"</span>,</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.25</span>, <span class="fl">1.25</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.25</span>, <span class="fl">1.25</span>))</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>), <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>))</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="dv">0</span>, .<span class="dv">2</span>, <span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">'(A'</span>[x]<span class="sc">*</span><span class="st">',A'</span>[y]<span class="sc">*</span><span class="st">')'</span>)), <span class="at">cex =</span> <span class="fl">1.5</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="dv">1</span>, <span class="fl">1.2</span>, <span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">'(B'</span>[x]<span class="sc">*</span><span class="st">',B'</span>[y]<span class="sc">*</span><span class="st">')'</span>)), <span class="at">cex =</span> <span class="fl">1.5</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="sc">-</span><span class="fl">0.1</span>, <span class="dv">0</span>, <span class="st">"A"</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">1.1</span>, <span class="dv">1</span>, <span class="st">"B"</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-euclidean-2d" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-euclidean-2d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="32-classification_files/figure-html/fig-euclidean-2d-1.png" class="img-fluid figure-img" width="480">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-euclidean-2d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;31.1: Euclidean distance between two points in a Cartesian plane
</figcaption>
</figure>
</div>
</div>
</div>
<p>In one dimension, distance is simply the absolute difference: <span class="math display">\[
d(A, B) = |A - B|
\]</span></p>
</section>
<section id="distance-in-higher-dimensions" class="level3">
<h3 class="anchored" data-anchor-id="distance-in-higher-dimensions">Distance in Higher Dimensions</h3>
<p>With high-dimensional data (many features), the concept extends naturally. For observations with <span class="math inline">\(p\)</span> features: <span class="math display">\[
d(i, j) = \sqrt{\sum_{k=1}^{p} (x_{ik} - x_{jk})^2}
\]</span></p>
<p>This is the generalized Euclidean distance—we sum the squared differences across all features.</p>
</section>
<section id="example-distance-between-digits" class="level3">
<h3 class="anchored" data-anchor-id="example-distance-between-digits">Example: Distance Between Digits</h3>
<p>Let’s compute distances between handwritten digit images using the MNIST dataset:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dslabs)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">exists</span>(<span class="st">"mnist"</span>)) mnist <span class="ot">&lt;-</span> <span class="fu">read_mnist</span>()</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1995</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>ind <span class="ot">&lt;-</span> <span class="fu">which</span>(mnist<span class="sc">$</span>train<span class="sc">$</span>labels <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">7</span>)) <span class="sc">%&gt;%</span> <span class="fu">sample</span>(<span class="dv">500</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> mnist<span class="sc">$</span>train<span class="sc">$</span>images[ind, ]</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> mnist<span class="sc">$</span>train<span class="sc">$</span>labels[ind]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Each digit image has 784 pixels (features). The labels for the first three observations are:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>y[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 7 2 7</code></pre>
</div>
</div>
<p>We expect digits of the same type to be closer to each other:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>x_1 <span class="ot">&lt;-</span> x[<span class="dv">1</span>, ]</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>x_2 <span class="ot">&lt;-</span> x[<span class="dv">2</span>, ]</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>x_3 <span class="ot">&lt;-</span> x[<span class="dv">3</span>, ]</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Distance between two 7s</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>dist_same <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>((x_1 <span class="sc">-</span> x_2)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Distance between a 7 and a 2</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>dist_diff_1 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>((x_1 <span class="sc">-</span> x_3)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>dist_diff_2 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>((x_2 <span class="sc">-</span> x_3)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Distance between two 7s:"</span>, <span class="fu">round</span>(dist_same, <span class="dv">1</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Distance between two 7s: 3273.4 </code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Distance between 7 and 2:"</span>, <span class="fu">round</span>(dist_diff_1, <span class="dv">1</span>), <span class="st">"and"</span>, <span class="fu">round</span>(dist_diff_2, <span class="dv">1</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Distance between 7 and 2: 2311 and 2635.9 </code></pre>
</div>
</div>
<p>As expected, the two 7s are closer to each other than to the 2.</p>
</section>
<section id="computing-distance-matrices" class="level3">
<h3 class="anchored" data-anchor-id="computing-distance-matrices">Computing Distance Matrices</h3>
<p>The <code>dist()</code> function efficiently computes pairwise distances:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">dist</span>(x)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(d)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "dist"</code></pre>
</div>
</div>
<p>We can visualize the distance matrix to see clustering patterns:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>rafalib<span class="sc">::</span><span class="fu">mypar</span>()</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">image</span>(<span class="fu">as.matrix</span>(d)[<span class="fu">order</span>(y), <span class="fu">order</span>(y)],</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="fu">rev</span>(RColorBrewer<span class="sc">::</span><span class="fu">brewer.pal</span>(<span class="dv">9</span>, <span class="st">"RdBu"</span>)),</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">"Distance Matrix (ordered by digit)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-dist-matrix" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-dist-matrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="32-classification_files/figure-html/fig-dist-matrix-1.png" class="img-fluid figure-img" width="576">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dist-matrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;31.2: Distance matrix for digit images, ordered by label. Similar digits (same class) cluster together with smaller distances (darker colors).
</figcaption>
</figure>
</div>
</div>
</div>
<p>The block structure reveals that 2s are more similar to other 2s, and 7s are more similar to other 7s.</p>
</section>
<section id="other-distance-metrics" class="level3">
<h3 class="anchored" data-anchor-id="other-distance-metrics">Other Distance Metrics</h3>
<p>Beyond Euclidean distance, other metrics are sometimes appropriate:</p>
<p><strong>Manhattan Distance</strong> (L1 norm): Sum of absolute differences <span class="math display">\[
d(x_i, x_j) = \sum_{k=1}^{p} |x_{ik} - x_{jk}|
\]</span></p>
<p><strong>Minkowski Distance</strong> (generalized): <span class="math display">\[
d(x_i, x_j) = \left(\sum_{k=1}^{p} |x_{ik} - x_{jk}|^q\right)^{1/q}
\]</span></p>
<p>When <span class="math inline">\(q = 2\)</span>, this is Euclidean; when <span class="math inline">\(q = 1\)</span>, this is Manhattan.</p>
</section>
</section>
<section id="k-nearest-neighbors-knn" class="level2" data-number="31.3">
<h2 data-number="31.3" class="anchored" data-anchor-id="k-nearest-neighbors-knn"><span class="header-section-number">31.3</span> K-Nearest Neighbors (KNN)</h2>
<section id="the-knn-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="the-knn-algorithm">The KNN Algorithm</h3>
<p><strong>K-Nearest Neighbors</strong> is one of the simplest and most intuitive classification algorithms. The idea is straightforward: classify a new observation based on the classes of its nearest neighbors in the training data.</p>
<p>The algorithm:</p>
<ol type="1">
<li>Choose the number of neighbors <span class="math inline">\(k\)</span></li>
<li>For a new observation, find the <span class="math inline">\(k\)</span> closest training points (using a distance metric)</li>
<li>Assign the class that is most common among these neighbors (majority vote)</li>
</ol>
<p>For regression problems, predict the average of the neighbors’ values.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Intuition
</div>
</div>
<div class="callout-body-container callout-body">
<p>“Tell me who your neighbors are, and I’ll tell you who you are.”</p>
<p>KNN makes no assumptions about the underlying data distribution—it simply uses proximity to make predictions.</p>
</div>
</div>
</section>
<section id="knn-for-classification" class="level3">
<h3 class="anchored" data-anchor-id="knn-for-classification">KNN for Classification</h3>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate two-class data</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>class1 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> <span class="fu">rnorm</span>(n<span class="sc">/</span><span class="dv">2</span>, <span class="at">mean =</span> <span class="dv">2</span>, <span class="at">sd =</span> <span class="dv">1</span>),</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">x2 =</span> <span class="fu">rnorm</span>(n<span class="sc">/</span><span class="dv">2</span>, <span class="at">mean =</span> <span class="dv">2</span>, <span class="at">sd =</span> <span class="dv">1</span>),</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">class =</span> <span class="st">"A"</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>class2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> <span class="fu">rnorm</span>(n<span class="sc">/</span><span class="dv">2</span>, <span class="at">mean =</span> <span class="dv">4</span>, <span class="at">sd =</span> <span class="dv">1</span>),</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">x2 =</span> <span class="fu">rnorm</span>(n<span class="sc">/</span><span class="dv">2</span>, <span class="at">mean =</span> <span class="dv">4</span>, <span class="at">sd =</span> <span class="dv">1</span>),</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">class =</span> <span class="st">"B"</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> <span class="fu">rbind</span>(class1, class2)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="co"># New point to classify</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>new_point <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x1 =</span> <span class="fl">3.2</span>, <span class="at">x2 =</span> <span class="fl">3.5</span>)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Find 5 nearest neighbors</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>distances <span class="ot">&lt;-</span> <span class="fu">sqrt</span>((train_data<span class="sc">$</span>x1 <span class="sc">-</span> new_point<span class="sc">$</span>x1)<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>                  (train_data<span class="sc">$</span>x2 <span class="sc">-</span> new_point<span class="sc">$</span>x2)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>nearest <span class="ot">&lt;-</span> <span class="fu">order</span>(distances)[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(train_data<span class="sc">$</span>x1, train_data<span class="sc">$</span>x2,</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="fu">ifelse</span>(train_data<span class="sc">$</span>class <span class="sc">==</span> <span class="st">"A"</span>, <span class="st">"blue"</span>, <span class="st">"red"</span>),</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">xlab =</span> <span class="st">"Feature 1"</span>, <span class="at">ylab =</span> <span class="st">"Feature 2"</span>,</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"K-Nearest Neighbors (k=5)"</span>)</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(new_point<span class="sc">$</span>x1, new_point<span class="sc">$</span>x2, <span class="at">pch =</span> <span class="dv">8</span>, <span class="at">cex =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Highlight nearest neighbors</span></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(train_data<span class="sc">$</span>x1[nearest], train_data<span class="sc">$</span>x2[nearest],</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>       <span class="at">cex =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="fu">ifelse</span>(train_data<span class="sc">$</span>class[nearest] <span class="sc">==</span> <span class="st">"A"</span>, <span class="st">"blue"</span>, <span class="st">"red"</span>))</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topleft"</span>, <span class="fu">c</span>(<span class="st">"Class A"</span>, <span class="st">"Class B"</span>, <span class="st">"New point"</span>),</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"red"</span>, <span class="st">"black"</span>), <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">16</span>, <span class="dv">16</span>, <span class="dv">8</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-knn-concept" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-knn-concept-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="32-classification_files/figure-html/fig-knn-concept-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-knn-concept-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;31.3: K-nearest neighbors classification: the new point (star) is classified based on its k nearest training points
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="the-effect-of-k-bias-variance-tradeoff" class="level3">
<h3 class="anchored" data-anchor-id="the-effect-of-k-bias-variance-tradeoff">The Effect of K: Bias-Variance Tradeoff</h3>
<p>The choice of <span class="math inline">\(k\)</span> is critical and illustrates the <strong>bias-variance tradeoff</strong>:</p>
<ul>
<li><p><strong>Small k</strong> (e.g., k=1): Very flexible decision boundary, low bias but high variance. Prone to overfitting—the boundary follows noise in the training data.</p></li>
<li><p><strong>Large k</strong>: Smoother decision boundary, higher bias but lower variance. May miss local patterns—prone to underfitting.</p></li>
</ul>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a grid for visualization</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>x1_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">6</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>x2_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">6</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>grid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">x1 =</span> x1_grid, <span class="at">x2 =</span> x2_grid)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (k_val <span class="cf">in</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">15</span>, <span class="dv">50</span>)) {</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predict on grid</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train =</span> train_data[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>              <span class="at">test =</span> grid,</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>              <span class="at">cl =</span> train_data<span class="sc">$</span>class,</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>              <span class="at">k =</span> k_val)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Plot decision regions</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(grid<span class="sc">$</span>x1, grid<span class="sc">$</span>x2,</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">ifelse</span>(pred <span class="sc">==</span> <span class="st">"A"</span>, <span class="fu">rgb</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.1</span>), <span class="fu">rgb</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">0.1</span>)),</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">15</span>, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">xlab =</span> <span class="st">"Feature 1"</span>, <span class="at">ylab =</span> <span class="st">"Feature 2"</span>,</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>       <span class="at">main =</span> <span class="fu">paste</span>(<span class="st">"k ="</span>, k_val))</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">points</span>(train_data<span class="sc">$</span>x1, train_data<span class="sc">$</span>x2,</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>         <span class="at">col =</span> <span class="fu">ifelse</span>(train_data<span class="sc">$</span>class <span class="sc">==</span> <span class="st">"A"</span>, <span class="st">"blue"</span>, <span class="st">"red"</span>), <span class="at">pch =</span> <span class="dv">16</span>)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-knn-k-comparison" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-knn-k-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="32-classification_files/figure-html/fig-knn-k-comparison-1.png" class="img-fluid figure-img" width="864">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-knn-k-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;31.4: Effect of k on KNN decision boundaries: small k creates complex boundaries (overfitting risk), large k creates smooth boundaries (underfitting risk)
</figcaption>
</figure>
</div>
</div>
</div>
<p>Notice how k=1 creates a very jagged boundary that follows individual training points, while k=50 creates a smooth boundary that may miss local structure.</p>
</section>
<section id="selecting-k-with-cross-validation" class="level3">
<h3 class="anchored" data-anchor-id="selecting-k-with-cross-validation">Selecting K with Cross-Validation</h3>
<p>We choose the optimal <span class="math inline">\(k\)</span> using cross-validation to estimate generalization performance:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Split data for validation</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>test_idx <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(train_data), <span class="dv">30</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>train_subset <span class="ot">&lt;-</span> train_data[<span class="sc">-</span>test_idx, ]</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>test_subset <span class="ot">&lt;-</span> train_data[test_idx, ]</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>k_values <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="dv">50</span>, <span class="at">by =</span> <span class="dv">2</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate accuracies</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>accuracy <span class="ot">&lt;-</span> <span class="fu">sapply</span>(k_values, <span class="cf">function</span>(k) {</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train =</span> train_subset[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>              <span class="at">test =</span> test_subset[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>              <span class="at">cl =</span> train_subset<span class="sc">$</span>class,</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>              <span class="at">k =</span> k)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(pred <span class="sc">==</span> test_subset<span class="sc">$</span>class)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>train_accuracy <span class="ot">&lt;-</span> <span class="fu">sapply</span>(k_values, <span class="cf">function</span>(k) {</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train =</span> train_subset[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>              <span class="at">test =</span> train_subset[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>              <span class="at">cl =</span> train_subset<span class="sc">$</span>class,</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>              <span class="at">k =</span> k)</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(pred <span class="sc">==</span> train_subset<span class="sc">$</span>class)</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(k_values, train_accuracy, <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lwd =</span> <span class="dv">2</span>,</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"k (number of neighbors)"</span>, <span class="at">ylab =</span> <span class="st">"Accuracy"</span>,</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Training vs Test Accuracy"</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="dv">1</span>))</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(k_values, accuracy, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"bottomright"</span>, <span class="fu">c</span>(<span class="st">"Training"</span>, <span class="st">"Test"</span>), <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"red"</span>), <span class="at">lwd =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-knn-cv" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-knn-cv-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="32-classification_files/figure-html/fig-knn-cv-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-knn-cv-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;31.5: Training vs test accuracy as a function of k: training accuracy is perfect at k=1, but test accuracy reveals the true generalization performance
</figcaption>
</figure>
</div>
</div>
</div>
<p>When k=1, training accuracy is perfect—each point is its own nearest neighbor. But test accuracy reveals how well the model actually generalizes.</p>
</section>
<section id="knn-with-the-caret-package" class="level3">
<h3 class="anchored" data-anchor-id="knn-with-the-caret-package">KNN with the caret Package</h3>
<p>The <code>caret</code> package provides a convenient interface for KNN with built-in cross-validation:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dslabs)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"mnist_27"</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Train KNN with cross-validation to select k</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>train_knn <span class="ot">&lt;-</span> <span class="fu">train</span>(y <span class="sc">~</span> ., <span class="at">method =</span> <span class="st">"knn"</span>,</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> mnist_27<span class="sc">$</span>train,</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>                   <span class="at">tuneGrid =</span> <span class="fu">data.frame</span>(<span class="at">k =</span> <span class="fu">seq</span>(<span class="dv">9</span>, <span class="dv">71</span>, <span class="dv">2</span>)))</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Best k value</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>train_knn<span class="sc">$</span>bestTune</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>    k
30 67</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test accuracy</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="fu">predict</span>(train_knn, mnist_27<span class="sc">$</span>test, <span class="at">type =</span> <span class="st">"raw"</span>),</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>                mnist_27<span class="sc">$</span>test<span class="sc">$</span>y)<span class="sc">$</span>overall[<span class="st">"Accuracy"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy 
   0.825 </code></pre>
</div>
</div>
</section>
<section id="visualizing-knn-decision-boundaries" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-knn-decision-boundaries">Visualizing KNN Decision Boundaries</h3>
<p>KNN can capture complex, non-linear decision boundaries:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper function for plotting conditional probabilities</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>plot_cond_prob <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">p_hat =</span> <span class="cn">NULL</span>) {</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  tmp <span class="ot">&lt;-</span> mnist_27<span class="sc">$</span>true_p</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="sc">!</span><span class="fu">is.null</span>(p_hat)) {</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    tmp <span class="ot">&lt;-</span> <span class="fu">mutate</span>(tmp, <span class="at">p =</span> p_hat)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>  tmp <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(x_1, x_2, <span class="at">z =</span> p, <span class="at">fill =</span> p)) <span class="sc">+</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_raster</span>(<span class="at">show.legend =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_fill_gradientn</span>(<span class="at">colors =</span> <span class="fu">c</span>(<span class="st">"#F8766D"</span>, <span class="st">"white"</span>, <span class="st">"#00BFC4"</span>)) <span class="sc">+</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">stat_contour</span>(<span class="at">breaks =</span> <span class="fu">c</span>(<span class="fl">0.5</span>), <span class="at">color =</span> <span class="st">"black"</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">plot_cond_prob</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"True conditional probability"</span>)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">plot_cond_prob</span>(<span class="fu">predict</span>(train_knn, <span class="at">newdata =</span> mnist_27<span class="sc">$</span>true_p, <span class="at">type =</span> <span class="st">"prob"</span>)[, <span class="dv">2</span>]) <span class="sc">+</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"KNN estimate"</span>)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>gridExtra<span class="sc">::</span><span class="fu">grid.arrange</span>(p2, p1, <span class="at">nrow =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-knn-boundary" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-knn-boundary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="32-classification_files/figure-html/fig-knn-boundary-1.png" class="img-fluid figure-img" width="864">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-knn-boundary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;31.6: KNN decision boundary compared to the true conditional probability. KNN is flexible enough to capture the non-linear pattern.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="predictor-space" class="level2" data-number="31.4">
<h2 data-number="31.4" class="anchored" data-anchor-id="predictor-space"><span class="header-section-number">31.4</span> Predictor Space</h2>
<p>The <strong>predictor space</strong> is a conceptual framework for understanding classification algorithms. It consists of all possible values the predictor variables can take.</p>
<p>For the digit classification problem, each observation is a point in 784-dimensional space. Classification algorithms partition this space into regions, each assigned to a class.</p>
<p>Key concepts:</p>
<ul>
<li><strong>Decision boundary</strong>: The surface separating regions assigned to different classes</li>
<li><strong>Neighborhood</strong>: The region around a point within a specified distance</li>
<li><strong>Feature scaling</strong>: Important because distance calculations are sensitive to scale</li>
</ul>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Feature Scaling
</div>
</div>
<div class="callout-body-container callout-body">
<p>KNN and other distance-based methods are sensitive to feature scales. A variable ranging from 0-1000 will dominate distance calculations compared to a variable ranging from 0-1.</p>
<p>Always standardize features before applying KNN:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize features</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>x_scaled <span class="ot">&lt;-</span> <span class="fu">scale</span>(x)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Or use caret's preProcess</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>train_knn <span class="ot">&lt;-</span> <span class="fu">train</span>(y <span class="sc">~</span> ., <span class="at">method =</span> <span class="st">"knn"</span>,</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> training_data,</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>                   <span class="at">preProcess =</span> <span class="fu">c</span>(<span class="st">"center"</span>, <span class="st">"scale"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
</div>
</section>
<section id="knn-for-regression" class="level2" data-number="31.5">
<h2 data-number="31.5" class="anchored" data-anchor-id="knn-for-regression"><span class="header-section-number">31.5</span> KNN for Regression</h2>
<p>KNN can also predict continuous outcomes. Instead of majority voting, we average the neighbors’ values:</p>
<p><span class="math display">\[
\hat{y} = \frac{1}{k} \sum_{x_i \in N_k(x)} y_i
\]</span></p>
<p>where <span class="math inline">\(N_k(x)\)</span> is the set of k nearest neighbors to x.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate non-linear data</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">2</span><span class="sc">*</span>pi, <span class="at">length.out =</span> n)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">sin</span>(x) <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> <span class="fl">0.3</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>reg_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (k_val <span class="cf">in</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">10</span>, <span class="dv">30</span>)) {</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predict using KNN regression</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>  x_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">2</span><span class="sc">*</span>pi, <span class="at">length.out =</span> <span class="dv">200</span>)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Manual KNN regression</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">&lt;-</span> <span class="fu">sapply</span>(x_grid, <span class="cf">function</span>(xnew) {</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>    dists <span class="ot">&lt;-</span> <span class="fu">abs</span>(reg_data<span class="sc">$</span>x <span class="sc">-</span> xnew)</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>    neighbors <span class="ot">&lt;-</span> <span class="fu">order</span>(dists)[<span class="dv">1</span><span class="sc">:</span>k_val]</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mean</span>(reg_data<span class="sc">$</span>y[neighbors])</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(x, y, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">col =</span> <span class="st">"gray60"</span>, <span class="at">main =</span> <span class="fu">paste</span>(<span class="st">"k ="</span>, k_val))</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(x_grid, pred, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(x_grid, <span class="fu">sin</span>(x_grid), <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">legend</span>(<span class="st">"topright"</span>, <span class="fu">c</span>(<span class="st">"KNN fit"</span>, <span class="st">"True function"</span>),</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>         <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"red"</span>), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">cex =</span> <span class="fl">0.7</span>)</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-knn-regression" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-knn-regression-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="32-classification_files/figure-html/fig-knn-regression-1.png" class="img-fluid figure-img" width="864">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-knn-regression-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;31.7: KNN regression with different values of k: smaller k gives more flexible (wiggly) fits, larger k gives smoother fits
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="advantages-and-limitations-of-knn" class="level2" data-number="31.6">
<h2 data-number="31.6" class="anchored" data-anchor-id="advantages-and-limitations-of-knn"><span class="header-section-number">31.6</span> Advantages and Limitations of KNN</h2>
<section id="advantages" class="level3">
<h3 class="anchored" data-anchor-id="advantages">Advantages</h3>
<p>KNN offers several appealing properties that make it a valuable tool in the classification toolkit. The algorithm is <strong>simple and intuitive</strong>—it’s easy to understand the logic and explain predictions to non-technical audiences. Unlike many machine learning methods, KNN has <strong>no training phase</strong>; all computation happens at prediction time, a property sometimes called “lazy learning.” This makes it trivial to update the model with new training data. The method is <strong>non-parametric</strong>, making no assumptions about the underlying data distribution, which allows it to adapt to complex patterns in the data. KNN <strong>naturally handles multiclass problems</strong> without any modification to the basic algorithm—simply take the majority vote among k neighbors regardless of how many classes exist. Finally, KNN can <strong>capture complex, non-linear patterns</strong> and decision boundaries that linear methods would miss entirely.</p>
</section>
<section id="limitations" class="level3">
<h3 class="anchored" data-anchor-id="limitations">Limitations</h3>
<p>Despite these strengths, KNN has important limitations that restrict its applicability. The method is <strong>computationally expensive for large datasets</strong> because each prediction requires computing distances to all training points, which becomes prohibitive as datasets grow. KNN is <strong>sensitive to irrelevant features</strong>—since all features contribute equally to distance calculations, adding noise variables degrades performance. This sensitivity also means the method <strong>requires careful feature scaling</strong>; variables on different scales will dominate distance calculations and bias results. The algorithm suffers from the <strong>curse of dimensionality</strong>: in high-dimensional spaces, all points become approximately equidistant, making the notion of “nearest” neighbors less meaningful. Finally, KNN provides <strong>no interpretable model</strong>—unlike decision trees or linear models, you cannot easily identify which features are most important for making predictions, limiting its use when interpretability matters.</p>
</section>
</section>
<section id="exercises" class="level2" data-number="31.7">
<h2 data-number="31.7" class="anchored" data-anchor-id="exercises"><span class="header-section-number">31.7</span> Exercises</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise Cl.1: Tissue Classification with KNN
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>Load the <code>tissue_gene_expression</code> dataset. Split the data into training and test sets, then use kNN to predict tissue type. Try values of <span class="math inline">\(k = 1, 3, 5, 7, 9, 11\)</span> and report which gives the best test accuracy.</li>
</ol>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"tissue_gene_expression"</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(tissue_gene_expression<span class="sc">$</span>x)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(tissue_gene_expression<span class="sc">$</span>y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise Cl.2: Sex Prediction from Height
</div>
</div>
<div class="callout-body-container callout-body">
<ol start="2" type="1">
<li>We previously used logistic regression to predict sex from height. Use kNN to do the same. Use cross-validation to select the optimal <span class="math inline">\(k\)</span> and compare the F1 score to the logistic regression result of approximately 0.6.</li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise Cl.3: Distance Metrics
</div>
</div>
<div class="callout-body-container callout-body">
<ol start="3" type="1">
<li>For the digit classification problem with 2s and 7s, experiment with different distance metrics (Euclidean vs Manhattan). Does the choice of metric affect classification accuracy?</li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise Cl.4: Weighted KNN
</div>
</div>
<div class="callout-body-container callout-body">
<ol start="4" type="1">
<li>Implement weighted KNN, where closer neighbors contribute more to the prediction. Compare performance to standard KNN.</li>
</ol>
</div>
</div>
</section>
<section id="summary" class="level2" data-number="31.8">
<h2 data-number="31.8" class="anchored" data-anchor-id="summary"><span class="header-section-number">31.8</span> Summary</h2>
<ul>
<li><strong>Distance</strong> measures similarity between observations and is fundamental to many classification methods</li>
<li><strong>K-Nearest Neighbors (KNN)</strong> classifies observations based on the majority class of nearby training points</li>
<li>The <strong>choice of k</strong> represents a bias-variance tradeoff: small k is flexible but noisy, large k is smooth but may miss local patterns</li>
<li><strong>Cross-validation</strong> should be used to select the optimal k</li>
<li><strong>Feature scaling</strong> is critical for distance-based methods</li>
<li>KNN is simple and effective but can be slow for large datasets and suffers from the curse of dimensionality</li>
<li>The <strong>predictor space</strong> framework helps visualize how classification algorithms partition the feature space</li>
</ul>
</section>
<section id="additional-resources" class="level2" data-number="31.9">
<h2 data-number="31.9" class="anchored" data-anchor-id="additional-resources"><span class="header-section-number">31.9</span> Additional Resources</h2>
<ul>
<li><span class="citation" data-cites="james2023islr">James et al. (<a href="../references.html#ref-james2023islr" role="doc-biblioref">2023</a>)</span> - Comprehensive treatment of KNN and classification</li>
<li><span class="citation" data-cites="thulin2025msr">Thulin (<a href="../references.html#ref-thulin2025msr" role="doc-biblioref">2025</a>)</span> - Modern statistics with R including machine learning</li>
<li>The <code>caret</code> package vignette for practical classification workflows</li>
</ul>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-james2023islr" class="csl-entry" role="listitem">
James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2023. <em>An Introduction to Statistical Learning with Applications in r</em>. 2nd ed. Springer. <a href="https://www.statlearning.com">https://www.statlearning.com</a>.
</div>
<div id="ref-thulin2025msr" class="csl-entry" role="listitem">
Thulin, Måns. 2025. <em>Modern Statistics with r</em>. CRC Press. <a href="https://www.modernstatisticswithr.com">https://www.modernstatisticswithr.com</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/31-bayesian-statistics.html" class="pagination-link" aria-label="Bayesian Statistics">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Bayesian Statistics</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/33-clustering.html" class="pagination-link" aria-label="Clustering">
        <span class="nav-page-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Clustering</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb23" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Classification Methods {#sec-classification}</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(class)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_minimal</span>())</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction to Classification</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>Classification is a supervised learning task where the goal is to predict categorical outcomes. Given a set of features (predictors), we want to assign observations to one of several predefined classes.</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>Classification problems are ubiquitous in biology and bioengineering:</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Diagnosing disease states from biomarkers</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Classifying cell types from gene expression</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Predicting protein function from sequence</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Identifying species from morphological measurements</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>In this chapter, we focus on **K-Nearest Neighbors (KNN)**, a fundamental classification algorithm that illustrates key concepts applicable to all classification methods. Other classification methods like decision trees, random forests, and support vector machines are covered in @sec-statistical-learning.</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a><span class="fu">## Distance: The Foundation of Classification</span></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>Many classification algorithms rely on measuring how similar or different observations are. **Distance** quantifies this similarity—observations that are close together are considered similar.</span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a><span class="fu">### Euclidean Distance</span></span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>The most common distance measure is **Euclidean distance**, the straight-line distance between two points:</span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a>For two points in two dimensions:</span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a>d(A, B) = \sqrt{(A_x - B_x)^2 + (A_y - B_y)^2}</span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-euclidean-2d</span></span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Euclidean distance between two points in a Cartesian plane"</span></span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 5</span></span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>rafalib<span class="sc">::</span><span class="fu">mypar</span>()</span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>), <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>), <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">cex =</span> <span class="dv">2</span>,</span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>     <span class="at">xaxt =</span> <span class="st">"n"</span>, <span class="at">yaxt =</span> <span class="st">"n"</span>, <span class="at">xlab =</span> <span class="st">""</span>, <span class="at">ylab =</span> <span class="st">""</span>, <span class="at">bty =</span> <span class="st">"n"</span>,</span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.25</span>, <span class="fl">1.25</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.25</span>, <span class="fl">1.25</span>))</span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>), <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>))</span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="dv">0</span>, .<span class="dv">2</span>, <span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">'(A'</span>[x]<span class="sc">*</span><span class="st">',A'</span>[y]<span class="sc">*</span><span class="st">')'</span>)), <span class="at">cex =</span> <span class="fl">1.5</span>)</span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="dv">1</span>, <span class="fl">1.2</span>, <span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">'(B'</span>[x]<span class="sc">*</span><span class="st">',B'</span>[y]<span class="sc">*</span><span class="st">')'</span>)), <span class="at">cex =</span> <span class="fl">1.5</span>)</span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="sc">-</span><span class="fl">0.1</span>, <span class="dv">0</span>, <span class="st">"A"</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">1.1</span>, <span class="dv">1</span>, <span class="st">"B"</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a>In one dimension, distance is simply the absolute difference:</span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>d(A, B) = |A - B|</span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a><span class="fu">### Distance in Higher Dimensions</span></span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a>With high-dimensional data (many features), the concept extends naturally. For observations with $p$ features:</span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a>d(i, j) = \sqrt{\sum_{k=1}^{p} (x_{ik} - x_{jk})^2}</span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a>This is the generalized Euclidean distance—we sum the squared differences across all features.</span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a><span class="fu">### Example: Distance Between Digits</span></span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a>Let's compute distances between handwritten digit images using the MNIST dataset:</span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dslabs)</span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">exists</span>(<span class="st">"mnist"</span>)) mnist <span class="ot">&lt;-</span> <span class="fu">read_mnist</span>()</span>
<span id="cb23-81"><a href="#cb23-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-82"><a href="#cb23-82" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1995</span>)</span>
<span id="cb23-83"><a href="#cb23-83" aria-hidden="true" tabindex="-1"></a>ind <span class="ot">&lt;-</span> <span class="fu">which</span>(mnist<span class="sc">$</span>train<span class="sc">$</span>labels <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">7</span>)) <span class="sc">%&gt;%</span> <span class="fu">sample</span>(<span class="dv">500</span>)</span>
<span id="cb23-84"><a href="#cb23-84" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> mnist<span class="sc">$</span>train<span class="sc">$</span>images[ind, ]</span>
<span id="cb23-85"><a href="#cb23-85" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> mnist<span class="sc">$</span>train<span class="sc">$</span>labels[ind]</span>
<span id="cb23-86"><a href="#cb23-86" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-87"><a href="#cb23-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-88"><a href="#cb23-88" aria-hidden="true" tabindex="-1"></a>Each digit image has 784 pixels (features). The labels for the first three observations are:</span>
<span id="cb23-89"><a href="#cb23-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-92"><a href="#cb23-92" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-93"><a href="#cb23-93" aria-hidden="true" tabindex="-1"></a>y[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]</span>
<span id="cb23-94"><a href="#cb23-94" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-95"><a href="#cb23-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-96"><a href="#cb23-96" aria-hidden="true" tabindex="-1"></a>We expect digits of the same type to be closer to each other:</span>
<span id="cb23-97"><a href="#cb23-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-100"><a href="#cb23-100" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-101"><a href="#cb23-101" aria-hidden="true" tabindex="-1"></a>x_1 <span class="ot">&lt;-</span> x[<span class="dv">1</span>, ]</span>
<span id="cb23-102"><a href="#cb23-102" aria-hidden="true" tabindex="-1"></a>x_2 <span class="ot">&lt;-</span> x[<span class="dv">2</span>, ]</span>
<span id="cb23-103"><a href="#cb23-103" aria-hidden="true" tabindex="-1"></a>x_3 <span class="ot">&lt;-</span> x[<span class="dv">3</span>, ]</span>
<span id="cb23-104"><a href="#cb23-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-105"><a href="#cb23-105" aria-hidden="true" tabindex="-1"></a><span class="co"># Distance between two 7s</span></span>
<span id="cb23-106"><a href="#cb23-106" aria-hidden="true" tabindex="-1"></a>dist_same <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>((x_1 <span class="sc">-</span> x_2)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb23-107"><a href="#cb23-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-108"><a href="#cb23-108" aria-hidden="true" tabindex="-1"></a><span class="co"># Distance between a 7 and a 2</span></span>
<span id="cb23-109"><a href="#cb23-109" aria-hidden="true" tabindex="-1"></a>dist_diff_1 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>((x_1 <span class="sc">-</span> x_3)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb23-110"><a href="#cb23-110" aria-hidden="true" tabindex="-1"></a>dist_diff_2 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>((x_2 <span class="sc">-</span> x_3)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb23-111"><a href="#cb23-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-112"><a href="#cb23-112" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Distance between two 7s:"</span>, <span class="fu">round</span>(dist_same, <span class="dv">1</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb23-113"><a href="#cb23-113" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Distance between 7 and 2:"</span>, <span class="fu">round</span>(dist_diff_1, <span class="dv">1</span>), <span class="st">"and"</span>, <span class="fu">round</span>(dist_diff_2, <span class="dv">1</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb23-114"><a href="#cb23-114" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-115"><a href="#cb23-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-116"><a href="#cb23-116" aria-hidden="true" tabindex="-1"></a>As expected, the two 7s are closer to each other than to the 2.</span>
<span id="cb23-117"><a href="#cb23-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-118"><a href="#cb23-118" aria-hidden="true" tabindex="-1"></a><span class="fu">### Computing Distance Matrices</span></span>
<span id="cb23-119"><a href="#cb23-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-120"><a href="#cb23-120" aria-hidden="true" tabindex="-1"></a>The <span class="in">`dist()`</span> function efficiently computes pairwise distances:</span>
<span id="cb23-121"><a href="#cb23-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-124"><a href="#cb23-124" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-125"><a href="#cb23-125" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">dist</span>(x)</span>
<span id="cb23-126"><a href="#cb23-126" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(d)</span>
<span id="cb23-127"><a href="#cb23-127" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-128"><a href="#cb23-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-129"><a href="#cb23-129" aria-hidden="true" tabindex="-1"></a>We can visualize the distance matrix to see clustering patterns:</span>
<span id="cb23-130"><a href="#cb23-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-133"><a href="#cb23-133" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-134"><a href="#cb23-134" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-dist-matrix</span></span>
<span id="cb23-135"><a href="#cb23-135" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Distance matrix for digit images, ordered by label. Similar digits (same class) cluster together with smaller distances (darker colors)."</span></span>
<span id="cb23-136"><a href="#cb23-136" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 6</span></span>
<span id="cb23-137"><a href="#cb23-137" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb23-138"><a href="#cb23-138" aria-hidden="true" tabindex="-1"></a>rafalib<span class="sc">::</span><span class="fu">mypar</span>()</span>
<span id="cb23-139"><a href="#cb23-139" aria-hidden="true" tabindex="-1"></a><span class="fu">image</span>(<span class="fu">as.matrix</span>(d)[<span class="fu">order</span>(y), <span class="fu">order</span>(y)],</span>
<span id="cb23-140"><a href="#cb23-140" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="fu">rev</span>(RColorBrewer<span class="sc">::</span><span class="fu">brewer.pal</span>(<span class="dv">9</span>, <span class="st">"RdBu"</span>)),</span>
<span id="cb23-141"><a href="#cb23-141" aria-hidden="true" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">"Distance Matrix (ordered by digit)"</span>)</span>
<span id="cb23-142"><a href="#cb23-142" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-143"><a href="#cb23-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-144"><a href="#cb23-144" aria-hidden="true" tabindex="-1"></a>The block structure reveals that 2s are more similar to other 2s, and 7s are more similar to other 7s.</span>
<span id="cb23-145"><a href="#cb23-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-146"><a href="#cb23-146" aria-hidden="true" tabindex="-1"></a><span class="fu">### Other Distance Metrics</span></span>
<span id="cb23-147"><a href="#cb23-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-148"><a href="#cb23-148" aria-hidden="true" tabindex="-1"></a>Beyond Euclidean distance, other metrics are sometimes appropriate:</span>
<span id="cb23-149"><a href="#cb23-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-150"><a href="#cb23-150" aria-hidden="true" tabindex="-1"></a>**Manhattan Distance** (L1 norm): Sum of absolute differences</span>
<span id="cb23-151"><a href="#cb23-151" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-152"><a href="#cb23-152" aria-hidden="true" tabindex="-1"></a>d(x_i, x_j) = \sum_{k=1}^{p} |x_{ik} - x_{jk}|</span>
<span id="cb23-153"><a href="#cb23-153" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-154"><a href="#cb23-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-155"><a href="#cb23-155" aria-hidden="true" tabindex="-1"></a>**Minkowski Distance** (generalized):</span>
<span id="cb23-156"><a href="#cb23-156" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-157"><a href="#cb23-157" aria-hidden="true" tabindex="-1"></a>d(x_i, x_j) = \left(\sum_{k=1}^{p} |x_{ik} - x_{jk}|^q\right)^{1/q}</span>
<span id="cb23-158"><a href="#cb23-158" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-159"><a href="#cb23-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-160"><a href="#cb23-160" aria-hidden="true" tabindex="-1"></a>When $q = 2$, this is Euclidean; when $q = 1$, this is Manhattan.</span>
<span id="cb23-161"><a href="#cb23-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-162"><a href="#cb23-162" aria-hidden="true" tabindex="-1"></a><span class="fu">## K-Nearest Neighbors (KNN)</span></span>
<span id="cb23-163"><a href="#cb23-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-164"><a href="#cb23-164" aria-hidden="true" tabindex="-1"></a><span class="fu">### The KNN Algorithm</span></span>
<span id="cb23-165"><a href="#cb23-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-166"><a href="#cb23-166" aria-hidden="true" tabindex="-1"></a>**K-Nearest Neighbors** is one of the simplest and most intuitive classification algorithms. The idea is straightforward: classify a new observation based on the classes of its nearest neighbors in the training data.</span>
<span id="cb23-167"><a href="#cb23-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-168"><a href="#cb23-168" aria-hidden="true" tabindex="-1"></a>The algorithm:</span>
<span id="cb23-169"><a href="#cb23-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-170"><a href="#cb23-170" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Choose the number of neighbors $k$</span>
<span id="cb23-171"><a href="#cb23-171" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>For a new observation, find the $k$ closest training points (using a distance metric)</span>
<span id="cb23-172"><a href="#cb23-172" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Assign the class that is most common among these neighbors (majority vote)</span>
<span id="cb23-173"><a href="#cb23-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-174"><a href="#cb23-174" aria-hidden="true" tabindex="-1"></a>For regression problems, predict the average of the neighbors' values.</span>
<span id="cb23-175"><a href="#cb23-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-176"><a href="#cb23-176" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb23-177"><a href="#cb23-177" aria-hidden="true" tabindex="-1"></a><span class="fu">## Intuition</span></span>
<span id="cb23-178"><a href="#cb23-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-179"><a href="#cb23-179" aria-hidden="true" tabindex="-1"></a>"Tell me who your neighbors are, and I'll tell you who you are."</span>
<span id="cb23-180"><a href="#cb23-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-181"><a href="#cb23-181" aria-hidden="true" tabindex="-1"></a>KNN makes no assumptions about the underlying data distribution—it simply uses proximity to make predictions.</span>
<span id="cb23-182"><a href="#cb23-182" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-183"><a href="#cb23-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-184"><a href="#cb23-184" aria-hidden="true" tabindex="-1"></a><span class="fu">### KNN for Classification</span></span>
<span id="cb23-185"><a href="#cb23-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-188"><a href="#cb23-188" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-189"><a href="#cb23-189" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-knn-concept</span></span>
<span id="cb23-190"><a href="#cb23-190" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "K-nearest neighbors classification: the new point (star) is classified based on its k nearest training points"</span></span>
<span id="cb23-191"><a href="#cb23-191" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 7</span></span>
<span id="cb23-192"><a href="#cb23-192" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb23-193"><a href="#cb23-193" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate two-class data</span></span>
<span id="cb23-194"><a href="#cb23-194" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb23-195"><a href="#cb23-195" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb23-196"><a href="#cb23-196" aria-hidden="true" tabindex="-1"></a>class1 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb23-197"><a href="#cb23-197" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> <span class="fu">rnorm</span>(n<span class="sc">/</span><span class="dv">2</span>, <span class="at">mean =</span> <span class="dv">2</span>, <span class="at">sd =</span> <span class="dv">1</span>),</span>
<span id="cb23-198"><a href="#cb23-198" aria-hidden="true" tabindex="-1"></a>  <span class="at">x2 =</span> <span class="fu">rnorm</span>(n<span class="sc">/</span><span class="dv">2</span>, <span class="at">mean =</span> <span class="dv">2</span>, <span class="at">sd =</span> <span class="dv">1</span>),</span>
<span id="cb23-199"><a href="#cb23-199" aria-hidden="true" tabindex="-1"></a>  <span class="at">class =</span> <span class="st">"A"</span></span>
<span id="cb23-200"><a href="#cb23-200" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-201"><a href="#cb23-201" aria-hidden="true" tabindex="-1"></a>class2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb23-202"><a href="#cb23-202" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> <span class="fu">rnorm</span>(n<span class="sc">/</span><span class="dv">2</span>, <span class="at">mean =</span> <span class="dv">4</span>, <span class="at">sd =</span> <span class="dv">1</span>),</span>
<span id="cb23-203"><a href="#cb23-203" aria-hidden="true" tabindex="-1"></a>  <span class="at">x2 =</span> <span class="fu">rnorm</span>(n<span class="sc">/</span><span class="dv">2</span>, <span class="at">mean =</span> <span class="dv">4</span>, <span class="at">sd =</span> <span class="dv">1</span>),</span>
<span id="cb23-204"><a href="#cb23-204" aria-hidden="true" tabindex="-1"></a>  <span class="at">class =</span> <span class="st">"B"</span></span>
<span id="cb23-205"><a href="#cb23-205" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-206"><a href="#cb23-206" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> <span class="fu">rbind</span>(class1, class2)</span>
<span id="cb23-207"><a href="#cb23-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-208"><a href="#cb23-208" aria-hidden="true" tabindex="-1"></a><span class="co"># New point to classify</span></span>
<span id="cb23-209"><a href="#cb23-209" aria-hidden="true" tabindex="-1"></a>new_point <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x1 =</span> <span class="fl">3.2</span>, <span class="at">x2 =</span> <span class="fl">3.5</span>)</span>
<span id="cb23-210"><a href="#cb23-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-211"><a href="#cb23-211" aria-hidden="true" tabindex="-1"></a><span class="co"># Find 5 nearest neighbors</span></span>
<span id="cb23-212"><a href="#cb23-212" aria-hidden="true" tabindex="-1"></a>distances <span class="ot">&lt;-</span> <span class="fu">sqrt</span>((train_data<span class="sc">$</span>x1 <span class="sc">-</span> new_point<span class="sc">$</span>x1)<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span></span>
<span id="cb23-213"><a href="#cb23-213" aria-hidden="true" tabindex="-1"></a>                  (train_data<span class="sc">$</span>x2 <span class="sc">-</span> new_point<span class="sc">$</span>x2)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb23-214"><a href="#cb23-214" aria-hidden="true" tabindex="-1"></a>nearest <span class="ot">&lt;-</span> <span class="fu">order</span>(distances)[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span>
<span id="cb23-215"><a href="#cb23-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-216"><a href="#cb23-216" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb23-217"><a href="#cb23-217" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(train_data<span class="sc">$</span>x1, train_data<span class="sc">$</span>x2,</span>
<span id="cb23-218"><a href="#cb23-218" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="fu">ifelse</span>(train_data<span class="sc">$</span>class <span class="sc">==</span> <span class="st">"A"</span>, <span class="st">"blue"</span>, <span class="st">"red"</span>),</span>
<span id="cb23-219"><a href="#cb23-219" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">xlab =</span> <span class="st">"Feature 1"</span>, <span class="at">ylab =</span> <span class="st">"Feature 2"</span>,</span>
<span id="cb23-220"><a href="#cb23-220" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"K-Nearest Neighbors (k=5)"</span>)</span>
<span id="cb23-221"><a href="#cb23-221" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(new_point<span class="sc">$</span>x1, new_point<span class="sc">$</span>x2, <span class="at">pch =</span> <span class="dv">8</span>, <span class="at">cex =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb23-222"><a href="#cb23-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-223"><a href="#cb23-223" aria-hidden="true" tabindex="-1"></a><span class="co"># Highlight nearest neighbors</span></span>
<span id="cb23-224"><a href="#cb23-224" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(train_data<span class="sc">$</span>x1[nearest], train_data<span class="sc">$</span>x2[nearest],</span>
<span id="cb23-225"><a href="#cb23-225" aria-hidden="true" tabindex="-1"></a>       <span class="at">cex =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="fu">ifelse</span>(train_data<span class="sc">$</span>class[nearest] <span class="sc">==</span> <span class="st">"A"</span>, <span class="st">"blue"</span>, <span class="st">"red"</span>))</span>
<span id="cb23-226"><a href="#cb23-226" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topleft"</span>, <span class="fu">c</span>(<span class="st">"Class A"</span>, <span class="st">"Class B"</span>, <span class="st">"New point"</span>),</span>
<span id="cb23-227"><a href="#cb23-227" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"red"</span>, <span class="st">"black"</span>), <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">16</span>, <span class="dv">16</span>, <span class="dv">8</span>))</span>
<span id="cb23-228"><a href="#cb23-228" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-229"><a href="#cb23-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-230"><a href="#cb23-230" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Effect of K: Bias-Variance Tradeoff</span></span>
<span id="cb23-231"><a href="#cb23-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-232"><a href="#cb23-232" aria-hidden="true" tabindex="-1"></a>The choice of $k$ is critical and illustrates the **bias-variance tradeoff**:</span>
<span id="cb23-233"><a href="#cb23-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-234"><a href="#cb23-234" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Small k** (e.g., k=1): Very flexible decision boundary, low bias but high variance. Prone to overfitting—the boundary follows noise in the training data.</span>
<span id="cb23-235"><a href="#cb23-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-236"><a href="#cb23-236" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Large k**: Smoother decision boundary, higher bias but lower variance. May miss local patterns—prone to underfitting.</span>
<span id="cb23-237"><a href="#cb23-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-240"><a href="#cb23-240" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-241"><a href="#cb23-241" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-knn-k-comparison</span></span>
<span id="cb23-242"><a href="#cb23-242" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Effect of k on KNN decision boundaries: small k creates complex boundaries (overfitting risk), large k creates smooth boundaries (underfitting risk)"</span></span>
<span id="cb23-243"><a href="#cb23-243" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 9</span></span>
<span id="cb23-244"><a href="#cb23-244" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 4</span></span>
<span id="cb23-245"><a href="#cb23-245" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a grid for visualization</span></span>
<span id="cb23-246"><a href="#cb23-246" aria-hidden="true" tabindex="-1"></a>x1_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">6</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb23-247"><a href="#cb23-247" aria-hidden="true" tabindex="-1"></a>x2_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">6</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb23-248"><a href="#cb23-248" aria-hidden="true" tabindex="-1"></a>grid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">x1 =</span> x1_grid, <span class="at">x2 =</span> x2_grid)</span>
<span id="cb23-249"><a href="#cb23-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-250"><a href="#cb23-250" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb23-251"><a href="#cb23-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-252"><a href="#cb23-252" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (k_val <span class="cf">in</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">15</span>, <span class="dv">50</span>)) {</span>
<span id="cb23-253"><a href="#cb23-253" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predict on grid</span></span>
<span id="cb23-254"><a href="#cb23-254" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train =</span> train_data[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],</span>
<span id="cb23-255"><a href="#cb23-255" aria-hidden="true" tabindex="-1"></a>              <span class="at">test =</span> grid,</span>
<span id="cb23-256"><a href="#cb23-256" aria-hidden="true" tabindex="-1"></a>              <span class="at">cl =</span> train_data<span class="sc">$</span>class,</span>
<span id="cb23-257"><a href="#cb23-257" aria-hidden="true" tabindex="-1"></a>              <span class="at">k =</span> k_val)</span>
<span id="cb23-258"><a href="#cb23-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-259"><a href="#cb23-259" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Plot decision regions</span></span>
<span id="cb23-260"><a href="#cb23-260" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(grid<span class="sc">$</span>x1, grid<span class="sc">$</span>x2,</span>
<span id="cb23-261"><a href="#cb23-261" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">ifelse</span>(pred <span class="sc">==</span> <span class="st">"A"</span>, <span class="fu">rgb</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.1</span>), <span class="fu">rgb</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">0.1</span>)),</span>
<span id="cb23-262"><a href="#cb23-262" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">15</span>, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">xlab =</span> <span class="st">"Feature 1"</span>, <span class="at">ylab =</span> <span class="st">"Feature 2"</span>,</span>
<span id="cb23-263"><a href="#cb23-263" aria-hidden="true" tabindex="-1"></a>       <span class="at">main =</span> <span class="fu">paste</span>(<span class="st">"k ="</span>, k_val))</span>
<span id="cb23-264"><a href="#cb23-264" aria-hidden="true" tabindex="-1"></a>  <span class="fu">points</span>(train_data<span class="sc">$</span>x1, train_data<span class="sc">$</span>x2,</span>
<span id="cb23-265"><a href="#cb23-265" aria-hidden="true" tabindex="-1"></a>         <span class="at">col =</span> <span class="fu">ifelse</span>(train_data<span class="sc">$</span>class <span class="sc">==</span> <span class="st">"A"</span>, <span class="st">"blue"</span>, <span class="st">"red"</span>), <span class="at">pch =</span> <span class="dv">16</span>)</span>
<span id="cb23-266"><a href="#cb23-266" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-267"><a href="#cb23-267" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-268"><a href="#cb23-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-269"><a href="#cb23-269" aria-hidden="true" tabindex="-1"></a>Notice how k=1 creates a very jagged boundary that follows individual training points, while k=50 creates a smooth boundary that may miss local structure.</span>
<span id="cb23-270"><a href="#cb23-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-271"><a href="#cb23-271" aria-hidden="true" tabindex="-1"></a><span class="fu">### Selecting K with Cross-Validation</span></span>
<span id="cb23-272"><a href="#cb23-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-273"><a href="#cb23-273" aria-hidden="true" tabindex="-1"></a>We choose the optimal $k$ using cross-validation to estimate generalization performance:</span>
<span id="cb23-274"><a href="#cb23-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-277"><a href="#cb23-277" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-278"><a href="#cb23-278" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-knn-cv</span></span>
<span id="cb23-279"><a href="#cb23-279" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Training vs test accuracy as a function of k: training accuracy is perfect at k=1, but test accuracy reveals the true generalization performance"</span></span>
<span id="cb23-280"><a href="#cb23-280" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 7</span></span>
<span id="cb23-281"><a href="#cb23-281" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb23-282"><a href="#cb23-282" aria-hidden="true" tabindex="-1"></a><span class="co"># Split data for validation</span></span>
<span id="cb23-283"><a href="#cb23-283" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb23-284"><a href="#cb23-284" aria-hidden="true" tabindex="-1"></a>test_idx <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(train_data), <span class="dv">30</span>)</span>
<span id="cb23-285"><a href="#cb23-285" aria-hidden="true" tabindex="-1"></a>train_subset <span class="ot">&lt;-</span> train_data[<span class="sc">-</span>test_idx, ]</span>
<span id="cb23-286"><a href="#cb23-286" aria-hidden="true" tabindex="-1"></a>test_subset <span class="ot">&lt;-</span> train_data[test_idx, ]</span>
<span id="cb23-287"><a href="#cb23-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-288"><a href="#cb23-288" aria-hidden="true" tabindex="-1"></a>k_values <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="dv">50</span>, <span class="at">by =</span> <span class="dv">2</span>)</span>
<span id="cb23-289"><a href="#cb23-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-290"><a href="#cb23-290" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate accuracies</span></span>
<span id="cb23-291"><a href="#cb23-291" aria-hidden="true" tabindex="-1"></a>accuracy <span class="ot">&lt;-</span> <span class="fu">sapply</span>(k_values, <span class="cf">function</span>(k) {</span>
<span id="cb23-292"><a href="#cb23-292" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train =</span> train_subset[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],</span>
<span id="cb23-293"><a href="#cb23-293" aria-hidden="true" tabindex="-1"></a>              <span class="at">test =</span> test_subset[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],</span>
<span id="cb23-294"><a href="#cb23-294" aria-hidden="true" tabindex="-1"></a>              <span class="at">cl =</span> train_subset<span class="sc">$</span>class,</span>
<span id="cb23-295"><a href="#cb23-295" aria-hidden="true" tabindex="-1"></a>              <span class="at">k =</span> k)</span>
<span id="cb23-296"><a href="#cb23-296" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(pred <span class="sc">==</span> test_subset<span class="sc">$</span>class)</span>
<span id="cb23-297"><a href="#cb23-297" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb23-298"><a href="#cb23-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-299"><a href="#cb23-299" aria-hidden="true" tabindex="-1"></a>train_accuracy <span class="ot">&lt;-</span> <span class="fu">sapply</span>(k_values, <span class="cf">function</span>(k) {</span>
<span id="cb23-300"><a href="#cb23-300" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train =</span> train_subset[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],</span>
<span id="cb23-301"><a href="#cb23-301" aria-hidden="true" tabindex="-1"></a>              <span class="at">test =</span> train_subset[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],</span>
<span id="cb23-302"><a href="#cb23-302" aria-hidden="true" tabindex="-1"></a>              <span class="at">cl =</span> train_subset<span class="sc">$</span>class,</span>
<span id="cb23-303"><a href="#cb23-303" aria-hidden="true" tabindex="-1"></a>              <span class="at">k =</span> k)</span>
<span id="cb23-304"><a href="#cb23-304" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(pred <span class="sc">==</span> train_subset<span class="sc">$</span>class)</span>
<span id="cb23-305"><a href="#cb23-305" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb23-306"><a href="#cb23-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-307"><a href="#cb23-307" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(k_values, train_accuracy, <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lwd =</span> <span class="dv">2</span>,</span>
<span id="cb23-308"><a href="#cb23-308" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"k (number of neighbors)"</span>, <span class="at">ylab =</span> <span class="st">"Accuracy"</span>,</span>
<span id="cb23-309"><a href="#cb23-309" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Training vs Test Accuracy"</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="dv">1</span>))</span>
<span id="cb23-310"><a href="#cb23-310" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(k_values, accuracy, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb23-311"><a href="#cb23-311" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"bottomright"</span>, <span class="fu">c</span>(<span class="st">"Training"</span>, <span class="st">"Test"</span>), <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"red"</span>), <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb23-312"><a href="#cb23-312" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-313"><a href="#cb23-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-314"><a href="#cb23-314" aria-hidden="true" tabindex="-1"></a>When k=1, training accuracy is perfect—each point is its own nearest neighbor. But test accuracy reveals how well the model actually generalizes.</span>
<span id="cb23-315"><a href="#cb23-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-316"><a href="#cb23-316" aria-hidden="true" tabindex="-1"></a><span class="fu">### KNN with the caret Package</span></span>
<span id="cb23-317"><a href="#cb23-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-318"><a href="#cb23-318" aria-hidden="true" tabindex="-1"></a>The <span class="in">`caret`</span> package provides a convenient interface for KNN with built-in cross-validation:</span>
<span id="cb23-319"><a href="#cb23-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-322"><a href="#cb23-322" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-323"><a href="#cb23-323" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb23-324"><a href="#cb23-324" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dslabs)</span>
<span id="cb23-325"><a href="#cb23-325" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"mnist_27"</span>)</span>
<span id="cb23-326"><a href="#cb23-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-327"><a href="#cb23-327" aria-hidden="true" tabindex="-1"></a><span class="co"># Train KNN with cross-validation to select k</span></span>
<span id="cb23-328"><a href="#cb23-328" aria-hidden="true" tabindex="-1"></a>train_knn <span class="ot">&lt;-</span> <span class="fu">train</span>(y <span class="sc">~</span> ., <span class="at">method =</span> <span class="st">"knn"</span>,</span>
<span id="cb23-329"><a href="#cb23-329" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> mnist_27<span class="sc">$</span>train,</span>
<span id="cb23-330"><a href="#cb23-330" aria-hidden="true" tabindex="-1"></a>                   <span class="at">tuneGrid =</span> <span class="fu">data.frame</span>(<span class="at">k =</span> <span class="fu">seq</span>(<span class="dv">9</span>, <span class="dv">71</span>, <span class="dv">2</span>)))</span>
<span id="cb23-331"><a href="#cb23-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-332"><a href="#cb23-332" aria-hidden="true" tabindex="-1"></a><span class="co"># Best k value</span></span>
<span id="cb23-333"><a href="#cb23-333" aria-hidden="true" tabindex="-1"></a>train_knn<span class="sc">$</span>bestTune</span>
<span id="cb23-334"><a href="#cb23-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-335"><a href="#cb23-335" aria-hidden="true" tabindex="-1"></a><span class="co"># Test accuracy</span></span>
<span id="cb23-336"><a href="#cb23-336" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="fu">predict</span>(train_knn, mnist_27<span class="sc">$</span>test, <span class="at">type =</span> <span class="st">"raw"</span>),</span>
<span id="cb23-337"><a href="#cb23-337" aria-hidden="true" tabindex="-1"></a>                mnist_27<span class="sc">$</span>test<span class="sc">$</span>y)<span class="sc">$</span>overall[<span class="st">"Accuracy"</span>]</span>
<span id="cb23-338"><a href="#cb23-338" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-339"><a href="#cb23-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-340"><a href="#cb23-340" aria-hidden="true" tabindex="-1"></a><span class="fu">### Visualizing KNN Decision Boundaries</span></span>
<span id="cb23-341"><a href="#cb23-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-342"><a href="#cb23-342" aria-hidden="true" tabindex="-1"></a>KNN can capture complex, non-linear decision boundaries:</span>
<span id="cb23-343"><a href="#cb23-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-346"><a href="#cb23-346" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-347"><a href="#cb23-347" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-knn-boundary</span></span>
<span id="cb23-348"><a href="#cb23-348" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "KNN decision boundary compared to the true conditional probability. KNN is flexible enough to capture the non-linear pattern."</span></span>
<span id="cb23-349"><a href="#cb23-349" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 9</span></span>
<span id="cb23-350"><a href="#cb23-350" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 4</span></span>
<span id="cb23-351"><a href="#cb23-351" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper function for plotting conditional probabilities</span></span>
<span id="cb23-352"><a href="#cb23-352" aria-hidden="true" tabindex="-1"></a>plot_cond_prob <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">p_hat =</span> <span class="cn">NULL</span>) {</span>
<span id="cb23-353"><a href="#cb23-353" aria-hidden="true" tabindex="-1"></a>  tmp <span class="ot">&lt;-</span> mnist_27<span class="sc">$</span>true_p</span>
<span id="cb23-354"><a href="#cb23-354" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="sc">!</span><span class="fu">is.null</span>(p_hat)) {</span>
<span id="cb23-355"><a href="#cb23-355" aria-hidden="true" tabindex="-1"></a>    tmp <span class="ot">&lt;-</span> <span class="fu">mutate</span>(tmp, <span class="at">p =</span> p_hat)</span>
<span id="cb23-356"><a href="#cb23-356" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb23-357"><a href="#cb23-357" aria-hidden="true" tabindex="-1"></a>  tmp <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(x_1, x_2, <span class="at">z =</span> p, <span class="at">fill =</span> p)) <span class="sc">+</span></span>
<span id="cb23-358"><a href="#cb23-358" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_raster</span>(<span class="at">show.legend =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb23-359"><a href="#cb23-359" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_fill_gradientn</span>(<span class="at">colors =</span> <span class="fu">c</span>(<span class="st">"#F8766D"</span>, <span class="st">"white"</span>, <span class="st">"#00BFC4"</span>)) <span class="sc">+</span></span>
<span id="cb23-360"><a href="#cb23-360" aria-hidden="true" tabindex="-1"></a>    <span class="fu">stat_contour</span>(<span class="at">breaks =</span> <span class="fu">c</span>(<span class="fl">0.5</span>), <span class="at">color =</span> <span class="st">"black"</span>)</span>
<span id="cb23-361"><a href="#cb23-361" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-362"><a href="#cb23-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-363"><a href="#cb23-363" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">plot_cond_prob</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"True conditional probability"</span>)</span>
<span id="cb23-364"><a href="#cb23-364" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">plot_cond_prob</span>(<span class="fu">predict</span>(train_knn, <span class="at">newdata =</span> mnist_27<span class="sc">$</span>true_p, <span class="at">type =</span> <span class="st">"prob"</span>)[, <span class="dv">2</span>]) <span class="sc">+</span></span>
<span id="cb23-365"><a href="#cb23-365" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"KNN estimate"</span>)</span>
<span id="cb23-366"><a href="#cb23-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-367"><a href="#cb23-367" aria-hidden="true" tabindex="-1"></a>gridExtra<span class="sc">::</span><span class="fu">grid.arrange</span>(p2, p1, <span class="at">nrow =</span> <span class="dv">1</span>)</span>
<span id="cb23-368"><a href="#cb23-368" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-369"><a href="#cb23-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-370"><a href="#cb23-370" aria-hidden="true" tabindex="-1"></a><span class="fu">## Predictor Space</span></span>
<span id="cb23-371"><a href="#cb23-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-372"><a href="#cb23-372" aria-hidden="true" tabindex="-1"></a>The **predictor space** is a conceptual framework for understanding classification algorithms. It consists of all possible values the predictor variables can take.</span>
<span id="cb23-373"><a href="#cb23-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-374"><a href="#cb23-374" aria-hidden="true" tabindex="-1"></a>For the digit classification problem, each observation is a point in 784-dimensional space. Classification algorithms partition this space into regions, each assigned to a class.</span>
<span id="cb23-375"><a href="#cb23-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-376"><a href="#cb23-376" aria-hidden="true" tabindex="-1"></a>Key concepts:</span>
<span id="cb23-377"><a href="#cb23-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-378"><a href="#cb23-378" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Decision boundary**: The surface separating regions assigned to different classes</span>
<span id="cb23-379"><a href="#cb23-379" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Neighborhood**: The region around a point within a specified distance</span>
<span id="cb23-380"><a href="#cb23-380" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Feature scaling**: Important because distance calculations are sensitive to scale</span>
<span id="cb23-381"><a href="#cb23-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-382"><a href="#cb23-382" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb23-383"><a href="#cb23-383" aria-hidden="true" tabindex="-1"></a><span class="fu">## Feature Scaling</span></span>
<span id="cb23-384"><a href="#cb23-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-385"><a href="#cb23-385" aria-hidden="true" tabindex="-1"></a>KNN and other distance-based methods are sensitive to feature scales. A variable ranging from 0-1000 will dominate distance calculations compared to a variable ranging from 0-1.</span>
<span id="cb23-386"><a href="#cb23-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-387"><a href="#cb23-387" aria-hidden="true" tabindex="-1"></a>Always standardize features before applying KNN:</span>
<span id="cb23-388"><a href="#cb23-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-391"><a href="#cb23-391" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-392"><a href="#cb23-392" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-393"><a href="#cb23-393" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize features</span></span>
<span id="cb23-394"><a href="#cb23-394" aria-hidden="true" tabindex="-1"></a>x_scaled <span class="ot">&lt;-</span> <span class="fu">scale</span>(x)</span>
<span id="cb23-395"><a href="#cb23-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-396"><a href="#cb23-396" aria-hidden="true" tabindex="-1"></a><span class="co"># Or use caret's preProcess</span></span>
<span id="cb23-397"><a href="#cb23-397" aria-hidden="true" tabindex="-1"></a>train_knn <span class="ot">&lt;-</span> <span class="fu">train</span>(y <span class="sc">~</span> ., <span class="at">method =</span> <span class="st">"knn"</span>,</span>
<span id="cb23-398"><a href="#cb23-398" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> training_data,</span>
<span id="cb23-399"><a href="#cb23-399" aria-hidden="true" tabindex="-1"></a>                   <span class="at">preProcess =</span> <span class="fu">c</span>(<span class="st">"center"</span>, <span class="st">"scale"</span>))</span>
<span id="cb23-400"><a href="#cb23-400" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-401"><a href="#cb23-401" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-402"><a href="#cb23-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-403"><a href="#cb23-403" aria-hidden="true" tabindex="-1"></a><span class="fu">## KNN for Regression</span></span>
<span id="cb23-404"><a href="#cb23-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-405"><a href="#cb23-405" aria-hidden="true" tabindex="-1"></a>KNN can also predict continuous outcomes. Instead of majority voting, we average the neighbors' values:</span>
<span id="cb23-406"><a href="#cb23-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-407"><a href="#cb23-407" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-408"><a href="#cb23-408" aria-hidden="true" tabindex="-1"></a>\hat{y} = \frac{1}{k} \sum_{x_i \in N_k(x)} y_i</span>
<span id="cb23-409"><a href="#cb23-409" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-410"><a href="#cb23-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-411"><a href="#cb23-411" aria-hidden="true" tabindex="-1"></a>where $N_k(x)$ is the set of k nearest neighbors to x.</span>
<span id="cb23-412"><a href="#cb23-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-415"><a href="#cb23-415" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-416"><a href="#cb23-416" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-knn-regression</span></span>
<span id="cb23-417"><a href="#cb23-417" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "KNN regression with different values of k: smaller k gives more flexible (wiggly) fits, larger k gives smoother fits"</span></span>
<span id="cb23-418"><a href="#cb23-418" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 9</span></span>
<span id="cb23-419"><a href="#cb23-419" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 4</span></span>
<span id="cb23-420"><a href="#cb23-420" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate non-linear data</span></span>
<span id="cb23-421"><a href="#cb23-421" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb23-422"><a href="#cb23-422" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb23-423"><a href="#cb23-423" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">2</span><span class="sc">*</span>pi, <span class="at">length.out =</span> n)</span>
<span id="cb23-424"><a href="#cb23-424" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">sin</span>(x) <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> <span class="fl">0.3</span>)</span>
<span id="cb23-425"><a href="#cb23-425" aria-hidden="true" tabindex="-1"></a>reg_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)</span>
<span id="cb23-426"><a href="#cb23-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-427"><a href="#cb23-427" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb23-428"><a href="#cb23-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-429"><a href="#cb23-429" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (k_val <span class="cf">in</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">10</span>, <span class="dv">30</span>)) {</span>
<span id="cb23-430"><a href="#cb23-430" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predict using KNN regression</span></span>
<span id="cb23-431"><a href="#cb23-431" aria-hidden="true" tabindex="-1"></a>  x_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">2</span><span class="sc">*</span>pi, <span class="at">length.out =</span> <span class="dv">200</span>)</span>
<span id="cb23-432"><a href="#cb23-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-433"><a href="#cb23-433" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Manual KNN regression</span></span>
<span id="cb23-434"><a href="#cb23-434" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">&lt;-</span> <span class="fu">sapply</span>(x_grid, <span class="cf">function</span>(xnew) {</span>
<span id="cb23-435"><a href="#cb23-435" aria-hidden="true" tabindex="-1"></a>    dists <span class="ot">&lt;-</span> <span class="fu">abs</span>(reg_data<span class="sc">$</span>x <span class="sc">-</span> xnew)</span>
<span id="cb23-436"><a href="#cb23-436" aria-hidden="true" tabindex="-1"></a>    neighbors <span class="ot">&lt;-</span> <span class="fu">order</span>(dists)[<span class="dv">1</span><span class="sc">:</span>k_val]</span>
<span id="cb23-437"><a href="#cb23-437" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mean</span>(reg_data<span class="sc">$</span>y[neighbors])</span>
<span id="cb23-438"><a href="#cb23-438" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb23-439"><a href="#cb23-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-440"><a href="#cb23-440" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(x, y, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">col =</span> <span class="st">"gray60"</span>, <span class="at">main =</span> <span class="fu">paste</span>(<span class="st">"k ="</span>, k_val))</span>
<span id="cb23-441"><a href="#cb23-441" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(x_grid, pred, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb23-442"><a href="#cb23-442" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(x_grid, <span class="fu">sin</span>(x_grid), <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb23-443"><a href="#cb23-443" aria-hidden="true" tabindex="-1"></a>  <span class="fu">legend</span>(<span class="st">"topright"</span>, <span class="fu">c</span>(<span class="st">"KNN fit"</span>, <span class="st">"True function"</span>),</span>
<span id="cb23-444"><a href="#cb23-444" aria-hidden="true" tabindex="-1"></a>         <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"red"</span>), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">cex =</span> <span class="fl">0.7</span>)</span>
<span id="cb23-445"><a href="#cb23-445" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-446"><a href="#cb23-446" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-447"><a href="#cb23-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-448"><a href="#cb23-448" aria-hidden="true" tabindex="-1"></a><span class="fu">## Advantages and Limitations of KNN</span></span>
<span id="cb23-449"><a href="#cb23-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-450"><a href="#cb23-450" aria-hidden="true" tabindex="-1"></a><span class="fu">### Advantages</span></span>
<span id="cb23-451"><a href="#cb23-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-452"><a href="#cb23-452" aria-hidden="true" tabindex="-1"></a>KNN offers several appealing properties that make it a valuable tool in the classification toolkit. The algorithm is **simple and intuitive**—it's easy to understand the logic and explain predictions to non-technical audiences. Unlike many machine learning methods, KNN has **no training phase**; all computation happens at prediction time, a property sometimes called "lazy learning." This makes it trivial to update the model with new training data. The method is **non-parametric**, making no assumptions about the underlying data distribution, which allows it to adapt to complex patterns in the data. KNN **naturally handles multiclass problems** without any modification to the basic algorithm—simply take the majority vote among k neighbors regardless of how many classes exist. Finally, KNN can **capture complex, non-linear patterns** and decision boundaries that linear methods would miss entirely.</span>
<span id="cb23-453"><a href="#cb23-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-454"><a href="#cb23-454" aria-hidden="true" tabindex="-1"></a><span class="fu">### Limitations</span></span>
<span id="cb23-455"><a href="#cb23-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-456"><a href="#cb23-456" aria-hidden="true" tabindex="-1"></a>Despite these strengths, KNN has important limitations that restrict its applicability. The method is **computationally expensive for large datasets** because each prediction requires computing distances to all training points, which becomes prohibitive as datasets grow. KNN is **sensitive to irrelevant features**—since all features contribute equally to distance calculations, adding noise variables degrades performance. This sensitivity also means the method **requires careful feature scaling**; variables on different scales will dominate distance calculations and bias results. The algorithm suffers from the **curse of dimensionality**: in high-dimensional spaces, all points become approximately equidistant, making the notion of "nearest" neighbors less meaningful. Finally, KNN provides **no interpretable model**—unlike decision trees or linear models, you cannot easily identify which features are most important for making predictions, limiting its use when interpretability matters.</span>
<span id="cb23-457"><a href="#cb23-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-458"><a href="#cb23-458" aria-hidden="true" tabindex="-1"></a><span class="fu">## Exercises</span></span>
<span id="cb23-459"><a href="#cb23-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-460"><a href="#cb23-460" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb23-461"><a href="#cb23-461" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise Cl.1: Tissue Classification with KNN</span></span>
<span id="cb23-462"><a href="#cb23-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-463"><a href="#cb23-463" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Load the <span class="in">`tissue_gene_expression`</span> dataset. Split the data into training and test sets, then use kNN to predict tissue type. Try values of $k = 1, 3, 5, 7, 9, 11$ and report which gives the best test accuracy.</span>
<span id="cb23-464"><a href="#cb23-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-467"><a href="#cb23-467" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-468"><a href="#cb23-468" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-469"><a href="#cb23-469" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"tissue_gene_expression"</span>)</span>
<span id="cb23-470"><a href="#cb23-470" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(tissue_gene_expression<span class="sc">$</span>x)</span>
<span id="cb23-471"><a href="#cb23-471" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(tissue_gene_expression<span class="sc">$</span>y)</span>
<span id="cb23-472"><a href="#cb23-472" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-473"><a href="#cb23-473" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-474"><a href="#cb23-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-475"><a href="#cb23-475" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb23-476"><a href="#cb23-476" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise Cl.2: Sex Prediction from Height</span></span>
<span id="cb23-477"><a href="#cb23-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-478"><a href="#cb23-478" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>We previously used logistic regression to predict sex from height. Use kNN to do the same. Use cross-validation to select the optimal $k$ and compare the F1 score to the logistic regression result of approximately 0.6.</span>
<span id="cb23-479"><a href="#cb23-479" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-480"><a href="#cb23-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-481"><a href="#cb23-481" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb23-482"><a href="#cb23-482" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise Cl.3: Distance Metrics</span></span>
<span id="cb23-483"><a href="#cb23-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-484"><a href="#cb23-484" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>For the digit classification problem with 2s and 7s, experiment with different distance metrics (Euclidean vs Manhattan). Does the choice of metric affect classification accuracy?</span>
<span id="cb23-485"><a href="#cb23-485" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-486"><a href="#cb23-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-487"><a href="#cb23-487" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb23-488"><a href="#cb23-488" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise Cl.4: Weighted KNN</span></span>
<span id="cb23-489"><a href="#cb23-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-490"><a href="#cb23-490" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Implement weighted KNN, where closer neighbors contribute more to the prediction. Compare performance to standard KNN.</span>
<span id="cb23-491"><a href="#cb23-491" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-492"><a href="#cb23-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-493"><a href="#cb23-493" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summary</span></span>
<span id="cb23-494"><a href="#cb23-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-495"><a href="#cb23-495" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Distance** measures similarity between observations and is fundamental to many classification methods</span>
<span id="cb23-496"><a href="#cb23-496" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**K-Nearest Neighbors (KNN)** classifies observations based on the majority class of nearby training points</span>
<span id="cb23-497"><a href="#cb23-497" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The **choice of k** represents a bias-variance tradeoff: small k is flexible but noisy, large k is smooth but may miss local patterns</span>
<span id="cb23-498"><a href="#cb23-498" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Cross-validation** should be used to select the optimal k</span>
<span id="cb23-499"><a href="#cb23-499" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Feature scaling** is critical for distance-based methods</span>
<span id="cb23-500"><a href="#cb23-500" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>KNN is simple and effective but can be slow for large datasets and suffers from the curse of dimensionality</span>
<span id="cb23-501"><a href="#cb23-501" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The **predictor space** framework helps visualize how classification algorithms partition the feature space</span>
<span id="cb23-502"><a href="#cb23-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-503"><a href="#cb23-503" aria-hidden="true" tabindex="-1"></a><span class="fu">## Additional Resources</span></span>
<span id="cb23-504"><a href="#cb23-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-505"><a href="#cb23-505" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>@james2023islr - Comprehensive treatment of KNN and classification</span>
<span id="cb23-506"><a href="#cb23-506" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>@thulin2025msr - Modern statistics with R including machine learning</span>
<span id="cb23-507"><a href="#cb23-507" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The <span class="in">`caret`</span> package vignette for practical classification workflows</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Statistics for Biosciences and Bioengineering</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>Built with <a href="https://quarto.org/">Quarto</a></p>
</div>
  </div>
</footer>




</body></html>