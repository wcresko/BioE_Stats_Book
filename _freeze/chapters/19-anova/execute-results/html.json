{
  "hash": "fe10efeb3b5c2b8e4ce2b1131bdcbb16",
  "result": {
    "engine": "knitr",
    "markdown": "# Analysis of Variance {#sec-anova}\n\n\n::: {.cell}\n\n:::\n\n\n## Beyond Two Groups\n\nThe t-test compares two groups, but many experiments involve more than two. We might compare three drug treatments, five temperature conditions, or four genetic strains. Running multiple t-tests creates problems: with many comparisons, false positives become likely even when no true differences exist.\n\nAnalysis of Variance (ANOVA) provides a solution. It tests whether any of the group means differ from the others in a single test, controlling the overall Type I error rate.\n\n## The ANOVA Framework\n\nANOVA partitions the total variation in the data into components: variation between groups (due to treatment effects) and variation within groups (due to random error).\n\n![](../images/Images_5b.016.jpeg){fig-align=\"center\"}\n\nThe key insight is that if groups have equal means, the between-group variation should be similar to the within-group variation. If the between-group variation is much larger, the group means probably differ.\n\n![](../images/Images_5b.015.jpeg){fig-align=\"center\"}\n\n## The F-Test\n\nANOVA uses the F-statistic:\n\n$$F = \\frac{MS_{between}}{MS_{within}} = \\frac{\\text{Variance between groups}}{\\text{Variance within groups}}$$\n\nUnder the null hypothesis (all group means equal), F follows an F-distribution. Large F values indicate that group means differ more than expected by chance.\n\n## One-Way ANOVA in R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example using iris data\niris_aov <- aov(Sepal.Length ~ Species, data = iris)\nsummary(iris_aov)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             Df Sum Sq Mean Sq F value Pr(>F)    \nSpecies       2  63.21  31.606   119.3 <2e-16 ***\nResiduals   147  38.96   0.265                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nThe significant p-value tells us that sepal length differs among species, but not which species differ from which.\n\n## ANOVA Assumptions\n\nLike the t-test, ANOVA assumes:\n\n1. **Normality**: Observations within each group are normally distributed\n2. **Homogeneity of variance**: Groups have equal variances\n3. **Independence**: Observations are independent\n\nANOVA is robust to mild violations of normality, especially with balanced designs and large samples. Serious violations of homogeneity of variance are more problematic but can be addressed with Welch's ANOVA or transformations.\n\n## Post-Hoc Comparisons\n\nA significant ANOVA tells us groups differ but not how. **Post-hoc tests** compare specific pairs of groups while controlling for multiple comparisons.\n\n**Tukey's HSD** (Honestly Significant Difference) compares all pairs:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTukeyHSD(iris_aov)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Sepal.Length ~ Species, data = iris)\n\n$Species\n                      diff       lwr       upr p adj\nversicolor-setosa    0.930 0.6862273 1.1737727     0\nvirginica-setosa     1.582 1.3382273 1.8257727     0\nvirginica-versicolor 0.652 0.4082273 0.8957727     0\n```\n\n\n:::\n:::\n\n\nEach pairwise comparison includes the difference in means, confidence interval, and adjusted p-value.\n\n## Planned Contrasts\n\nIf you have specific hypotheses about which groups should differ (decided before seeing the data), planned contrasts are more powerful than post-hoc tests. They focus statistical power on the comparisons you care about.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example: Compare setosa to the average of the other two species\ncontrasts(iris$Species) <- cbind(\n  setosa_vs_others = c(2, -1, -1)\n)\nsummary.lm(aov(Sepal.Length ~ Species, data = iris))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\naov(formula = Sepal.Length ~ Species, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              5.84333    0.04203 139.020  < 2e-16 ***\nSpeciessetosa_vs_others -0.41867    0.02972 -14.086  < 2e-16 ***\nSpecies                  0.46103    0.07280   6.333 2.77e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.6187,\tAdjusted R-squared:  0.6135 \nF-statistic: 119.3 on 2 and 147 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n## Fixed vs. Random Effects\n\n**Fixed effects** are specific treatments of interest that would be the same if the study were replicated—drug A, drug B, drug C. Conclusions apply only to these specific treatments.\n\n**Random effects** are levels sampled from a larger population—particular subjects, batches, or locations. The goal is to generalize to the population of possible levels, not just those observed.\n\nThe distinction matters because it affects how F-ratios are calculated and what conclusions can be drawn.\n\n## Two-Way ANOVA\n\nWhen experiments have two factors, two-way ANOVA examines main effects of each factor and their interaction.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulated factorial design\nset.seed(42)\nn <- 20\ndata_factorial <- data.frame(\n  response = c(rnorm(n, 10, 2), rnorm(n, 12, 2), \n               rnorm(n, 11, 2), rnorm(n, 18, 2)),\n  factor_A = rep(c(\"A1\", \"A1\", \"A2\", \"A2\"), each = n),\n  factor_B = rep(c(\"B1\", \"B2\", \"B1\", \"B2\"), each = n)\n)\n\ntwo_way <- aov(response ~ factor_A * factor_B, data = data_factorial)\nsummary(two_way)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  Df Sum Sq Mean Sq F value   Pr(>F)    \nfactor_A           1  279.6   279.6   59.95 3.41e-11 ***\nfactor_B           1  352.6   352.6   75.61 5.12e-13 ***\nfactor_A:factor_B  1  195.2   195.2   41.87 8.57e-09 ***\nResiduals         76  354.4     4.7                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nAn **interaction** means the effect of one factor depends on the level of the other. Significant interactions often require examining simple effects rather than main effects.\n\n## Interaction Plots\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize interaction\ninteraction.plot(data_factorial$factor_A, data_factorial$factor_B, \n                 data_factorial$response,\n                 col = c(\"blue\", \"red\"), lwd = 2,\n                 xlab = \"Factor A\", ylab = \"Response\",\n                 trace.label = \"Factor B\")\n```\n\n::: {.cell-output-display}\n![](19-anova_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nNon-parallel lines suggest an interaction. Parallel lines suggest additive (non-interacting) effects.\n\n![](../images/images_7a.022.jpeg){fig-align=\"center\"}\n\n## Nested Designs\n\nIn nested designs, levels of one factor exist only within levels of another. For example, technicians might be nested within labs—each technician works in only one lab.\n\nNested designs have no interaction term because not all combinations of factor levels exist. They are common when sampling is hierarchical.\n\n## Practical Considerations\n\nReport effect sizes (like $\\eta^2$) alongside p-values. A significant ANOVA with tiny effect size may not be practically meaningful.\n\nCheck assumptions with residual plots. Consider transformations or nonparametric alternatives (Kruskal-Wallis) when assumptions are violated.\n\nPlan your sample size using power analysis before collecting data, specifying the minimum effect size you want to detect.\n\n## ANOVA as a General Linear Model\n\nANOVA is a special case of the general linear model (GLM). Both t-tests and ANOVA can be expressed as regression with indicator variables (dummy coding). This unified framework shows that these seemingly different methods are fundamentally the same.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ANOVA using lm() with dummy coding\n# Equivalent to aov()\niris_lm <- lm(Sepal.Length ~ Species, data = iris)\nanova(iris_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: Sepal.Length\n           Df Sum Sq Mean Sq F value    Pr(>F)    \nSpecies     2 63.212  31.606  119.26 < 2.2e-16 ***\nResiduals 147 38.956   0.265                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nThe connection becomes clear when you realize:\n- A one-sample t-test is regression on an intercept\n- A two-sample t-test is regression with one binary predictor\n- One-way ANOVA is regression with multiple indicator variables\n\nThis unified view is powerful: once you understand regression, you understand the entire family of linear models.\n\n## Effect Sizes in ANOVA\n\nBeyond statistical significance, report how much of the variance is explained by your factors.\n\n**Eta-squared ($\\eta^2$)**: Proportion of total variance explained by the factor\n\n$$\\eta^2 = \\frac{SS_{between}}{SS_{total}}$$\n\n**Partial eta-squared ($\\eta^2_p$)**: Proportion of variance explained after accounting for other factors\n\n**Omega-squared ($\\omega^2$)**: Less biased estimate of variance explained in the population\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate effect sizes\nss <- summary(iris_aov)[[1]]\nss_between <- ss[\"Species\", \"Sum Sq\"]\nss_within <- ss[\"Residuals\", \"Sum Sq\"]\nss_total <- ss_between + ss_within\n\neta_squared <- ss_between / ss_total\ncat(\"Eta-squared:\", round(eta_squared, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEta-squared: 0.619 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Omega-squared (less biased)\nms_within <- ss[\"Residuals\", \"Mean Sq\"]\nn <- nrow(iris)\nk <- length(unique(iris$Species))\nomega_squared <- (ss_between - (k-1) * ms_within) / (ss_total + ms_within)\ncat(\"Omega-squared:\", round(omega_squared, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOmega-squared: 0.612 \n```\n\n\n:::\n:::\n\n\n## Pseudoreplication\n\n::: {.callout-warning}\n## A Common Design Flaw\n\n**Pseudoreplication** occurs when non-independent observations are treated as independent replicates. This inflates the apparent sample size and leads to artificially small p-values.\n\nCommon examples:\n- Multiple measurements from the same individual treated as independent\n- Multiple cells from the same culture dish\n- Multiple fish from the same tank when treatment was applied to tanks\n- Technical replicates confused with biological replicates\n:::\n\nThe unit of replication must be the unit to which the treatment was independently applied. If you treat three tanks with drug A and three with drug B, you have n=3 per group regardless of how many fish are in each tank.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Wrong: treats individual fish as independent\n# If 10 fish per tank, and tanks are the true units:\nset.seed(42)\n# This overstates the evidence because fish within tanks are correlated\ntank_A <- rep(c(10, 12, 11), each = 10) + rnorm(30, sd = 1)  # 3 tanks, 10 fish each\ntank_B <- rep(c(8, 9, 8.5), each = 10) + rnorm(30, sd = 1)\n\n# Pseudoreplicated analysis (WRONG - n appears to be 30 per group)\ncat(\"Pseudoreplicated p-value:\", t.test(tank_A, tank_B)$p.value, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPseudoreplicated p-value: 2.315344e-11 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Correct analysis (using tank means, n = 3 per group)\nmeans_A <- c(mean(tank_A[1:10]), mean(tank_A[11:20]), mean(tank_A[21:30]))\nmeans_B <- c(mean(tank_B[1:10]), mean(tank_B[11:20]), mean(tank_B[21:30]))\ncat(\"Correct p-value:\", t.test(means_A, means_B)$p.value, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCorrect p-value: 0.008405113 \n```\n\n\n:::\n:::\n\n\nThe correct analysis has less power (larger p-value) because it honestly reflects the true sample size.\n\n## Repeated Measures ANOVA\n\nWhen the same subjects are measured under multiple conditions, observations are not independent—each subject creates correlated measurements. **Repeated measures ANOVA** accounts for this by partitioning out between-subject variability.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulated repeated measures data\nset.seed(123)\nn_subjects <- 10\nsubject <- factor(rep(1:n_subjects, 3))\ntime <- factor(rep(c(\"Before\", \"During\", \"After\"), each = n_subjects))\n\n# Subjects have baseline differences, plus time effect\nbaseline <- rnorm(n_subjects, 50, 10)\nresponse <- c(baseline, baseline + 5 + rnorm(n_subjects, 0, 3),\n              baseline + 2 + rnorm(n_subjects, 0, 3))\n\nrm_data <- data.frame(subject, time, response)\n\n# Repeated measures ANOVA\nrm_aov <- aov(response ~ time + Error(subject/time), data = rm_data)\nsummary(rm_aov)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nError: subject\n          Df Sum Sq Mean Sq F value Pr(>F)\nResiduals  9   2593   288.1               \n\nError: subject:time\n          Df Sum Sq Mean Sq F value   Pr(>F)    \ntime       2  187.3   93.64   12.52 0.000391 ***\nResiduals 18  134.6    7.48                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nRepeated measures designs are powerful because they control for individual differences, but require additional assumptions (sphericity) that should be checked.\n\n## Summary\n\nANOVA provides a flexible framework for comparing groups:\n\n- One-way ANOVA compares means across multiple groups\n- The F-test assesses whether between-group variance exceeds within-group variance\n- Post-hoc tests identify which specific groups differ\n- Two-way ANOVA examines main effects and interactions\n- Fixed effects are specific treatments; random effects are sampled from populations\n- ANOVA is part of the general linear model family\n- Always report effect sizes, not just p-values\n- Beware of pseudoreplication—the unit of analysis must match the unit of replication\n\n## Additional Resources\n\n- @logan2010biostatistical - Comprehensive treatment of ANOVA designs in biological research\n- @crawley2007r - Detailed coverage of linear models in R including ANOVA\n",
    "supporting": [
      "19-anova_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}