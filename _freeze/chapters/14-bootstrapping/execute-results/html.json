{
  "hash": "7656741fc180795975e67da23adc95d6",
  "result": {
    "engine": "knitr",
    "markdown": "# Bootstrapping {#sec-bootstrapping}\n\n\n::: {.cell}\n\n:::\n\n\n## The Bootstrap Idea\n\nFor the sample mean, we have elegant formulas for standard errors and confidence intervals derived from probability theory. But what about other statistics—the median, a correlation coefficient, the ratio of two means? For many estimators, no convenient formula exists.\n\nThe bootstrap, invented by Bradley Efron in 1979, provides a general solution. The key insight is that we can learn about the sampling distribution of a statistic by resampling from our data. If our sample is representative of the population, then samples drawn from our sample (with replacement) mimic what we would get from repeated sampling from the population.\n\n![](../images/week_2.030.jpeg){fig-align=\"center\"}\n\n## Why the Bootstrap Works\n\nThe bootstrap treats the observed sample as if it were the population. By drawing many samples with replacement from this \"population,\" we create a distribution of the statistic of interest. This bootstrap distribution approximates the true sampling distribution.\n\nThe bootstrap standard error is the standard deviation of the bootstrap distribution. Bootstrap confidence intervals can be constructed from the percentiles of the bootstrap distribution—the 2.5th and 97.5th percentiles give an approximate 95% confidence interval.\n\n## Bootstrap Procedure\n\nThe basic algorithm is straightforward:\n\n1. Draw a random sample of size n from your data with replacement (the bootstrap sample)\n2. Calculate the statistic of interest from this bootstrap sample\n3. Repeat steps 1 and 2 many times (1000 or more)\n4. Use the distribution of bootstrap statistics to estimate standard error or confidence intervals\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Bootstrap example: estimating standard error of median\nset.seed(42)\noriginal_data <- rexp(50, rate = 0.1)  # Skewed distribution\n\n# Observed median\nobserved_median <- median(original_data)\n\n# Bootstrap\nn_boot <- 1000\nboot_medians <- replicate(n_boot, {\n  boot_sample <- sample(original_data, replace = TRUE)\n  median(boot_sample)\n})\n\n# Bootstrap standard error\nboot_se <- sd(boot_medians)\n\n# Bootstrap confidence interval (percentile method)\nboot_ci <- quantile(boot_medians, c(0.025, 0.975))\n\ncat(\"Observed median:\", round(observed_median, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nObserved median: 6.59 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Bootstrap SE:\", round(boot_se, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBootstrap SE: 1.46 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"95% CI:\", round(boot_ci, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n95% CI: 4.39 11.92 \n```\n\n\n:::\n\n```{.r .cell-code}\nhist(boot_medians, breaks = 30, main = \"Bootstrap Distribution of Median\",\n     xlab = \"Median\", col = \"lightblue\")\nabline(v = observed_median, col = \"red\", lwd = 2)\nabline(v = boot_ci, col = \"blue\", lwd = 2, lty = 2)\n```\n\n::: {.cell-output-display}\n![](14-bootstrapping_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n## Advantages of the Bootstrap\n\nThe bootstrap is remarkably versatile. It can be applied to almost any statistic—means, medians, correlations, regression coefficients, eigenvalues, and more. It works when no formula for standard errors exists. It is nonparametric, making no assumptions about the underlying distribution. It handles complex sampling designs and calculations that would be intractable analytically.\n\nThe bootstrap is widely used for assessing confidence in phylogenetic trees, where the complexity of tree-building algorithms makes analytical approaches impractical. In machine learning, bootstrap aggregating (bagging) improves prediction accuracy by combining models trained on bootstrap samples.\n\n## When the Bootstrap Fails\n\nThe bootstrap is not a magic solution to all problems. It requires that the original sample be representative of the population—a biased sample produces biased bootstrap estimates. It can struggle with very small samples where the original data may not adequately represent the population.\n\nCertain statistics, like the maximum of a sample, are poorly estimated by the bootstrap because the bootstrap distribution is bounded by the observed data. The bootstrap also assumes that observations are independent; for dependent data (like time series), specialized bootstrap methods are needed.\n\n## Bootstrap Confidence Intervals\n\nSeveral methods exist for constructing bootstrap confidence intervals. The **percentile method** uses the quantiles of the bootstrap distribution directly. The **basic bootstrap** method reflects the bootstrap distribution around the observed estimate. The **BCa (bias-corrected and accelerated)** method adjusts for bias and skewness in the bootstrap distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Different bootstrap CI methods\nlibrary(boot)\n\n# Define statistic function\nmedian_fun <- function(data, indices) {\n  median(data[indices])\n}\n\n# Run bootstrap\nboot_result <- boot(original_data, median_fun, R = 1000)\n\n# Different CI methods\nboot.ci(boot_result, type = c(\"perc\", \"basic\", \"bca\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = boot_result, type = c(\"perc\", \"basic\", \"bca\"))\n\nIntervals : \nLevel      Basic              Percentile            BCa          \n95%   ( 1.256,  8.841 )   ( 4.331, 11.916 )   ( 4.244, 11.582 )  \nCalculations and Intervals on Original Scale\n```\n\n\n:::\n:::\n\n\nThe BCa method is generally preferred when computationally feasible, as it provides better coverage in many situations.\n\n## Practical Recommendations\n\nFor most applications, 1000 bootstrap replications provide adequate precision for standard errors. For confidence intervals, especially when using the BCa method, 10,000 replications may be preferable. Always set a random seed for reproducibility.\n\nRemember that the bootstrap estimates sampling variability—it cannot fix problems with biased samples or invalid measurements. Use it as a tool for understanding uncertainty, not as a cure for poor data quality.\n",
    "supporting": [
      "14-bootstrapping_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}