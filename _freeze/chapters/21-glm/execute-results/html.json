{
  "hash": "98061efa49e28d07ededd16e16e8d90f",
  "result": {
    "engine": "knitr",
    "markdown": "# Generalized Linear Models {#sec-glm}\n\n\n::: {.cell}\n\n:::\n\n\n## Beyond Normal Distributions\n\nStandard linear regression assumes that the response variable is continuous and normally distributed. But many important response variables violate these assumptions. Binary outcomes (success/failure, alive/dead) follow binomial distributions. Count data (number of events, cells, species) often follow Poisson distributions.\n\nGeneralized Linear Models (GLMs) extend linear regression to handle these situations. They provide a unified framework for modeling responses that follow different distributions from the exponential family.\n\n## Frequency Analysis: Categorical Response Variables\n\nBefore diving into GLMs, it's important to understand how we analyze categorical response variables. When observations fall into categories rather than being measured on a continuous scale, we count the frequency in each category and compare observed frequencies to expected values.\n\n### Chi-Square Goodness of Fit Test\n\nThe **goodness of fit test** asks whether observed frequencies match a hypothesized distribution. The classic example comes from Mendelian genetics.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Mendel's pea experiment - F2 phenotype ratios\n# Expected: 9:3:3:1 for Yellow-Smooth:Yellow-Wrinkled:Green-Smooth:Green-Wrinkled\nobserved <- c(315, 101, 108, 32)  # Mendel's actual data\nexpected_ratios <- c(9/16, 3/16, 3/16, 1/16)\n\n# Perform chi-square test\nchisq.test(observed, p = expected_ratios)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tChi-squared test for given probabilities\n\ndata:  observed\nX-squared = 0.47002, df = 3, p-value = 0.9254\n```\n\n\n:::\n:::\n\n\nThe test statistic measures deviation from expected:\n\n$$\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}$$\n\nwhere $O_i$ are observed and $E_i$ are expected counts. Under the null hypothesis (observed frequencies match expected), this follows a chi-square distribution with $df = k - 1$ where $k$ is the number of categories.\n\n::: {.callout-warning}\n## Chi-Square Assumptions\n\n1. **Independence**: Observations must be independent\n2. **Expected counts**: No more than 20% of expected counts should be < 5\n3. **Sample size**: Total sample should be reasonably large\n\nCheck expected values before interpreting results:\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- sum(observed)\nexpected <- n * expected_ratios\ncat(\"Expected counts:\", round(expected, 1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nExpected counts: 312.8 104.2 104.2 34.8\n```\n\n\n:::\n:::\n\n:::\n\n### Contingency Table Analysis\n\nWhen we have two categorical variables, we use a **contingency table** to examine their association. The null hypothesis is that the variables are independent.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example: Hair color and eye color association\n# Data from 1000 students\nhair_eye <- matrix(c(347, 191,    # Blue eyes: blonde, brunette\n                     177, 329),   # Brown eyes: blonde, brunette\n                   nrow = 2, byrow = TRUE)\nrownames(hair_eye) <- c(\"Blue_eyes\", \"Brown_eyes\")\ncolnames(hair_eye) <- c(\"Blonde\", \"Brunette\")\n\n# View the contingency table\nhair_eye\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           Blonde Brunette\nBlue_eyes     347      191\nBrown_eyes    177      329\n```\n\n\n:::\n\n```{.r .cell-code}\n# Chi-square test of independence\nchisq.test(hair_eye)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's Chi-squared test with Yates' continuity correction\n\ndata:  hair_eye\nX-squared = 89.703, df = 1, p-value < 2.2e-16\n```\n\n\n:::\n:::\n\n\nFor contingency tables, $df = (r-1)(c-1)$ where $r$ and $c$ are the number of rows and columns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize with a mosaic plot\nmosaicplot(hair_eye, main = \"Hair and Eye Color Association\",\n           color = c(\"gold\", \"brown\"), shade = FALSE)\n```\n\n::: {.cell-output-display}\n![](21-glm_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n### Standardized Residuals\n\nTo understand where associations are strongest, examine **standardized residuals**:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Which cells deviate most from independence?\ntest_result <- chisq.test(hair_eye)\ntest_result$residuals\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              Blonde  Brunette\nBlue_eyes   4.683940 -4.701920\nBrown_eyes -4.829778  4.848318\n```\n\n\n:::\n:::\n\n\nResiduals > 2 or < -2 indicate cells contributing substantially to the association. Positive residuals mean more observations than expected under independence; negative means fewer.\n\n### G-Test (Log-Likelihood Ratio Test)\n\nThe **G-test** is an alternative to chi-square based on likelihood ratios:\n\n$$G = 2 \\sum O_i \\ln\\left(\\frac{O_i}{E_i}\\right)$$\n\nThe G-test and chi-square give similar results for large samples, but G-tests are preferred when:\n- Sample sizes are small\n- Differences between observed and expected are small\n- You want to decompose complex tables\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Manual G-test calculation\nobserved_flat <- as.vector(hair_eye)\nexpected_flat <- as.vector(test_result$expected)\nG <- 2 * sum(observed_flat * log(observed_flat / expected_flat))\np_value <- 1 - pchisq(G, df = 1)\n\ncat(\"G statistic:\", round(G, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nG statistic: 92.248 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"p-value:\", format(p_value, scientific = TRUE), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\np-value: 0e+00 \n```\n\n\n:::\n:::\n\n\n### Odds Ratios: Measuring Effect Size\n\nThe chi-square test tells us *whether* variables are associated, but not the **strength** of association. For 2×2 tables, the **odds ratio** quantifies effect size.\n\nThe odds of an event are $\\frac{p}{1-p}$. The odds ratio compares odds between groups:\n\n$$OR = \\frac{odds_1}{odds_2} = \\frac{a/b}{c/d} = \\frac{ad}{bc}$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Odds ratio for hair/eye color data\na <- hair_eye[1,1]  # Blue eyes, Blonde\nb <- hair_eye[1,2]  # Blue eyes, Brunette\nc <- hair_eye[2,1]  # Brown eyes, Blonde\nd <- hair_eye[2,2]  # Brown eyes, Brunette\n\nodds_ratio <- (a * d) / (b * c)\ncat(\"Odds Ratio:\", round(odds_ratio, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOdds Ratio: 3.38 \n```\n\n\n:::\n:::\n\n\nAn OR of 3.38 means blue-eyed individuals have about 3.4 times the odds of being blonde compared to brown-eyed individuals.\n\n- OR = 1: No association\n- OR > 1: Positive association\n- OR < 1: Negative association\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Confidence interval for odds ratio (using log transform)\nlog_OR <- log(odds_ratio)\nse_log_OR <- sqrt(1/a + 1/b + 1/c + 1/d)\nci_log <- log_OR + c(-1.96, 1.96) * se_log_OR\nci_OR <- exp(ci_log)\n\ncat(\"95% CI for OR: [\", round(ci_OR[1], 2), \",\", round(ci_OR[2], 2), \"]\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n95% CI for OR: [ 2.62 , 4.35 ]\n```\n\n\n:::\n:::\n\n\n### Fisher's Exact Test\n\nFor small sample sizes (expected counts < 5), **Fisher's exact test** is more appropriate. It calculates exact probabilities rather than relying on the chi-square approximation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Small sample example\nsmall_table <- matrix(c(3, 1, 1, 3), nrow = 2)\nfisher.test(small_table)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tFisher's Exact Test for Count Data\n\ndata:  small_table\np-value = 0.4857\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n   0.2117329 621.9337505\nsample estimates:\nodds ratio \n  6.408309 \n```\n\n\n:::\n:::\n\n\nFisher's test is preferred for 2×2 tables with small samples and provides a confidence interval for the odds ratio.\n\n## Components of a GLM\n\nGLMs have three components:\n\n**Random component**: Specifies the probability distribution of the response variable (e.g., binomial, Poisson, normal).\n\n**Systematic component**: The linear predictor, a linear combination of explanatory variables:\n$$\\eta = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots$$\n\n**Link function**: Connects the random and systematic components, transforming the expected value of the response to the scale of the linear predictor.\n\n## The Link Function\n\nDifferent distributions use different link functions:\n\n| Distribution | Typical Link | Link Function |\n|:-------------|:-------------|:--------------|\n| Normal | Identity | $\\eta = \\mu$ |\n| Binomial | Logit | $\\eta = \\log(\\frac{\\mu}{1-\\mu})$ |\n| Poisson | Log | $\\eta = \\log(\\mu)$ |\n\n## Logistic Regression\n\nLogistic regression models binary outcomes. The response is 0 or 1 (failure or success), and we model the probability of success as a function of predictors.\n\nThe logistic function maps the linear predictor to probabilities:\n\n$$P(Y = 1 | X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X)}}$$\n\nEquivalently, we model the log-odds:\n\n$$\\log\\left(\\frac{P}{1-P}\\right) = \\beta_0 + \\beta_1 X$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# The logistic function\ncurve(1 / (1 + exp(-x)), from = -6, to = 6, \n      xlab = \"Linear Predictor\", ylab = \"Probability\",\n      main = \"The Logistic Function\", lwd = 2, col = \"blue\")\n```\n\n::: {.cell-output-display}\n![](21-glm_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n## Fitting Logistic Regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example: predicting transmission type from mpg\ndata(mtcars)\nmtcars$am <- factor(mtcars$am, labels = c(\"automatic\", \"manual\"))\n\nlogit_model <- glm(am ~ mpg, data = mtcars, family = binomial)\nsummary(logit_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = am ~ mpg, family = binomial, data = mtcars)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)   \n(Intercept)  -6.6035     2.3514  -2.808  0.00498 **\nmpg           0.3070     0.1148   2.673  0.00751 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43.230  on 31  degrees of freedom\nResidual deviance: 29.675  on 30  degrees of freedom\nAIC: 33.675\n\nNumber of Fisher Scoring iterations: 5\n```\n\n\n:::\n:::\n\n\n## Interpreting Logistic Coefficients\n\nCoefficients are on the log-odds scale. To interpret them:\n\n**Exponentiate** to get odds ratios:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp(coef(logit_model))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)         mpg \n0.001355579 1.359379288 \n```\n\n\n:::\n:::\n\n\nThe odds ratio for mpg (1.36) means that each additional mpg is associated with 36% higher odds of having a manual transmission.\n\n## Making Predictions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Predict probability for specific mpg values\nnew_data <- data.frame(mpg = c(15, 20, 25, 30))\npredict(logit_model, newdata = new_data, type = \"response\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        1         2         3         4 \n0.1194021 0.3862832 0.7450109 0.9313311 \n```\n\n\n:::\n:::\n\n\nThe `type = \"response\"` argument returns probabilities rather than log-odds.\n\n## Multiple Logistic Regression\n\nLike linear regression, logistic regression can include multiple predictors. This allows us to:\n\n- Control for confounding variables\n- Examine how multiple factors together predict the outcome\n- Test for interactions between predictors\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Multiple logistic regression: am ~ mpg + wt + hp\nmulti_logit <- glm(am ~ mpg + wt + hp, data = mtcars, family = binomial)\nsummary(multi_logit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = am ~ mpg + wt + hp, family = binomial, data = mtcars)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)  \n(Intercept) -15.72137   40.00281  -0.393   0.6943  \nmpg           1.22930    1.58109   0.778   0.4369  \nwt           -6.95492    3.35297  -2.074   0.0381 *\nhp            0.08389    0.08228   1.020   0.3079  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43.2297  on 31  degrees of freedom\nResidual deviance:  8.7661  on 28  degrees of freedom\nAIC: 16.766\n\nNumber of Fisher Scoring iterations: 10\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Odds ratios for all predictors\nexp(coef(multi_logit))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n (Intercept)          mpg           wt           hp \n1.486947e-07 3.418843e+00 9.539266e-04 1.087513e+00 \n```\n\n\n:::\n:::\n\n\nNotice how coefficients change compared to the simple model—this is the effect of controlling for other variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare models with likelihood ratio test\nanova(logit_model, multi_logit, test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table\n\nModel 1: am ~ mpg\nModel 2: am ~ mpg + wt + hp\n  Resid. Df Resid. Dev Df Deviance  Pr(>Chi)    \n1        30    29.6752                          \n2        28     8.7661  2   20.909 2.882e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nThe likelihood ratio test compares nested models. A significant p-value indicates the fuller model fits significantly better.\n\n## Poisson Regression\n\nPoisson regression models count data—the number of events in a fixed period or area. The response must be non-negative integers, and we assume events occur independently at a constant rate.\n\n$$\\log(\\mu) = \\beta_0 + \\beta_1 X$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example: modeling count data\nset.seed(42)\nexposure <- runif(100, 1, 10)\ncounts <- rpois(100, lambda = exp(0.5 + 0.3 * exposure))\n\npois_model <- glm(counts ~ exposure, family = poisson)\nsummary(pois_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = counts ~ exposure, family = poisson)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  0.42499    0.10624    4.00 6.32e-05 ***\nexposure     0.30714    0.01345   22.84  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 744.110  on 99  degrees of freedom\nResidual deviance:  97.826  on 98  degrees of freedom\nAIC: 498.52\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\n## Overdispersion\n\nA key assumption of Poisson regression is that the mean equals the variance. When variance exceeds the mean (**overdispersion**), standard errors are underestimated and p-values become too small.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check for overdispersion\n# Ratio of residual deviance to df should be near 1\ndispersion_ratio <- pois_model$deviance / pois_model$df.residual\ncat(\"Dispersion ratio:\", round(dispersion_ratio, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDispersion ratio: 0.998 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Values > 1.5 suggest overdispersion\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nValues > 1.5 suggest overdispersion\n```\n\n\n:::\n:::\n\n\n### Handling Overdispersion\n\n**Quasi-Poisson** estimates the dispersion parameter from the data rather than assuming it equals 1:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create overdispersed data for demonstration\nset.seed(42)\nn <- 100\nx <- runif(n, 1, 10)\n# Generate overdispersed counts (negative binomial acts like overdispersed Poisson)\ny_overdispersed <- rnbinom(n, size = 2, mu = exp(0.5 + 0.3 * x))\n\n# Standard Poisson (ignores overdispersion)\npois_fit <- glm(y_overdispersed ~ x, family = poisson)\n\n# Quasi-Poisson (accounts for overdispersion)\nquasi_fit <- glm(y_overdispersed ~ x, family = quasipoisson)\n\n# Compare standard errors\ncat(\"Poisson SE:\", round(summary(pois_fit)$coefficients[2, 2], 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPoisson SE: 0.0129 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Quasi-Poisson SE:\", round(summary(quasi_fit)$coefficients[2, 2], 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nQuasi-Poisson SE: 0.0327 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"SE inflation factor:\", round(summary(quasi_fit)$coefficients[2, 2] /\n                                   summary(pois_fit)$coefficients[2, 2], 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSE inflation factor: 2.53 \n```\n\n\n:::\n:::\n\n\nSimilarly, **quasibinomial** handles overdispersion in binomial data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Quasibinomial example\n# family = quasibinomial adjusts for extra-binomial variation\n```\n:::\n\n\n::: {.callout-tip}\n## When to Use Quasi-Likelihood\n\nUse `quasipoisson` or `quasibinomial` when:\n\n- Dispersion ratio is substantially > 1 (overdispersion)\n- You don't need AIC for model comparison (quasi-models don't have AIC)\n- The basic model structure is correct but variance assumptions are violated\n\nFor severe overdispersion, consider **negative binomial regression** (package `MASS`) which models overdispersion explicitly.\n:::\n\n## Model Assessment\n\nGLMs use **deviance** rather than R² to assess fit. Deviance compares the fitted model to a saturated model (one parameter per observation).\n\n**Null deviance**: Deviance with only the intercept\n**Residual deviance**: Deviance of the fitted model\n\nA large drop from null to residual deviance indicates the predictors explain substantial variation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare deviances\nwith(logit_model, null.deviance - deviance)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 13.55457\n```\n\n\n:::\n\n```{.r .cell-code}\n# Chi-square test for improvement\nwith(logit_model, pchisq(null.deviance - deviance, \n                         df.null - df.residual, \n                         lower.tail = FALSE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0002317271\n```\n\n\n:::\n:::\n\n\n## Model Comparison with AIC\n\nAs with linear models, AIC helps compare GLMs:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare models\nmodel1 <- glm(am ~ mpg, data = mtcars, family = binomial)\nmodel2 <- glm(am ~ mpg + wt, data = mtcars, family = binomial)\nmodel3 <- glm(am ~ mpg * wt, data = mtcars, family = binomial)\n\nAIC(model1, model2, model3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       df      AIC\nmodel1  2 33.67517\nmodel2  3 23.18426\nmodel3  4 24.49947\n```\n\n\n:::\n:::\n\n\n## Assumptions and Diagnostics\n\nGLM assumptions include:\n- Correct specification of the distribution\n- Correct link function\n- Independence of observations\n- No extreme multicollinearity\n\nDiagnostic tools include:\n- Residual plots (deviance or Pearson residuals)\n- Influence measures\n- Goodness-of-fit tests\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(1, 2))\nplot(logit_model, which = c(1, 2))\n```\n\n::: {.cell-output-display}\n![](21-glm_files/figure-html/unnamed-chunk-24-1.png){width=768}\n:::\n:::\n\n\n## Summary\n\nGLMs provide a flexible framework for modeling non-normal response variables while maintaining the interpretability of linear models. Logistic regression for binary outcomes and Poisson regression for counts are the most common applications, but the framework extends to other distributions as needed.\n",
    "supporting": [
      "21-glm_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}