{
  "hash": "7465fa4b9a24d1cc0fafacd5fb361d96",
  "result": {
    "engine": "knitr",
    "markdown": "# T-Tests {#sec-t-tests}\n\n\n::: {.cell}\n\n:::\n\n\n## Comparing Means\n\nOne of the most common questions in data analysis is whether two groups differ. Is the mean expression level different between treatment and control? Does the new material have different strength than the standard? Do patients on drug A have different outcomes than patients on drug B?\n\nThe t-test is the classic method for comparing means. It compares the observed difference between groups to the variability expected by chance, producing a test statistic that follows a t-distribution under the null hypothesis of no difference.\n\n## The T-Distribution\n\nThe t-distribution, discovered by William Sealy Gosset (who published under the pseudonym \"Student\"), resembles the normal distribution but has heavier tails. This accounts for the extra uncertainty that comes from estimating the population standard deviation from sample data.\n\nThe t-distribution is characterized by its degrees of freedom (df). As df increases, the t-distribution approaches the normal distribution. For small samples, the heavier tails mean that extreme values are more likely, leading to wider confidence intervals and more conservative tests.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare t-distributions with different df\nx <- seq(-4, 4, length.out = 200)\nplot(x, dnorm(x), type = \"l\", lwd = 2, col = \"black\",\n     xlab = \"x\", ylab = \"Density\",\n     main = \"T-distributions vs. Normal\")\nlines(x, dt(x, df = 3), lwd = 2, col = \"red\")\nlines(x, dt(x, df = 10), lwd = 2, col = \"blue\")\nlegend(\"topright\", \n       legend = c(\"Normal\", \"t (df=3)\", \"t (df=10)\"),\n       col = c(\"black\", \"red\", \"blue\"), lwd = 2)\n```\n\n::: {.cell-output-display}\n![](12-t-tests_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n## One-Sample T-Test\n\nThe one-sample t-test compares a sample mean to a hypothesized population value. The null hypothesis is that the population mean equals the specified value: $H_0: \\mu = \\mu_0$.\n\nThe test statistic is:\n\n$$t = \\frac{\\bar{x} - \\mu_0}{s / \\sqrt{n}}$$\n\nThis is the difference between the sample mean and hypothesized value, divided by the standard error of the mean. Under the null hypothesis, this statistic follows a t-distribution with $n-1$ degrees of freedom.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# One-sample t-test example\n# Does this sample come from a population with mean = 100?\nset.seed(42)\nsample_data <- rnorm(25, mean = 105, sd = 15)\n\nt.test(sample_data, mu = 100)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  sample_data\nt = 1.9936, df = 24, p-value = 0.05768\nalternative hypothesis: true mean is not equal to 100\n95 percent confidence interval:\n  99.72443 115.90166\nsample estimates:\nmean of x \n  107.813 \n```\n\n\n:::\n:::\n\n\nThe output shows the t-statistic, degrees of freedom, p-value, confidence interval, and sample mean. The small p-value indicates evidence that the true mean differs from 100.\n\n## Two-Sample T-Test\n\nThe two-sample (independent samples) t-test compares means from two independent groups. The null hypothesis is that the population means are equal: $H_0: \\mu_1 = \\mu_2$.\n\nThe test assumes:\n- Independence of observations within and between groups\n- Normally distributed populations (or large samples)\n- Equal variances in both groups (for the standard version)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Two-sample t-test example\nset.seed(518)\ntreatment <- rnorm(n = 30, mean = 12, sd = 3)\ncontrol <- rnorm(n = 30, mean = 10, sd = 3)\n\n# Visualize the data\npar(mfrow = c(1, 2))\nboxplot(treatment, control, names = c(\"Treatment\", \"Control\"),\n        col = c(\"lightblue\", \"lightgreen\"), main = \"Boxplot\")\n        \n# Combined histogram\nhist(treatment, col = rgb(0, 0, 1, 0.5), xlim = c(0, 20),\n     main = \"Histograms\", xlab = \"Value\")\nhist(control, col = rgb(0, 1, 0, 0.5), add = TRUE)\nlegend(\"topright\", legend = c(\"Treatment\", \"Control\"),\n       fill = c(rgb(0, 0, 1, 0.5), rgb(0, 1, 0, 0.5)))\n```\n\n::: {.cell-output-display}\n![](12-t-tests_files/figure-html/unnamed-chunk-4-1.png){width=768}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Perform the t-test\nt.test(treatment, control)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  treatment and control\nt = 1.3224, df = 57.98, p-value = 0.1912\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.5256045  2.5718411\nsample estimates:\nmean of x mean of y \n 11.08437  10.06125 \n```\n\n\n:::\n:::\n\n\n## Welch's T-Test\n\nThe classic two-sample t-test assumes equal variances. When this assumption is violated, Welch's t-test provides a better alternative. It adjusts the degrees of freedom to account for unequal variances.\n\nR's `t.test()` function uses Welch's test by default. To use the equal-variance version, set `var.equal = TRUE`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# When variances are unequal\nset.seed(42)\ngroup1 <- rnorm(30, mean = 50, sd = 5)\ngroup2 <- rnorm(30, mean = 52, sd = 15)\n\n# Welch's test (default)\nt.test(group1, group2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  group1 and group2\nt = 0.055423, df = 37.98, p-value = 0.9561\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.095093  6.438216\nsample estimates:\nmean of x mean of y \n 50.34293  50.17137 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Equal variance assumed\nt.test(group1, group2, var.equal = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTwo Sample t-test\n\ndata:  group1 and group2\nt = 0.055423, df = 58, p-value = 0.956\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.024786  6.367910\nsample estimates:\nmean of x mean of y \n 50.34293  50.17137 \n```\n\n\n:::\n:::\n\n\n## Paired T-Test\n\nWhen observations in two groups are naturally paired—the same subjects measured twice, matched pairs, or before-and-after measurements—the paired t-test is more appropriate. It tests whether the mean difference within pairs is zero.\n\nThe paired t-test is more powerful than the two-sample test when pairs are positively correlated, because it removes between-subject variability.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Paired t-test example: before and after treatment\nset.seed(123)\nn <- 20\nbefore <- rnorm(n, mean = 100, sd = 15)\n# After measurements are correlated with before\nafter <- before + rnorm(n, mean = 5, sd = 5)\n\n# Paired test (correct for this data)\nt.test(after, before, paired = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPaired t-test\n\ndata:  after and before\nt = 5.1123, df = 19, p-value = 6.19e-05\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 2.801598 6.685830\nsample estimates:\nmean difference \n       4.743714 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Compare to unpaired (less power)\nt.test(after, before, paired = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  after and before\nt = 1.0209, df = 37.992, p-value = 0.3138\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -4.663231 14.150660\nsample estimates:\nmean of x mean of y \n 106.8681  102.1244 \n```\n\n\n:::\n:::\n\n\nNotice that the paired test produces a smaller p-value because it accounts for the correlation between measurements on the same subject.\n\n## One-Tailed vs. Two-Tailed Tests\n\nBy default, `t.test()` performs a two-tailed test. For a one-tailed test, specify the alternative hypothesis:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Two-tailed (default): H_A: treatment ≠ control\nt.test(treatment, control, alternative = \"two.sided\")$p.value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1912327\n```\n\n\n:::\n\n```{.r .cell-code}\n# One-tailed: H_A: treatment > control\nt.test(treatment, control, alternative = \"greater\")$p.value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.09561633\n```\n\n\n:::\n\n```{.r .cell-code}\n# One-tailed: H_A: treatment < control\nt.test(treatment, control, alternative = \"less\")$p.value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9043837\n```\n\n\n:::\n:::\n\n\nUse one-tailed tests only when you have a strong prior reason to expect an effect in a specific direction and would not act on an effect in the opposite direction.\n\n## Checking Assumptions\n\nT-tests assume normally distributed data (or large samples) and, for the standard two-sample test, equal variances. Check these assumptions before interpreting results.\n\n**Normality**: Use histograms, Q-Q plots, or formal tests like Shapiro-Wilk.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check normality with Q-Q plot\nqqnorm(treatment)\nqqline(treatment, col = \"red\")\n```\n\n::: {.cell-output-display}\n![](12-t-tests_files/figure-html/unnamed-chunk-9-1.png){width=576}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Shapiro-Wilk test for normality\nshapiro.test(treatment)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  treatment\nW = 0.9115, p-value = 0.01624\n```\n\n\n:::\n:::\n\n\nA non-significant Shapiro-Wilk test suggests the data are consistent with normality. However, this test has low power for small samples and may reject normality for trivial deviations with large samples.\n\n**Equal variances**: Compare standard deviations or use Levene's test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare standard deviations\nsd(treatment)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.024138\n```\n\n\n:::\n\n```{.r .cell-code}\nsd(control)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.968592\n```\n\n\n:::\n\n```{.r .cell-code}\n# Levene's test (from car package)\n# car::leveneTest(c(treatment, control), \n#                 factor(rep(c(\"treatment\", \"control\"), each = 30)))\n```\n:::\n\n\n## Effect Size: Cohen's d\n\nStatistical significance does not tell you how large an effect is. **Cohen's d** measures effect size as the standardized difference between means:\n\n$$d = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_{pooled}}$$\n\nwhere $s_{pooled}$ is the pooled standard deviation.\n\nConventional interpretations: $|d| = 0.2$ is small, $|d| = 0.5$ is medium, $|d| = 0.8$ is large. However, context matters—a small d might be practically important in some fields.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate Cohen's d\nmean_diff <- mean(treatment) - mean(control)\ns_pooled <- sqrt((var(treatment) + var(control)) / 2)\ncohens_d <- mean_diff / s_pooled\n\ncat(\"Cohen's d:\", round(cohens_d, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCohen's d: 0.34 \n```\n\n\n:::\n:::\n\n\n## Practical Example\n\nLet's work through a complete analysis comparing two groups:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulated drug trial data\nset.seed(999)\ndrug <- rnorm(40, mean = 75, sd = 12)\nplacebo <- rnorm(40, mean = 70, sd = 12)\n\n# Step 1: Visualize\npar(mfrow = c(2, 2))\nboxplot(drug, placebo, names = c(\"Drug\", \"Placebo\"), \n        col = c(\"coral\", \"lightblue\"), main = \"Response by Group\")\n\n# Step 2: Check normality\nqqnorm(drug, main = \"Q-Q Plot: Drug\")\nqqline(drug, col = \"red\")\nqqnorm(placebo, main = \"Q-Q Plot: Placebo\")\nqqline(placebo, col = \"red\")\n\n# Combined histogram\nhist(drug, col = rgb(1, 0.5, 0.5, 0.5), xlim = c(40, 110),\n     main = \"Distribution Comparison\", xlab = \"Response\")\nhist(placebo, col = rgb(0.5, 0.5, 1, 0.5), add = TRUE)\n```\n\n::: {.cell-output-display}\n![](12-t-tests_files/figure-html/unnamed-chunk-13-1.png){width=768}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 3: Perform t-test\nresult <- t.test(drug, placebo)\nprint(result)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  drug and placebo\nt = 1.2147, df = 75.923, p-value = 0.2282\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.990367  8.213525\nsample estimates:\nmean of x mean of y \n 72.26982  69.15824 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Step 4: Calculate effect size\ncohens_d <- (mean(drug) - mean(placebo)) / \n            sqrt((var(drug) + var(placebo)) / 2)\ncat(\"\\nCohen's d:\", round(cohens_d, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCohen's d: 0.27 \n```\n\n\n:::\n:::\n\n\nThe t-test shows a significant difference (p < 0.05), and Cohen's d indicates a medium effect size. We can conclude that the drug group shows higher response than the placebo group, with the mean difference being about 0.4 standard deviations.\n",
    "supporting": [
      "12-t-tests_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}